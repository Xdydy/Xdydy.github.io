<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>ElasticQuota</title>
    <link href="/2025/07/20/elasticquota/"/>
    <url>/2025/07/20/elasticquota/</url>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="Koordinator-简单介绍"><a href="#Koordinator-简单介绍" class="headerlink" title="Koordinator 简单介绍"></a>Koordinator 简单介绍</h2><blockquote><p>​​QoS（Quality of Service，服务质量）​​是网络和系统中用于<strong>资源分配优先级</strong>​​和​<strong>性能保障</strong>的技术机制，旨在确保关键服务在资源受限时仍能满足特定要求（如延迟、带宽、可靠性）<br>在 <code>Koordinator</code> 中，QoS用于表达Pod在该节点上的运行质量，比如获取资源的方式、获取资源的比例、QoS保障策略等</p></blockquote><p><code>Koordinator</code> 是一个为微服务基于<code>Qos</code>的编排工具，用于编排基于<code>k8s</code>部署的AI，大数据等应用。<br>他的诞生旨在在原有的<code>k8s</code>调度能力上做一定的增强，主要包括一下几个方面.</p><ul><li>在集群中协调不同类型的工作负载以及在单点上能跑不同类型的<code>pods</code></li><li>允许资源过度申请来提高资源的利用率，但是仍然能满足<code>QoS</code>的保证</li><li>资源编排与资源隔离来提高各种批处理任务的效率</li></ul><p>与k8s类似，<code>Koordinator</code>主要包括以下几个组件</p><ul><li><code>Koord-Scheduler</code>: 基于<code>QoS</code>敏感的任务调度器，用于任务管理。</li><li><code>Koord-Descheduler</code>: 负载感知调度，一个支持节点负载<strong>重新平衡</strong>的调度插件，支持用户定义节点的CPU负载级别，以避免热点节点</li><li><code>Koord-Manager</code>: 由多个控制器和 webhook 组成，用于协调共置工作负载并支持资源超额承诺调度和 SLO 管理。</li><li><code>Koordlet</code>: 作为DaemonSet部署在kubernetes集群中，用于支持colocation资源过量使用、干扰检测、QoS保证等。</li></ul><h2 id="K8S-本身的调度能力"><a href="#K8S-本身的调度能力" class="headerlink" title="K8S 本身的调度能力"></a>K8S 本身的调度能力</h2><h3 id="K8S-下发任务的过程"><a href="#K8S-下发任务的过程" class="headerlink" title="K8S 下发任务的过程"></a>K8S 下发任务的过程</h3><ol><li>用户提交<code>Pods</code>定义</li></ol><p>用户会通过<code>kubectl</code>将请求提交到了<code>kube-apiserver</code>组件中。</p><ol start="2"><li>Kube-ApiServer 层</li></ol><ul><li>认证：判断请求客户端的证书等信息（密钥管理），通过用户得到角色</li><li>鉴权：检查用户是否有权限创建<code>pods</code></li><li>准入控制：<ul><li>ResourceQuota是否满足</li><li>DefaultStorageClass</li><li>PodSecurity安全策略</li></ul></li></ul><ol start="3"><li>写入etcd</li></ol><p>API-Server会将pods的元数据信息写入到etcd中</p><ol start="4"><li>调度器(Kube-Scheduler)</li></ol><ul><li>监控未调度的<code>pods</code></li><li>过滤：排除一些一定不能调度的节点(例如资源不足、亲和性不满足等)</li><li>打分：根据亲和性规则</li><li>绑定：将<code>pods</code>与<code>nodes</code>节点进行绑定</li></ul><ol start="5"><li><code>kubelet</code>接管</li></ol><ul><li>拉取镜像</li><li>创建沙箱</li><li>启动容器</li></ul><h3 id="K8S-下的-Resource-Quota"><a href="#K8S-下的-Resource-Quota" class="headerlink" title="K8S 下的 Resource Quota"></a>K8S 下的 Resource Quota</h3><p>​​Kubernetes的Resource Quota（资源配额）​​是一种集群管理机制，用于限制命名空间（Namespace）​级别的资源使用总量，防止单个命名空间过度消耗 CPU、内存、存储等资源，从而保障集群的公平性和稳定性.</p><ul><li>面向场景：不同的团队在不同的<code>namespaces</code>下工作，<code>ResourceQuota</code>实现在<code>namespace</code>下的资源隔离</li><li>禁止超额：如果用户创建的资源超过了<code>ResourceQuota</code>的限制，那么<code>k8s</code>会直接返回<code>403 Forbidden</code>禁止用户创建<code>pods</code></li></ul><p>但是<code>k8s</code>的<code>Resource Quota</code>是在<code>kube-apiserver</code>层面完成的，不具备资源借用的这种灵活性。</p><h2 id="Koordinator-scheduler"><a href="#Koordinator-scheduler" class="headerlink" title="Koordinator scheduler"></a>Koordinator scheduler</h2><p>Koordinator Scheduler 是用于实现其资源高效利用率的一个调度器，相当于是<code>kube-scheduler</code>的一个升级版。<br><code>Koord-Scheduler</code>包含了许多用于任务调度的组件，例如elasticquota, Gang scheduling</p><h3 id="容量调度"><a href="#容量调度" class="headerlink" title="容量调度"></a>容量调度</h3><p>容量调度是 koord-scheduler 在共享集群中管理不同用户资源使用情况的一种能力。主要通过管理 <code>ElasticQuota</code> 来实现</p><h3 id="绑定调度"><a href="#绑定调度" class="headerlink" title="绑定调度"></a>绑定调度</h3><h1 id="Koordinator-的任务调度"><a href="#Koordinator-的任务调度" class="headerlink" title="Koordinator 的任务调度"></a>Koordinator 的任务调度</h1><ul><li>资源隔离：在同一个节点上，一个或者一组<code>pods</code>需要进行资源隔离，以防止对其他类型的<code>pods</code>的抢占，相当于划分成为了一个个静态的箱子。<br>通常我们会通过资源配额(Quota)进行资源隔离</li><li>资源抢占<ul><li>在同一个配额下的抢占：高优先级的<code>pods</code>会对低优先级的<code>pods</code>进行抢占</li><li>不同配额下的抢占：<code>koordinator scheduler</code>通过<code>ElasticQuota</code>实现跨资源配额下的抢占</li></ul></li></ul><h2 id="ElasticQuota"><a href="#ElasticQuota" class="headerlink" title="ElasticQuota"></a>ElasticQuota</h2><p>正如前文我们所介绍的，<code>ElasticQuota</code>是<code>Koord-Scheduler</code>一个重要的组件，其可以实现</p><ul><li>不同quota组的借用与归还，忙的quota可以跟空闲的quota借用资源，当空闲quota变忙的时候可以还回去</li><li>它考虑了不同配额组之间的资源公平性，当繁忙配额组向空闲配额组借用资源时，可以按照一定的公平规则将资源分配给繁忙配额组。</li></ul><h3 id="Label-级别的隔离"><a href="#Label-级别的隔离" class="headerlink" title="Label 级别的隔离"></a>Label 级别的隔离</h3><ol><li>我们可以通过以下方式创建一个<code>ElasticQuota</code></li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">scheduling.sigs.k8s.io/v1alpha1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ElasticQuota</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">quota-example</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">quota.scheduling.koordinator.sh/parent:</span> <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-attr">quota.scheduling.koordinator.sh/is-parent:</span> <span class="hljs-string">&quot;false&quot;</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">max:</span><br>    <span class="hljs-attr">cpu:</span> <span class="hljs-string">500m</span><br>    <span class="hljs-attr">memory:</span> <span class="hljs-string">40Mi</span><br>  <span class="hljs-attr">min:</span><br>    <span class="hljs-attr">cpu:</span> <span class="hljs-string">100m</span><br>    <span class="hljs-attr">memory:</span> <span class="hljs-string">20Mi</span><br></code></pre></td></tr></table></figure><ol start="2"><li>并且创建一个<code>pods</code></li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">pod-example</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">quota.scheduling.koordinator.sh/name:</span> <span class="hljs-string">&quot;quota-example&quot;</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">schedulerName:</span> <span class="hljs-string">koord-scheduler</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">command:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">sleep</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">365d</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">busybox</span><br>    <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>    <span class="hljs-attr">name:</span> <span class="hljs-string">curlimage</span><br>    <span class="hljs-attr">resources:</span><br>      <span class="hljs-attr">limits:</span><br>        <span class="hljs-attr">cpu:</span> <span class="hljs-string">40m</span><br>        <span class="hljs-attr">memory:</span> <span class="hljs-string">30Mi</span><br>      <span class="hljs-attr">requests:</span><br>        <span class="hljs-attr">cpu:</span> <span class="hljs-string">40m</span><br>        <span class="hljs-attr">memory:</span> <span class="hljs-string">30Mi</span><br>  <span class="hljs-attr">restartPolicy:</span> <span class="hljs-string">Always</span><br></code></pre></td></tr></table></figure><p>可以通过</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl describe elasticquota quota-example<br></code></pre></td></tr></table></figure><p>得到当前配额资源的使用情况，得到的结果如下</p><p><img src="/../assets/elasticquota/ElasticQuota%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5.png" alt="当前配额使用情况"></p><ol start="3"><li>然后我们创建一个跟原来一样的<code>pods</code></li></ol><p>可以看到它正在<code>pending</code></p><p><img src="/../assets/elasticquota/pending-pods.png" alt="alt text"></p><p>把原本正在运行的<code>pods</code>删掉</p><p><img src="/../assets/elasticquota/delete-pods.png" alt="alt text"></p><h3 id="Label-级别的抢占"><a href="#Label-级别的抢占" class="headerlink" title="Label 级别的抢占"></a>Label 级别的抢占</h3><p>前文我们已经演示了通过<code>Label</code>实现资源的隔离，在一个配额内我们某些高优先级的任务能够抢占低优先级的任务</p><ol><li>创建优先级<code>class</code></li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">scheduling.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PriorityClass</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">high-priority</span>  <span class="hljs-comment"># 优先级名称</span><br><span class="hljs-attr">value:</span> <span class="hljs-number">1000000</span>         <span class="hljs-comment"># 优先级数值（越高越优先）</span><br><span class="hljs-attr">globalDefault:</span> <span class="hljs-literal">false</span>   <span class="hljs-comment"># 是否作为默认优先级（通常设为 false）</span><br><span class="hljs-attr">description:</span> <span class="hljs-string">&quot;High priority for critical workloads&quot;</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">scheduling.k8s.io/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PriorityClass</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">low-priority</span>  <span class="hljs-comment"># 优先级名称</span><br><span class="hljs-attr">value:</span> <span class="hljs-number">1000</span>         <span class="hljs-comment"># 优先级数值（越高越优先）</span><br><span class="hljs-attr">globalDefault:</span> <span class="hljs-literal">false</span>   <span class="hljs-comment"># 是否作为默认优先级（通常设为 false）</span><br><span class="hljs-attr">description:</span> <span class="hljs-string">&quot;Low priority for critical workloads&quot;</span><br></code></pre></td></tr></table></figure><ol start="2"><li>创建<code>elasticquota</code></li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">scheduling.sigs.k8s.io/v1alpha1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">ElasticQuota</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">quota-example</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">quota.scheduling.koordinator.sh/parent:</span> <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-attr">quota.scheduling.koordinator.sh/is-parent:</span> <span class="hljs-string">&quot;false&quot;</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">max:</span><br>    <span class="hljs-attr">cpu:</span> <span class="hljs-string">1Gi</span><br>    <span class="hljs-attr">memory:</span> <span class="hljs-string">40Mi</span><br>  <span class="hljs-attr">min:</span><br>    <span class="hljs-attr">cpu:</span> <span class="hljs-string">1Gi</span><br>    <span class="hljs-attr">memory:</span> <span class="hljs-string">20Mi</span><br></code></pre></td></tr></table></figure><ol start="3"><li>创建低优先级的<code>deployment</code></li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">busy-low-priority</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">3</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">matchLabels:</span><br>      <span class="hljs-attr">app:</span> <span class="hljs-string">busybox</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app:</span> <span class="hljs-string">busybox</span><br>        <span class="hljs-attr">quota.scheduling.koordinator.sh/name:</span> <span class="hljs-string">&quot;quota-example&quot;</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">schedulerName:</span> <span class="hljs-string">koord-scheduler</span><br>      <span class="hljs-attr">priorityClassName:</span> <span class="hljs-string">low-priority</span>  <span class="hljs-comment"># 引用已创建的 PriorityClass</span><br>      <span class="hljs-attr">containers:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">busybox</span><br>        <span class="hljs-attr">image:</span> <span class="hljs-string">busybox</span><br>        <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>        <span class="hljs-attr">command:</span> <br>          <span class="hljs-bullet">-</span> <span class="hljs-string">sleep</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;10d&quot;</span><br>        <span class="hljs-attr">resources:</span><br>          <span class="hljs-attr">requests:</span><br>            <span class="hljs-attr">cpu:</span> <span class="hljs-string">100m</span><br>            <span class="hljs-attr">memory:</span> <span class="hljs-string">10Mi</span><br></code></pre></td></tr></table></figure><p>由于3个<code>10Mi</code>内存的<code>pods</code>并没有超过配额的限制，因此可以运行</p><p><img src="/../assets/elasticquota/low-deployment.png" alt="alt text"></p><ol start="4"><li>创建高优先级的<code>pods</code></li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">busy-high-priority</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">3</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">matchLabels:</span><br>      <span class="hljs-attr">app:</span> <span class="hljs-string">busybox</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app:</span> <span class="hljs-string">busybox</span><br>        <span class="hljs-attr">quota.scheduling.koordinator.sh/name:</span> <span class="hljs-string">&quot;quota-example&quot;</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">schedulerName:</span> <span class="hljs-string">koord-scheduler</span><br>      <span class="hljs-attr">priorityClassName:</span> <span class="hljs-string">high-priority</span>  <span class="hljs-comment"># 引用已创建的 PriorityClass</span><br>      <span class="hljs-attr">containers:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">busybox</span><br>        <span class="hljs-attr">image:</span> <span class="hljs-string">busybox</span><br>        <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">IfNotPresent</span><br>        <span class="hljs-attr">command:</span> <br>          <span class="hljs-bullet">-</span> <span class="hljs-string">sleep</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;10d&quot;</span><br>        <span class="hljs-attr">resources:</span><br>          <span class="hljs-attr">requests:</span><br>            <span class="hljs-attr">cpu:</span> <span class="hljs-string">100m</span><br>            <span class="hljs-attr">memory:</span> <span class="hljs-string">10Mi</span><br></code></pre></td></tr></table></figure><p>可以看到高优先级的<code>pods</code>可以抢占低优先级的<code>pods</code></p><p><img src="/../assets/elasticquota/high-deployment.png" alt="alt text"></p><h3 id="Namespaces级别的隔离"><a href="#Namespaces级别的隔离" class="headerlink" title="Namespaces级别的隔离"></a>Namespaces级别的隔离</h3><p>其中的<code>namespace</code>隔离与<code>label</code>隔离接口接近，这里不再赘述</p><h3 id="代码逻辑"><a href="#代码逻辑" class="headerlink" title="代码逻辑"></a>代码逻辑</h3><p><img src="/../assets/elasticquota/manager.png" alt="代码总体架构"></p><h4 id="PreFilter-阶段"><a href="#PreFilter-阶段" class="headerlink" title="PreFilter 阶段"></a>PreFilter 阶段</h4><p>这个阶段主要是处理了<code>pods</code>加入到一个<code>quota</code>中，其中包含了几个重要的过程</p><ul><li>检查<code>EnableRuntimeQuota</code>: 这个</li><li>检查<code>pods</code>是否是不被驱逐的<code>pods</code>: 将该<code>pods</code>加入到不被驱逐的集合当中，如果当前<code>quota</code>的资源不足，就拒绝这个<code>pods</code></li><li>检查<code>EnableCheckParentQuota</code>: 会递归的检查当前的资源请求会不会导致父<code>quota</code>超额，拒绝超额的<code>pods</code></li></ul><h4 id="PostFilter-阶段"><a href="#PostFilter-阶段" class="headerlink" title="PostFilter 阶段"></a>PostFilter 阶段</h4><p>这个阶段会修改默认的驱逐过程，只允许同个<code>quota</code>的<code>pods</code>可以互相驱逐对方</p><h2 id="Load-aware-Descheduler"><a href="#Load-aware-Descheduler" class="headerlink" title="Load-aware Descheduler"></a>Load-aware Descheduler</h2><h3 id="代码逻辑-1"><a href="#代码逻辑-1" class="headerlink" title="代码逻辑"></a>代码逻辑</h3><h4 id="Balance-方法"><a href="#Balance-方法" class="headerlink" title="Balance 方法"></a>Balance 方法</h4><p>该方法通过遍历节点池来实现重新的负载均衡，对每个节点调用<code>processOneNodePool</code></p><ul><li>获取节点的使用情况<code>getNodeUsage</code></li><li>获取节点的上下限<code>getNodeThresholds</code></li><li>将节点进行分类<code>classifyNodes</code>: 分为低负载节点、高负载节点以及正常节点，分别为<code>lowNodes, highNodes, prodLowNodes, prodHighNodes, bothLowNodes</code></li><li>过滤出实际高使用量的节点<code>filterRealAbnormalNodes</code></li><li>重置低使用量的节点<code>resetNodesAsNormal</code></li><li>将<code>pods</code>从<code>SourceNodes</code>中驱逐<code>evictPodsFromSourceNodes</code></li><li>尝试把高负载节点标记为正常节点</li></ul><p><code>evictPodsFromSourceNodes</code>中有一个重要的函数调用<code>balancePods</code></p><ul><li><code>balancePods</code>首先将<code>pods</code>进行分类，分为可以删除的<code>pods</code>以及不可删除的</li><li>然后将<code>pods</code>排个序</li><li>然后驱逐<code>pods</code> <code>evictPods</code></li><li>如果<code>continueEvictionCond</code>条件不满足，就不会继续再驱逐<code>pods</code></li></ul><p><code>continueEvictionCond</code>判定如果当前的节点压力已经没那么大了，说明就不用继续驱逐了</p><h4 id="nodeFit"><a href="#nodeFit" class="headerlink" title="nodeFit"></a>nodeFit</h4><p>看的时候一直有一个问题，如果一个<code>pods</code>从高负载节点重调度到一个节点之后，导致了这个节点变为高负载该咋办？这样重调度是不是一直死循环了</p><p><code>nodeFit</code>参数设置的时候在重调度过程中就会检查每个<code>pods</code>是否有合适的节点，如果没有设置，那么<code>pods</code>就会直接调度到一个节点上</p><p><code>podFitsAnyNodeWithThreshold</code> 方法会检查一个<code>pods</code>是否有合适的节点可以接纳它</p><ul><li><code>NodeFit</code>方法会检查某个<code>pods</code>是否能够调度到这个节点上, 但只是一些亲和性的检查还有一些资源使用量的检查</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// NodeFit returns true if the provided pod can be scheduled onto the provided node.</span><br><span class="hljs-comment">// This function is used when the NodeFit pod filtering feature of the Descheduler is enabled.</span><br><span class="hljs-comment">// This function currently considers a subset of the Kubernetes Scheduler&#x27;s predicates when</span><br><span class="hljs-comment">// deciding if a pod would fit on a node, but more predicates may be added in the future.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NodeFit</span><span class="hljs-params">(nodeIndexer podutil.GetPodsAssignedToNodeFunc, pod *corev1.Pod, node *corev1.Node)</span></span> []<span class="hljs-type">error</span> &#123;<br><span class="hljs-comment">// Check node selector and required affinity</span><br><span class="hljs-keyword">var</span> errors []<span class="hljs-type">error</span><br><span class="hljs-keyword">if</span> ok, err := utils.PodMatchNodeSelector(pod, node); err != <span class="hljs-literal">nil</span> &#123;<br>errors = <span class="hljs-built_in">append</span>(errors, err)<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> !ok &#123;<br>errors = <span class="hljs-built_in">append</span>(errors, fmt.Errorf(<span class="hljs-string">&quot;pod node selector does not match the node label&quot;</span>))<br>&#125;<br><span class="hljs-comment">// Check taints (we only care about NoSchedule and NoExecute taints)</span><br>ok := utils.TolerationsTolerateTaintsWithFilter(pod.Spec.Tolerations, node.Spec.Taints, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(taint *corev1.Taint)</span></span> <span class="hljs-type">bool</span> &#123;<br><span class="hljs-keyword">return</span> taint.Effect == corev1.TaintEffectNoSchedule || taint.Effect == corev1.TaintEffectNoExecute<br>&#125;)<br><span class="hljs-keyword">if</span> !ok &#123;<br>errors = <span class="hljs-built_in">append</span>(errors, fmt.Errorf(<span class="hljs-string">&quot;pod does not tolerate taints on the node&quot;</span>))<br>&#125;<br><span class="hljs-comment">// Check if the pod can fit on a node based off it&#x27;s requests</span><br>ok, reqErrors := fitsRequest(nodeIndexer, pod, node)<br><span class="hljs-keyword">if</span> !ok &#123;<br>errors = <span class="hljs-built_in">append</span>(errors, reqErrors...)<br>&#125;<br><span class="hljs-comment">// Check if node is schedulable</span><br><span class="hljs-keyword">if</span> IsNodeUnschedulable(node) &#123;<br>errors = <span class="hljs-built_in">append</span>(errors, fmt.Errorf(<span class="hljs-string">&quot;node is not schedulable&quot;</span>))<br>&#125;<br><br><span class="hljs-keyword">return</span> errors<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>获取之后会评估这个<code>pod</code>的<code>request</code>会不会导致<code>node</code>过载，如果过载就不会再调度到这个节点上</li></ul>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>elasticquota</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>knative 学习笔记</title>
    <link href="/2025/07/20/knative/"/>
    <url>/2025/07/20/knative/</url>
    
    <content type="html"><![CDATA[<h1 id="Knative-学习笔记"><a href="#Knative-学习笔记" class="headerlink" title="Knative 学习笔记"></a>Knative 学习笔记</h1><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h2><ul><li>有 <code>kind</code>（kubernetes in docker）</li><li>有 <code>kubectl</code></li></ul><h2 id="Knative-CLI-安装"><a href="#Knative-CLI-安装" class="headerlink" title="Knative CLI 安装"></a>Knative CLI 安装</h2><ul><li><p>源码安装</p><ul><li>先决条件：有 <code>Go</code></li><li>克隆仓库</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><br>git <span class="hljs-built_in">clone</span> git@github.com:knative/client.git<br><span class="hljs-built_in">cd</span> client/<br></code></pre></td></tr></table></figure><ul><li>构建二进制执行文件  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hack/build.sh -f<br></code></pre></td></tr></table></figure></li></ul></li><li><p>将二进制文件移动到路径下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mv</span> kn /usr/local/bin<br></code></pre></td></tr></table></figure></li><li><p>校验版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kn version<br></code></pre></td></tr></table></figure></li></ul><h2 id="Knative-quickstart-插件安装"><a href="#Knative-quickstart-插件安装" class="headerlink" title="Knative quickstart 插件安装"></a>Knative quickstart 插件安装</h2><ul><li><p>源码安装</p><ul><li>克隆仓库</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> git@github.com:knative-extensions/kn-plugin-quickstart.git<br></code></pre></td></tr></table></figure><ul><li>构建源码  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./hack/build.sh<br></code></pre></td></tr></table></figure></li></ul></li><li><p>移动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mv</span> kn-quickstart /usr/local/bin<br></code></pre></td></tr></table></figure></li><li><p>校验</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kn quickstart --<span class="hljs-built_in">help</span><br></code></pre></td></tr></table></figure></li></ul><h3 id="运行-Knative-quickstart-插件"><a href="#运行-Knative-quickstart-插件" class="headerlink" title="运行 Knative quickstart 插件"></a>运行 Knative quickstart 插件</h3><ul><li>安装 k8s 实例</li><li>创建一个集群名字为 <code>knative</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kind create cluster --name knative<br></code></pre></td></tr></table></figure><ul><li>安装 <code>Knative Serving</code></li><li>安装 <code>Knative Eventing</code></li><li>本地部署</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kn quickstart kind --registry<br></code></pre></td></tr></table></figure><p><img src="/../assets/knative/LwV9bxxOZorWfjxQbftcPeBhnte.png"></p><h3 id="Knative-Functions"><a href="#Knative-Functions" class="headerlink" title="Knative Functions"></a>Knative Functions</h3><h4 id="安装-func-CLI"><a href="#安装-func-CLI" class="headerlink" title="安装 func CLI"></a>安装 func CLI</h4><ul><li><p>源码安装</p><ul><li>克隆仓库</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> git@github.com:knative/func.git<br></code></pre></td></tr></table></figure><ul><li>编译<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span>  func &amp;&amp; make<br></code></pre></td></tr></table></figure></li></ul></li></ul><h4 id="作为-Knative-的插件安装"><a href="#作为-Knative-的插件安装" class="headerlink" title="作为 Knative 的插件安装"></a>作为 Knative 的插件安装</h4><ul><li>移动到系统目录</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mv</span> ./func /usr/local/bin/kn-func<br></code></pre></td></tr></table></figure><ul><li>验证</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kn func version<br></code></pre></td></tr></table></figure><h2 id="从K8S安装Knative"><a href="#从K8S安装Knative" class="headerlink" title="从K8S安装Knative"></a>从K8S安装Knative</h2><h3 id="K8S搭建"><a href="#K8S搭建" class="headerlink" title="K8S搭建"></a>K8S搭建</h3><ul><li>启动集群</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo kubeadm init<br></code></pre></td></tr></table></figure><h3 id="Knative-serving-安装"><a href="#Knative-serving-安装" class="headerlink" title="Knative-serving 安装"></a>Knative-serving 安装</h3><ul><li><p>配置 <code>serving-crds.yaml</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://github.com/knative/serving/releases/download/knative-v1.12.4/serving-crds.yaml<br>kubectl apply -f serving-crds.yaml<br></code></pre></td></tr></table></figure></li><li><p>配置 <code>serving-core.yaml</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://github.com/knative/serving/releases/download/knative-v1.12.4/serving-core.yaml<br>kubectl apply -f serving-core.yaml<br></code></pre></td></tr></table></figure></li><li><p>配置网络</p><ul><li>使用 kourier<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget [https://github.com/knative/net-kourier/releases/download/knative-v1.12.3/kourier.yaml](https://github.com/knative/net-kourier/releases/download/knative-v1.12.3/kourier.yaml)<br>kubectl apply -f kourier.yaml<br><br><span class="hljs-comment"># Configure Knative Serving to use Kourier by default by running the command:</span><br><br>kubectl patch configmap/config-network <br>--namespace knative-serving <br>--<span class="hljs-built_in">type</span> merge <br>--patch <span class="hljs-string">&#x27;&#123;&quot;data&quot;:&#123;&quot;ingress-class&quot;:&quot;kourier.ingress.networking.knative.dev&quot;&#125;&#125;&#x27;</span><br><br>kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.12.4/serving-default-domain.yaml<br><br><span class="hljs-comment"># 10.0.0.233 is an arbitary choice.</span><br>EXTERNAL_IP=<span class="hljs-string">&quot;10.0.0.233&quot;</span><br><br><span class="hljs-comment"># To get rid of the strange rules that default urls *.svc.cluster.local cannot be accessed from outside network. </span><br><span class="hljs-comment"># sslip can avoid us from trouble of manipulating DNS record.</span><br>kubectl patch configmap/config-domain \<br>  --namespace knative-serving \<br>  --<span class="hljs-built_in">type</span> merge \<br>  --patch <span class="hljs-string">&quot;&#123;\&quot;data\&quot;:&#123;\&quot;<span class="hljs-variable">$EXTERNAL_IP</span>.sslip.io\&quot;:\&quot;\&quot;&#125;&#125;&quot;</span><br><br>kubectl patch svc kourier -n kourier-system -p <span class="hljs-string">&quot;&#123;\&quot;spec\&quot;: &#123;\&quot;type\&quot;: \&quot;LoadBalancer\&quot;, \&quot;externalIPs\&quot;: [\&quot;<span class="hljs-variable">$EXTERNAL_IP</span>\&quot;]&#125;&#125;&quot;</span><br><br><span class="hljs-comment"># Fetch the External IP address or CNAME by running the command:</span><br><br>kubectl --namespace kourier-system get service kourier<br><br></code></pre></td></tr></table></figure><ul><li>使用istio<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://github.com/knative/net-istio/releases/download/knative-v1.12.3/istio.yaml<br>kubectl apply -l knative.dev/crd-install=<span class="hljs-literal">true</span> -f istio.yaml<br>kubectl apply -f istio.yaml<br><br><span class="hljs-comment"># Install the Knative Istio controller by running the command:</span><br>wget https://github.com/knative/net-istio/releases/download/knative-v1.12.3/net-istio.yaml<br>kubectl apply -f net-istio.yaml<br><br><span class="hljs-comment"># Fetch the External IP address or CNAME by running the command:</span><br>kubectl --namespace istio-system get service istio-ingressgateway<br></code></pre></td></tr></table></figure></li></ul></li></ul></li></ul><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><h4 id="无法对外暴露-IP"><a href="#无法对外暴露-IP" class="headerlink" title="无法对外暴露 IP"></a>无法对外暴露 IP</h4><ul><li>当前解决方案</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl get svc -n kourier-system<br><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># NAME               TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="hljs-comment"># kourier            LoadBalancer   10.106.92.238   &lt;pending&gt;     80:31491/TCP,443:31283/TCP   23m</span><br><span class="hljs-comment"># kourier-internal   ClusterIP      10.109.2.63     &lt;none&gt;        80/TCP,443/TCP               23m</span><br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -v --noproxy <span class="hljs-string">&#x27;*&#x27;</span> -H <span class="hljs-string">&quot;Host: nodehello.default.example.com&quot;</span> http://10.106.92.238:80<br></code></pre></td></tr></table></figure><ul><li>解决方案2.0</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 10.0.0.233 is an arbitary choice.</span><br>EXTERNAL_IP=<span class="hljs-string">&quot;10.0.0.233&quot;</span><br><br><span class="hljs-comment"># To get rid of the strange rules that default urls *.svc.cluster.local cannot be accessed from outside network. </span><br><span class="hljs-comment"># sslip can avoid us from trouble of manipulating DNS record.</span><br>kubectl patch configmap/config-domain \<br>      --namespace knative-serving \<br>      --<span class="hljs-built_in">type</span> merge \<br>      --patch <span class="hljs-string">&quot;&#123;\&quot;data\&quot;:&#123;\&quot;<span class="hljs-variable">$EXTERNAL_IP</span>.sslip.io\&quot;:\&quot;\&quot;&#125;&#125;&quot;</span><br><br>kubectl patch svc kourier -n kourier-system -p <span class="hljs-string">&quot;&#123;\&quot;spec\&quot;: &#123;\&quot;type\&quot;: \&quot;LoadBalancer\&quot;, \&quot;externalIPs\&quot;: [\&quot;<span class="hljs-variable">$EXTERNAL_IP</span>\&quot;]&#125;&#125;&quot;</span><br></code></pre></td></tr></table></figure><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><h3 id="代理问题"><a href="#代理问题" class="headerlink" title="代理问题"></a>代理问题</h3><p>在国内环境下安装 knative serving 时需要通过代理，但是在 <code>http_proxy</code> 中设置为 <code>http://127.0.0.1:7890</code> 并不能够正确的将其设置为本机的代理，因为在 docker 环境下它读到的 127.0.0.1 并不知道是啥。需要设置为一个域名代理 <code>proxy.i2ec.top:21087</code>，通过内网 IP 或者公网 IP 设置代理</p><p>安装过程中可以通过</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl get pods -n knative-serving<br></code></pre></td></tr></table></figure><p>判断 <code>knative-serving</code> 是否被正确添加</p><p>但是在部署函数完成后要想成功调用函数，又需要对生成的域名做绕过代理的处理，例如现在生成了一个</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">http://hello.default.127.0.0.1.sslip.io/<br></code></pre></td></tr></table></figure><p>使用 <code>curl</code> 工具时需要绕过代理访问</p><blockquote><p>可以为 no_proxy 添加 <code>.sslip.io</code> 作为一个小技巧</p></blockquote><h1 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h1><h2 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h2><h3 id="创建一个函数"><a href="#创建一个函数" class="headerlink" title="创建一个函数"></a>创建一个函数</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kn func create -l go hello<br></code></pre></td></tr></table></figure><h3 id="构建运行部署函数"><a href="#构建运行部署函数" class="headerlink" title="构建运行部署函数"></a>构建运行部署函数</h3><ul><li>运行</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kn func run<br></code></pre></td></tr></table></figure><ul><li>触发</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kn func invoke<br></code></pre></td></tr></table></figure><p><img src="/../assets/knative/T6OzbZPgxoSfT4xUt7RcKBwCnDg.png"></p><ul><li>部署</li></ul><p>部署一个函数创建一个 OCI 容器镜像，并将该镜像 push 到镜像仓库中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kn func deploy --registry &lt;&gt;<br></code></pre></td></tr></table></figure><h1 id="Serving"><a href="#Serving" class="headerlink" title="Serving"></a>Serving</h1><h2 id="创建一个-Service"><a href="#创建一个-Service" class="headerlink" title="创建一个 Service"></a>创建一个 Service</h2><ul><li>先决条件</li></ul><h2 id="从私有仓库部署"><a href="#从私有仓库部署" class="headerlink" title="从私有仓库部署"></a>从私有仓库部署</h2>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>knative</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Serverless 智能化应用</title>
    <link href="/2025/07/20/serverless_ai/"/>
    <url>/2025/07/20/serverless_ai/</url>
    
    <content type="html"><![CDATA[<h1 id="Serverless-智能化应用"><a href="#Serverless-智能化应用" class="headerlink" title="Serverless 智能化应用"></a>Serverless 智能化应用</h1><h1 id="研究问题"><a href="#研究问题" class="headerlink" title="研究问题"></a>研究问题</h1><ul><li><p>底层系统资源的配置（GPU，内存大小配置等）智能适应 or 人工设定</p></li><li><p>有状态函数的快速存储机制</p></li><li><p>容错</p><ul><li>执行顺序：多个无状态函数可能会乱序执行，导致结果也是乱序</li><li>执行状态：有状态函数的执行可能会断掉，需要能够恢复</li></ul></li></ul><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><h2 id="Cirrus-a-Serverless-Framework-for-End-to-end-ML-Workflow"><a href="#Cirrus-a-Serverless-Framework-for-End-to-end-ML-Workflow" class="headerlink" title="Cirrus: a Serverless Framework for End-to-end ML Workflow"></a><a href="https://dl.acm.org/doi/abs/10.1145/3357223.3362711">Cirrus: a Serverless Framework for End-to-end ML Workflow</a></h2><p>代码仓库：<a href="https://github.com/ucbrise/cirrus">https://github.com/ucbrise/cirrus</a></p><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><ul><li><p>解决 ML 过程资源配置和管理的问题</p><ul><li>传统的 <code>workflow</code> 拥有多个阶段，每一个阶段的计算都是异构的</li><li>计算的异构使得机器学习用户很难正确配置和管理资源，并且在实践中，这会构成重大负担，经常导致过度配置并损害用户生产力。</li></ul></li><li><p>Serverless 可以很好的管理资源</p><ul><li>但是很难适应 Serverless</li></ul></li><li><p><code>Cirrus</code> 通过 Serverless 的框架对 ML 做资源的适配管理</p><ul><li>轻量级的工作运行时，为 ML 人员找到最适合的资源配置</li><li>节省了配置大量内存或存储的成本<ul><li>(a) 来自远程存储的流式训练小批量数据；</li><li>(b) 重新设计分布式训练算法以在无服务器环境中稳健运行</li></ul></li><li>采用无状态的 worker 架构，使系统能够有效地处理频繁的 worker 离开和到达作为预期行为。</li></ul></li></ul><h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ul><li><p>ML Workflow 带来两个问题</p><ul><li>过度配置：如果使用虚拟机做资源的配置，配置的复杂性就会导致过度配置</li><li>资源管理：管理的复杂性降低了交互式和迭代用例</li></ul></li><li><p>Serverless 本身的挑战</p><ul><li>内存以及存储过小：利用无服务器计算的主要挑战是与 lambda 函数相关的本地资源限制（内存、CPU、存储、网络）非常小</li><li>低带宽以及缺少 P2P 通信：最新的 Lambda 也只有 60MB 的带宽；缺少通信策略，用于数据中心机器学习的常见通信策略，例如树形结构或环形结构的 AllReduce 通信，在此类环境中受到限制</li><li>启动时间短暂并且不可预测：Lambda 函数的生命周期很短，并且其启动时间变化很大。这意味着在训练期间，lambda 会在不可预测的时间开始，并可能在训练中间结束。这需要 lambda 的 ML 运行时能够容忍工作人员的频繁离开和到达。</li><li>缺少快速共享存储的功能：由于 lambda 函数彼此不能直接通信，因此需要快速的共享存储。但是 ML 训练对数据的性能要求非常高，不能有太大的延时</li></ul></li></ul><h3 id="系统设计"><a href="#系统设计" class="headerlink" title="系统设计"></a>系统设计</h3><h4 id="系统架构图"><a href="#系统架构图" class="headerlink" title="系统架构图"></a>系统架构图</h4><p><img src="/../assets/serverless_ai/T6RKbWlZ9o53x3xfiy6chhkXn7g.png"></p><h4 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h4><ul><li><p>Python 前端：提供了一个底层抽象系统资源的高级接口</p><ul><li>预处理模块：该子模块允许不同类型的数据集转换：最小-最大缩放、标准化和特征哈希。</li><li>训练模块：可以使用随机梯度下降来训练的 ML 模型。</li><li>超参数优化：允许用户对给定的参数集运行网格搜索。</li></ul></li><li><p>客户端后端：解析训练数据并将其加载到 S3，在 lambda 上启动 Cirrus 工作程序，管理分布式数据存储，跟踪计算进度，并在计算完成后将结果返回到 Python 前端。</p></li><li><p>工作运行时：Cirrus 提供了一个运行时，它封装了系统支持的不同计算之间共享的所有函数</p></li><li><p>分布式数据存储：</p><ul><li>低延迟：将数据存储部署在云虚拟机中</li><li>可扩展：Cirrus 包括以下机制：(1) 分片存储、(2) 高度多线程、(3) 数据压缩、(4) 梯度过滤器和 (5) 异步通信。</li><li>强接口</li></ul></li></ul><h4 id="端到端的-ML-阶段"><a href="#端到端的-ML-阶段" class="headerlink" title="端到端的 ML 阶段"></a>端到端的 ML 阶段</h4><ul><li><p>数据加载与预处理</p><ul><li>假设数据已经被全局存储（例如 S3）Cirrus 将其转为二进制数据</li><li>使用 Map-Reduce 模式。</li></ul></li><li><p>模型训练</p><ul><li>分布式 SGD 算法</li><li>每个 <code>worker</code> 运行 Lambda 函数并负责迭代计算梯度步骤。每个梯度计算都需要两个输入：一个小批量和最新的模型</li><li>对于每次迭代，每个工作人员都会计算一个新的梯度。然后将该梯度异步发送到数据存储 (send_gradient_X ) 以更新模型。</li></ul></li><li><p>超参数优化</p><ul><li>典型的做法是在多维参数空间上执行网格搜索。通常让网格搜索完全运行完成并对结果进行后处理以找到最佳配置（过度配置）</li><li>随着时间的推移，Cirrus 通过提供超参数搜索仪表板来消除这种过度配置的情况</li><li>因此，Cirrus 提供 (a) 用于启动超参数搜索的 API 和执行后端，(b) 用于监控模型精度收敛的仪表板，(c) 终止单独调整实验并节省超额配置成本的能力。</li></ul></li></ul><h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><h4 id="Python-前端"><a href="#Python-前端" class="headerlink" title="Python 前端"></a>Python 前端</h4><ul><li>抽象了有关开发者的细节</li><li>通过 API 参数覆盖内部配置参数</li></ul><h4 id="Client-后端"><a href="#Client-后端" class="headerlink" title="Client 后端"></a>Client 后端</h4><ul><li><p>将前端的算法部署到 Lambda 上并抽象了管理</p><ul><li>内部保存了与 Lambda 函数的连接列表</li></ul></li><li><p>使用线程池响应请求</p><ul><li>Lambda API 的特殊性</li></ul></li></ul><h4 id="分布式数据存储"><a href="#分布式数据存储" class="headerlink" title="分布式数据存储"></a>分布式数据存储</h4><ul><li><p>多线程服务器，将任务分配给多个核心</p><ul><li>目的：高效地更新模型</li></ul></li><li><p>对传入&#x2F;传出存储的梯度和模型实施数据压缩</p><ul><li>目的：减少网络带来的瓶颈</li></ul></li><li><p>通过发送和接收稀疏梯度和模型数据结构来优化通信</p></li></ul><h4 id="Worker-运行时"><a href="#Worker-运行时" class="headerlink" title="Worker 运行时"></a>Worker 运行时</h4><p><img src="/../assets/serverless_ai/EIpDbh2kooFxcOxq9BMcZ2QUnXV.png"></p><ul><li>ML 计算的通用抽象</li><li>用于访问训练数据、参数模型和中间结果的数据原语。</li></ul><h2 id="Ray-A-Distributed-Framework-for-Emerging-AI-Applications"><a href="#Ray-A-Distributed-Framework-for-Emerging-AI-Applications" class="headerlink" title="Ray: A Distributed Framework for Emerging AI Applications"></a><a href="https://www.usenix.org/conference/osdi18/presentation/moritz">Ray: A Distributed Framework for Emerging AI Applications</a></h2><h3 id="解决问题-1"><a href="#解决问题-1" class="headerlink" title="解决问题"></a>解决问题</h3><ul><li><p>需求：下一代的 AI 需要持续与环境交互，对性能和复杂性有要求</p><ul><li>必须支持细粒度计算</li><li>支持时间和资源的合理使用的异构性</li><li>必须支持动态执行，因为模拟或与环境交互的结果可能会改变未来的计算</li></ul></li><li><p>贡献：Ray，一个通用集群计算框架，支持 RL 应用程序的模拟、训练和服务</p><ul><li>该框架统一了新兴 RL 应用程序的训练、模拟和服务必要组件</li><li>抽象任务并行以及 Actor 计算</li><li>控制状态存储在分片元数据存储中，所有其他系统组件都是无状态的。</li><li>自下而上的分布式调度策略</li></ul></li></ul><h3 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a>问题描述</h3><ul><li><p>针对需求</p><ul><li>细粒度、异构计算<ul><li>计算时间可能几秒钟到几小时</li><li>硬件资源可能也不一样</li></ul></li><li>灵活的计算模型<ul><li>无状态：无状态计算可以在系统中的任何节点上执行，这使得在需要时可以轻松实现负载平衡和计算到数据的移动<ul><li>适合细粒度模拟和数据处理</li></ul></li><li>有状态：状态计算非常适合实现参数服务器、对 GPU 支持的数据执行重复计算或运行不公开其状态的第三方模拟器</li></ul></li><li>动态执行<ul><li>计算完成的顺序并不总是事先知道（例如，模拟完成的顺序），并且计算的结果可以决定未来的计算</li></ul></li></ul></li><li><p>对要实现的目标</p><ul><li>要每秒处理数百万个任务</li><li>集成现有的模拟器以及机器学习框架</li></ul></li></ul><h3 id="编程与计算模型"><a href="#编程与计算模型" class="headerlink" title="编程与计算模型"></a>编程与计算模型</h3><h4 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h4><ul><li><p><code>Tasks</code>：表示在无状态工作线程上执行远程函数</p><ul><li>并行：当调用远程函数时，会立即返回表示任务结果的 future</li><li>协作：可以使用 ray.get() 检索 Future，并将其作为参数传递给其他远程函数</li><li>无状态：对不可变对象进行操作，具有幂等性，具备容错能力</li></ul></li><li><p><code>Actor</code>：表示有状态的计算</p><ul><li><code>handle</code>：可以被传递给其他的 <code>Actor</code>，便于远程调用</li></ul></li></ul><p><img src="/../assets/serverless_ai/IzQgbNQ7joYN7Hxcc5tcVVCEnNg.png"></p><ul><li>为了处理具有异构持续时间的并发任务，引入了 ray.wait()，它等待前 k 个可用结果，而不是像 ray.get() 那样等待所有结果。</li><li>为了处理资源异构任务，使开发人员能够指定资源需求，以便 Ray 调度器能够有效地管理资源。</li><li>为了提高灵活性，启用<strong>嵌套远程函数</strong>，这意味着远程函数可以调用其他远程函数。这对于实现高可扩展性也至关重要，因为它允许多个进程以分布式方式调用远程函数。</li></ul><h4 id="计算模型"><a href="#计算模型" class="headerlink" title="计算模型"></a>计算模型</h4><ul><li><p>任务图计算：输入满足条件时自动触发</p><ul><li>两种节点类型<ul><li>数据节点</li><li>任务节点</li></ul></li><li>两种边<ul><li>数据边：捕捉数据节点和任务节点之间的依赖关系<ul><li>若 D 是 T 的输出，那么从 T 到 D 就有一条连边</li></ul></li><li>控制边：捕捉两个有调用关系的任务节点之间的计算依赖关系<ul><li>若 T1 调用 T2，那么 T1 到 T2 有一条边</li></ul></li></ul></li></ul></li><li><p>Actor</p><ul><li>新增状态边<ul><li>若 Mj 方法在 Mi 方法之后，那么 Mi 到 Mj 有一条边</li><li>所有对一个 Actor 的方法的调用顺序通过状态边连接</li></ul></li></ul></li><li><p>有状态边帮助我们将参与者嵌入到无状态任务图中，因为它们捕获共享参与者内部状态的连续方法调用之间的隐式数据依赖关系</p></li></ul><h3 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h3><ul><li>应用层：实现 API</li><li>系统层：提供高拓展性以及容错性</li></ul><h4 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h4><ul><li><p><code>Driver</code>：运行用户程序的进程</p></li><li><p><code>Worker</code>：一个调用远程函数或 Task 的无状态进程</p><ul><li>由系统层分配任务</li><li>当远程函数被声明时，函数被分配到所有的 <code>Worker</code></li></ul></li><li><p><code>Actor</code>：有状态进程，在调用时仅执行他所公开的方法</p><ul><li><code>Actor</code> 必须被显式实例化</li><li>通过之前方法的执行结果序列化地执行方法</li></ul></li></ul><h4 id="系统层"><a href="#系统层" class="headerlink" title="系统层"></a>系统层</h4><p><img src="/../assets/serverless_ai/TRtMbePDxoNIBBxigoEcxkubnxh.png"></p><h5 id="全局控制存储（GCS）：维护系统的控制状态"><a href="#全局控制存储（GCS）：维护系统的控制状态" class="headerlink" title="全局控制存储（GCS）：维护系统的控制状态"></a>全局控制存储（GCS）：维护系统的控制状态</h5><ul><li><p>具有发布-订阅的键值存储</p><ul><li>使用分片来实现扩展</li><li>使用每个分片链复制来提供容错能力</li></ul></li><li><p>容错能力</p><ul><li>需要维护沿袭信息：持久沿袭信息组件与其他组件分离，每个组件独立扩展</li></ul></li><li><p>保持低延迟</p><ul><li>最大限度的减少任务调度的开销</li><li>任务分配与任务调度分离：对象元数据存储在 GCS 中而不是调度程序中</li></ul></li><li><p>使系统中的每个其他组件都是无状态的</p></li></ul><h5 id="自下而上的分部署调度器：两级分层调度器"><a href="#自下而上的分部署调度器：两级分层调度器" class="headerlink" title="自下而上的分部署调度器：两级分层调度器"></a>自下而上的分部署调度器：两级分层调度器</h5><ul><li><p>全局调度器</p><ul><li>考虑每个节点的负载和任务的约束来做出调度决策</li><li>选择提供最短估计等待时间的节点</li><li>通过心跳获取每个节点的队列大小和节点资源可用性，以及来自 GCS 的任务输入的位置及其大小。</li><li>如果全局调度程序成为瓶颈，可以通过 GCS 实例化更多共享相同信息的副本</li></ul></li><li><p>每个节点本地调度器</p><ul><li>每个节点创建的任务首先通过本地调度器</li><li>本地调度器在本地调度程序，直到节点过载</li><li>当本地调度器不想管了，就交给全局调度器</li></ul></li></ul><p><img src="/../assets/serverless_ai/QU23b2xyEogFT1xauHzcpLb8nyc.png"></p><h5 id="内存中分布式对象存储"><a href="#内存中分布式对象存储" class="headerlink" title="内存中分布式对象存储"></a>内存中分布式对象存储</h5><p>在每个节点上，通过共享内存实现对象存储。这允许在同一节点上运行的任务之间进行零拷贝数据共享。作为数据格式，使用 Apache Arrow</p><ul><li><p>对象存储：</p><ul><li>如果任务的输入不是本地的，则输入会在执行之前复制到本地对象存储。</li><li>此外，任务将其输出写入本地对象存储</li></ul></li><li><p>低延迟</p><ul><li>将整个对象保持在内存中，通过 LRU 机制写入磁盘</li></ul></li><li><p>容错</p><ul><li>通过沿袭重新执行来恢复任何所需的对象。</li><li>在初始执行时，GCS 存储的沿袭信息追踪着有状态的 Actor 以及无状态的 Tasks</li><li></li></ul></li></ul><h2 id="ServerlessLLM-Locality-Enhanced-Serverless-Inference-for-Large-Language-Models"><a href="#ServerlessLLM-Locality-Enhanced-Serverless-Inference-for-Large-Language-Models" class="headerlink" title="ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models"></a><a href="https://arxiv.org/abs/2401.14351">ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models</a></h2><h3 id="解决问题-2"><a href="#解决问题-2" class="headerlink" title="解决问题"></a>解决问题</h3><ul><li><p>一个局部性增强的用于大模型推理的 Serverless 系统</p><ul><li>利用 GPU 服务器上可用的存储和内存设备的大量容量和带宽，从而减少昂贵的远程检查点下载并实现高效的检查点加载</li></ul></li><li><p>主要贡献</p><ul><li>LLM 检查点快速加载系统：利用<strong>加载优化检查点格式设计</strong>以及<strong>高效的多层检查点加载系统</strong><ul><li>一个新的加载优化检查点，支持顺序、基于块的读取和高效的张量寻址</li><li>多层次检查点加载系统，通过内存中<strong>数据块池</strong>，具有<strong>高效内存复制的数据路径，</strong>多阶段数据加载流水线</li></ul></li><li>本地驱动的 LLM 推理实时迁移：允许 ServerlessLLM 有效地实现局部驱动的服务器分配，同时保持正在进行的 LLM 推理的低延迟<ul><li>基于 token 的迁移决定了迁移到另一个服务器的最小 token 集</li><li>二阶段迁移保证了 LLM 推理迁移时避免影响在线推理服务</li></ul></li><li>位置感知服务器分配：使 ServerlessLLM 能够评估集群中每个服务器的状态，并有效地安排模型启动时间以利用本地检查点放置<ul><li>集成了用于估计<strong>从不同层次加载检查点的时间</strong>以及<strong>迁移到另一个服务器的时间</strong>的模型</li></ul></li></ul></li></ul><h3 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h3><p><img src="/../assets/serverless_ai/Y6ijbTeTXoX4WIxCz1PcJR9Ln2c.png"></p><ul><li><p>Serverless LLM 推理系统</p><ul><li>接收一个用户的输入请求</li><li>基于之前生成的 token 迭代式生成 token</li><li>每轮迭代使用一个 KV 存储来加速下一代的 token 生成</li></ul></li><li><p>传统的 Serverless LLM 推理系统</p><ul><li><strong>请求路由器</strong>将请求转发到已经在运行 LLM 推理服务的实例上（称为热节点）或者让<strong>模型加载器</strong>创建更多的实例节点</li><li><strong>模型加载器</strong>从未分配节点池以及冷节点池分配节点来启动一个新的 LLM 推理服务</li></ul></li></ul><h3 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a>问题描述</h3><h4 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h4><ul><li><p>大模型推理服务</p><ul><li>需要大量的 GPU 资源</li><li>延迟时间很难估计：取决于他们的输出长度</li><li>大量的 GPU 资源被消耗：LLM 提供商需要托管大量的 LLM</li></ul></li><li><p>为了减少 GPU 消耗</p><ul><li>开发者上传他们的 checkpoint -&gt; 包括模型执行文件以及模型参数</li><li>接收请求后将其<strong>转发到已经加载好模型的 GPU</strong> 中</li><li>使用无服务器的方法可以充分利用共享 GPU 资源，并且开发者不需要为 GPU 长时间运行付费</li></ul></li><li><p>Serverless 保持 LLM 的 promise 时有显著的延迟</p><ul><li>数据可大可小</li><li>数据异构</li><li>利用<strong>多层的存储架构</strong>进行检查点的本地存储，并充分利用存储带宽</li></ul></li><li><p>上述设计带来的现实问题</p><ul><li>如何优化检查点加载来充分利用存储带宽</li><li>选择已经加载好的服务器可能会带来 GPU 服务器的争用，这部分争用不知道何时结束</li><li>当接收到请求需要加载一个模型的时候，应该如何保证模型启动的最短时间</li></ul></li></ul><h4 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h4><ul><li><p>从模型存储库中下载模型检查点的代价大</p><ul><li>从 S3 下载一个 130GB 的模型大概需要 26 秒的时间</li></ul></li><li><p>从存储设备加载模型检查点的代价大</p><ul><li>使用 PyTorch 加载 OPT-30B 到 4 块 GPU 花费 34s</li><li>加载 LLaMA-2-70b 到 8 块 GPU 花费 84s</li></ul></li></ul><h4 id="当前解决方案"><a href="#当前解决方案" class="headerlink" title="当前解决方案"></a>当前解决方案</h4><ul><li>超额订阅模型实例：搞多点 GPU，太贵了</li><li>在本地内存中缓存模型：小模型可以这么干，大模型经常 cache miss</li><li>部署额外的存储服务器：部署额外存储服务器和高带宽网络的成本通常会产生巨额费用</li></ul><h3 id="快速-LLM-检查点加载"><a href="#快速-LLM-检查点加载" class="headerlink" title="快速 LLM 检查点加载"></a>快速 LLM 检查点加载</h3><h4 id="加载优化的检查点"><a href="#加载优化的检查点" class="headerlink" title="加载优化的检查点"></a>加载优化的检查点</h4><ul><li><p>检查点通常包含</p><ul><li>定义模型架构的模型执行文件</li><li>模型参数文件，将参数的二进制数据存储在 LLM 中</li></ul></li><li><p>ServerlessLLM 将检查点转化一下</p><ul><li>支持基于块的读取：仅包含模型的二进制数据，不包含张量形状等元数据</li><li>支持高效的张量寻址：创建一个索引文件，将张量名称映射到 GPU id、偏移量和大小的元组，以便于高效恢复张量</li></ul></li><li><p>ServerlessLLM 有一个内服务模型管理器来加载优化后的检查点</p><ul><li>从 GPU 上分配内存并预加载检查点的二进制数据</li><li>模型需要时可以有效地获取 GPU 的内存地址<ul><li>通过一个<strong>加载函数</strong>，通过每个 GPU 的基地址以及偏移量</li></ul></li></ul></li></ul><h4 id="高效的多层次检查点加载"><a href="#高效的多层次检查点加载" class="headerlink" title="高效的多层次检查点加载"></a>高效的多层次检查点加载</h4><ul><li><p>内存数据块池</p><ul><li>使用并行化 PCI 链路</li><li>支持应用级别的控制：提供 API 对内存的分配以及释放的控制</li><li>减少内存碎片</li></ul></li><li><p>高效数据路径（data path）</p><ul><li>利用直接文件访问？</li><li>利用固定内存：使用固定内存消除 DRAM 和 GPU 之间的冗余数据复制</li></ul></li></ul><h3 id="实时迁移的本地驱动-LLM-推理"><a href="#实时迁移的本地驱动-LLM-推理" class="headerlink" title="实时迁移的本地驱动 LLM 推理"></a>实时迁移的本地驱动 LLM 推理</h3><h4 id="必要性"><a href="#必要性" class="headerlink" title="必要性"></a>必要性</h4><p><img src="/../assets/serverless_ai/CXudbH1aaoYT49xu6VucvxsunPr.png"></p><ul><li><strong>可用性驱动策略</strong>选择 GPU 可用的服务器 1，这使得没有被加载进来的 B 受到影响，而 A 不受影响</li><li><strong>本地驱动策略</strong>选择了已经加载好模型的服务器 2，这也让 B 的加载受到影响，并且服务器 1 浪费了</li><li><strong>抢先驱动策略</strong>让 B 打断 A 的推理过程，并且让 A 在服务器 1 上跑，这样让 A 被打断了</li><li><strong>实时迁移的本地驱动策略</strong>让服务器 1 预加载 A 的模型，A 加载好了就把 A 迁移过去，这样对 AB 都好</li></ul><h4 id="实时迁移过程"><a href="#实时迁移过程" class="headerlink" title="实时迁移过程"></a>实时迁移过程</h4><ul><li><p>简单的想法是创建快照并迁移</p><ul><li>但是这样太慢了</li></ul></li><li><p>使用<strong>基于 Token 的迁移</strong></p><ul><li>前提：在推理过程中，模型检查点是只读的，并且可以低延迟地从令牌重新计算 KV 缓存</li><li>所以当模型检查点的副本在另一台服务器上，就可以在那里启动模型并传输令牌</li><li>传输的过程就变成了传输整数数组（小且快）</li></ul></li><li><p>避免令牌传输时中断推理，使用<strong>二阶段传输</strong></p><ul><li>阶段 1：目标服务器使用中间令牌重新计算 KV 缓存</li><li>阶段 2：目标服务器接收发送中间令牌后生成的剩余令牌</li><li>具体过程<ul><li><strong>模型加载管理器</strong>让<strong>目标服务器</strong>加载模型 A，如果目标服务器上有空闲实例 A 则跳过此步骤</li><li>加载后该<strong>管理器</strong>向源服务器发送关于目标服务器的<strong>模型迁移请求</strong></li><li>如果源服务器推理未完成，就将推理过程的令牌的<strong>恢复请求</strong>发送到目标服务器</li><li>目标服务器根据接收的<strong>恢复请求</strong>中的令牌重新计算 KV 缓存</li><li>当恢复请求结束后，源服务器停止推理，使用所有令牌和“已迁移”标志回复请求路由器。</li><li>管理器完成迁移，将源服务器的模型 A 卸载并开始推理模型 B</li><li><strong>请求路由器</strong>检查推理响应中的标志。如果是“迁移”，则请求路由器将其路由表中的 src 服务器替换为 dest 服务器，并将所有令牌发送到 dest 服务器以继续推理</li></ul></li></ul></li></ul><h3 id="本地感知的服务器分配"><a href="#本地感知的服务器分配" class="headerlink" title="本地感知的服务器分配"></a>本地感知的服务器分配</h3><h4 id="模型调度器设计"><a href="#模型调度器设计" class="headerlink" title="模型调度器设计"></a>模型调度器设计</h4><ul><li>模型加载时间估计器</li></ul><h4 id="估计模型加载时间"><a href="#估计模型加载时间" class="headerlink" title="估计模型加载时间"></a>估计模型加载时间</h4><ul><li>三个要素<ul><li>排队时间（q），即模型在服务器加载任务队列中的等待时间。</li><li>模型大小 (n)、模型大小（以字节为单位）或其在多 GPU 推理场景中的模型分区</li><li>带宽 (b)，将模型从存储传输到 GPU 的可用速度</li></ul></li></ul><h4 id="估计模型迁移时间"><a href="#估计模型迁移时间" class="headerlink" title="估计模型迁移时间"></a>估计模型迁移时间</h4><h2 id="FuncPipe-A-Pipelined-Serverless-Framework-for-Fast-and-Cost-Efficient-Training-of-Deep-Learning-Mod"><a href="#FuncPipe-A-Pipelined-Serverless-Framework-for-Fast-and-Cost-Efficient-Training-of-Deep-Learning-Mod" class="headerlink" title="FuncPipe: A Pipelined Serverless Framework for Fast and Cost-Efficient Training of Deep Learning Mod"></a><a href="https://dl.acm.org/doi/abs/10.1145/3570607">FuncPipe: A Pipelined Serverless Framework for Fast and Cost-Efficient Training of Deep Learning Mod</a></h2><h3 id="解决问题-3"><a href="#解决问题-3" class="headerlink" title="解决问题"></a>解决问题</h3><ul><li><p>深度学习在 Serverless 平台上的训练有障碍</p><ul><li>Serverless 基础设施的资源限制</li><li>深度学习模型对内存和带宽的爆炸性需求</li></ul></li><li><p>FuncPipe 贡献</p><ul><li>Serverless 训练的流水线框架：利用模型分区来弥合上述的差距</li><li>流水线的 scatter-reduce 算法：提高通信效率</li><li>使用混合整数二次规划（MIQP）：制定模型划分和资源分配的协同优化问题</li></ul></li></ul><h3 id="背景知识-1"><a href="#背景知识-1" class="headerlink" title="背景知识"></a>背景知识</h3><ul><li><p>Serverless 训练的好处</p><ul><li>不用配置虚拟机，不用管理集群</li><li>按需付费</li><li>资源弹性扩充</li></ul></li><li><p>DL 训练的通信方式</p><ul><li>集中式：参数服务器。Worker 给参数，服务器返还参数。例如 Cirrus</li><li>去中心化：基于某种协议（例如 all-reduce 或者 scatter-reduce）</li></ul></li></ul><h3 id="问题描述-3"><a href="#问题描述-3" class="headerlink" title="问题描述"></a>问题描述</h3><ul><li><p>Serverless 通信能力不能满足 DL 训练的通信需求</p><ul><li>传输的数据量少（带宽低）</li><li>延迟高（不具备直接通信能力，依赖于中间件）</li></ul></li><li><p>Serverless 内存占用小</p></li><li><p>问题定义：</p><ul><li>如何划分深度学习模型<ul><li>之前的工作都是基于静态的资源，只追求最大的吞吐量</li></ul></li><li>如何为每个 Serverless 函数分配资源</li></ul></li></ul><h3 id="系统设计-1"><a href="#系统设计-1" class="headerlink" title="系统设计"></a>系统设计</h3><p><img src="/../assets/serverless_ai/HrwgbwXlZoLJ6lxXdf1cNM8zn6b.png"></p><h4 id="系统架构-1"><a href="#系统架构-1" class="headerlink" title="系统架构"></a>系统架构</h4><ul><li><p>启动组件</p></li><li><p>运行时组件</p></li><li><p>客户端 API</p><ul><li>设置、部署、监控训练</li></ul></li></ul><h4 id="训练流水线"><a href="#训练流水线" class="headerlink" title="训练流水线"></a>训练流水线</h4><p><img src="/../assets/serverless_ai/UT2NbJD47ox21wxuGhLcBXrdnSd.png"></p><ul><li><p>执行同步训练，避免潜在的收敛和准确性问题</p><ul><li>数据被分为微批次<ul><li>所有的微批次都会经过每个分区进行前向计算</li><li>所有前向计算完成后，微批次以相反的顺序进行反向计算</li></ul></li></ul></li><li><p>每个 Worker 有两种任务</p><ul><li>通信任务<ul><li>分为上行、下行以及同步</li><li>上行下行通过云存储完成，同步在处于同一个配置的 Worker 在一轮迭代后执行</li></ul></li><li>计算任务</li></ul></li><li><p>类似工作：GPipe。不同点：将通信任务视为管道阶段并将其与计算任务重叠</p></li></ul><h4 id="分散减少流水线-scatter-reduce"><a href="#分散减少流水线-scatter-reduce" class="headerlink" title="分散减少流水线(scatter-reduce)"></a>分散减少流水线(scatter-reduce)</h4><p><img src="/../assets/serverless_ai/YxGabeGbUod133xwYIicvqBon79.png"></p><ul><li><p>流水线存储的分散减少算法</p><ul><li>将梯度划分为 n 个分割，利用所有 worker 的计算资源进行梯度聚合，那么每个 worker 符合合并一个 split</li><li>三个阶段<ul><li>每个 worker 将其他 worker 负责的 n-1 个梯度分割上传到存储</li><li>第 i 个 worker 将其他 worker 上传的第 i 个 Worker 聚合并计算聚合后的梯度</li><li>每个 worker 上传合并后的分割并计算所有其他合并的分割</li></ul></li></ul></li><li><p>改进后的分散减少算法</p><ul><li>n 个步骤<ul><li>第 1 步，第 i 个 worker 上传 i+1 分割</li><li>第 k 步，第 i 个 worker 上传 i+k 分割，并下载 i-(k-1)</li><li>第 n 步，第 i 个 worker 已经上传了所有分割，并且从下一个 worker 获得梯度</li></ul></li></ul></li></ul><h4 id="模型划分与资源分配的协同优化"><a href="#模型划分与资源分配的协同优化" class="headerlink" title="模型划分与资源分配的协同优化"></a>模型划分与资源分配的协同优化</h4><p>（没看懂）</p><h3 id="系统实现"><a href="#系统实现" class="headerlink" title="系统实现"></a>系统实现</h3><ul><li><p>管道任务堆叠：通过 DAG 图保证数据并行</p><ul><li>不同类型的任务用不同的资源需求</li><li>将他们组合成一个 DAG 并通过任务执行器进行管理</li><li>每个节点都有一个 ID 并且有一堆依赖的节点 ID，当依赖资源满足时可以保证恰好一次进行</li></ul></li><li><p>基于存储的通信</p><ul><li>不同分区的发送和接受</li><li>分区副本之间的分散减少</li><li>通信使用 Python pickle 序列化并上传到存储桶</li></ul></li><li><p>局限性</p><ul><li>单个层次内存过大会把 Serverless 函数弄爆</li><li>可能得解决方案是张量并行</li><li>使用张量并行性增加了所提出的协同优化方法的复杂性，因为额外的决策维度极大地扩展了搜索空间</li></ul></li></ul><h3 id="部分代码实现"><a href="#部分代码实现" class="headerlink" title="部分代码实现"></a>部分代码实现</h3><p><img src="/../assets/serverless_ai/IcO8btF5zol6Bex960XcWQyFnxh.png"></p><p><img src="/../assets/serverless_ai/DtNBbLlA0oOhSKxkIKwcUGIen0c.png"></p><h2 id="ElasticFlow-An-Elastic-Serverless-Training-Platform-for-Distributed-Deep-Learning"><a href="#ElasticFlow-An-Elastic-Serverless-Training-Platform-for-Distributed-Deep-Learning" class="headerlink" title="ElasticFlow: An Elastic Serverless Training Platform for Distributed Deep Learning"></a><a href="https://dl.acm.org/doi/10.1145/3575693.3575721">ElasticFlow: An Elastic Serverless Training Platform for Distributed Deep Learning</a></h2><h3 id="解决问题-4"><a href="#解决问题-4" class="headerlink" title="解决问题"></a>解决问题</h3><ul><li><p>一个用于深度学习的弹性的 Serverless 训练平台</p><ul><li>用户只需要指定作业的深度神经网络模型和超参数，无需指定 GPU 的数量</li><li>用户指定作业的 ddl，但不指定占用 GPU 的时间量</li></ul></li><li></li></ul>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Serverless</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ray 学习笔记</title>
    <link href="/2025/07/20/ray/"/>
    <url>/2025/07/20/ray/</url>
    
    <content type="html"><![CDATA[<h1 id="Ray-学习笔记"><a href="#Ray-学习笔记" class="headerlink" title="Ray 学习笔记"></a>Ray 学习笔记</h1><h1 id="Ray-概述"><a href="#Ray-概述" class="headerlink" title="Ray 概述"></a>Ray 概述</h1><p>Ray 是一个用于扩展 AI 和 Python 应用程序（如机器学习）的开源统一框架。它提供了并行处理的计算层，因此您无需成为分布式系统专家。Ray 通过以下组件，最小化了运行分布式个体和端到端机器学习工作流的复杂性：</p><ul><li>为常见的机器学习任务（如数据预处理、分布式训练、超参数调整、强化学习和模型服务）提供可扩展的库。</li><li>用于并行化和扩展 Python 应用程序的 Pythonic 分布式计算基元。</li><li>用于与现有工具和基础设施（如 Kubernetes、AWS、GCP 和 Azure）集成和部署 Ray 集群的集成工具和实用程序。</li></ul><p>对于数据科学家和机器学习从业者来说，Ray 让您无需基础设施专业知识就能扩展作业：</p><ul><li>轻松地在多个节点和 GPU 上并行化和分布 ML 工作负载。</li><li>利用 ML 生态系统，具有原生和可扩展的集成。</li></ul><p>对于 ML 平台构建者和 ML 工程师，Ray：</p><ul><li>提供了创建可扩展且健壮的 ML 平台的计算抽象。</li><li>提供了简化上手和与更广泛的 ML 生态系统集成的统一 ML API。</li><li>通过使相同的 Python 代码能够从笔记本电脑无缝扩展到大型集群，减少了开发与生产之间的摩擦。</li></ul><p>对于分布式系统工程师，Ray 自动处理关键过程：</p><ul><li>编排——管理分布式系统的各种组件。</li><li>调度——协调任务执行的时间和地点。</li><li>容错——确保任务完成，不管不可避免的故障点。</li><li>自动扩展——根据动态需求调整分配的资源数量。</li></ul><h1 id="Ray-安装"><a href="#Ray-安装" class="headerlink" title="Ray 安装"></a>Ray 安装</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install -U <span class="hljs-string">&quot;ray[data,train,tune,serve]&quot;</span><br></code></pre></td></tr></table></figure><h1 id="Ray-核心组件"><a href="#Ray-核心组件" class="headerlink" title="Ray 核心组件"></a>Ray 核心组件</h1><ul><li><p>Ray Core：提供了一些核心组件构造可扩展的分布式应用</p></li><li><p>Ray Data：一个可扩展的用户 ML 训练的数据处理库</p></li><li><p>Ray Train：一个可扩展的 ML 训练库，用于支撑分布式训练以及参数微调</p><ul><li>可扩展：将模型从单一机器扩展到集群</li><li>抽象性：忽略了分布式计算的复杂性</li><li>适用方面：大模型以及大型数据集</li></ul></li><li><p>Ray Tune：用于参数微调</p></li><li><p>Ray Serve：一个可扩展的模型服务库，用于构建在线推理 API</p></li><li><p>Ray RLlib：一个用于强化学习（RL）的库</p></li><li><p>Ray Clusters：一系列连接着 Ray head node 的 worker 节点，集群可扩展</p></li></ul><h2 id="Ray-Core"><a href="#Ray-Core" class="headerlink" title="Ray Core"></a>Ray Core</h2><h3 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h3><ul><li><p>Task：无状态的 Worker</p><ul><li>Ray 允许任意的函数在分离的 python worker 上执行</li><li>可以明确资源需求（CPUs, GPUs）</li></ul></li><li><p>Actor：有状态的 Worker</p><ul><li>可以让函数访问其对应的 worker 的变量</li><li>也可以明确资源需求</li></ul></li><li><p>Object：Task 以及 Worker 都是在 Object 上计算的</p><ul><li>可以在任意的 Ray 集群中存储</li><li>可以被引用</li><li>远程 Object 被缓存在 Ray 的分布式共享内存存储中</li></ul></li><li><p>Placement Groups：允许用户管原子性地管理组资源</p><ul><li>可以计划 Ray 的 Task 以及 Actor</li></ul></li></ul><h3 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h3><h4 id="remote-函数"><a href="#remote-函数" class="headerlink" title="remote 函数"></a><code>remote</code> 函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@ray.remote</span><br></code></pre></td></tr></table></figure><p><code>./_private/worker.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@PublicAPI</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">remote</span>(<span class="hljs-params"></span><br><span class="hljs-params">    *args, **kwargs</span><br><span class="hljs-params"></span>) -&gt; <span class="hljs-type">Union</span>[ray.remote_function.RemoteFunction, ray.actor.ActorClass]:<br>    <span class="hljs-comment"># &quot;callable&quot; returns true for both function and class.</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(args) == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(kwargs) == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">callable</span>(args[<span class="hljs-number">0</span>]):<br>        <span class="hljs-comment"># This is the case where the decorator is just @ray.remote.</span><br>        <span class="hljs-comment"># &quot;args[0]&quot; is the class or function under the decorator.</span><br>        <span class="hljs-keyword">return</span> _make_remote(args[<span class="hljs-number">0</span>], &#123;&#125;)<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(args) == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(kwargs) &gt; <span class="hljs-number">0</span>, ray_option_utils.remote_args_error_string<br>    <span class="hljs-keyword">return</span> functools.partial(_make_remote, options=kwargs)<br></code></pre></td></tr></table></figure><p><code>./_private/worker.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_remote</span>(<span class="hljs-params">function_or_class, options</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> function_or_class.__module__:<br>        function_or_class.__module__ = <span class="hljs-string">&quot;global&quot;</span><br><br>    <span class="hljs-keyword">if</span> inspect.isfunction(function_or_class) <span class="hljs-keyword">or</span> is_cython(function_or_class):<br>        ray_option_utils.validate_task_options(options, in_options=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">return</span> ray.remote_function.RemoteFunction(<br>            Language.PYTHON,<br>            function_or_class,<br>            <span class="hljs-literal">None</span>,<br>            options,<br>        )<br><br>    <span class="hljs-keyword">if</span> inspect.isclass(function_or_class):<br>        ray_option_utils.validate_actor_options(options, in_options=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">return</span> ray.actor._make_actor(function_or_class, options)<br><br>    <span class="hljs-keyword">raise</span> TypeError(<br>        <span class="hljs-string">&quot;The @ray.remote decorator must be applied to either a function or a class.&quot;</span><br>    )<br></code></pre></td></tr></table></figure><p><code>./remote_function.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">RemoteFunction</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        language,</span><br><span class="hljs-params">        function,</span><br><span class="hljs-params">        function_descriptor,</span><br><span class="hljs-params">        task_options,</span><br><span class="hljs-params">    </span>):<br>        ...<br>        <span class="hljs-comment"># Override task.remote&#x27;s signature and docstring</span><br><span class="hljs-meta">        @wraps(<span class="hljs-params">function</span>)</span><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">_remote_proxy</span>(<span class="hljs-params">*args, **kwargs</span>):<br>            <span class="hljs-keyword">return</span> self._remote(args=args, kwargs=kwargs, **self._default_options)<br><br>        self.remote = _remote_proxy<br></code></pre></td></tr></table></figure><p>因此对于 <code>remote</code> 装饰器的请求，其内部流程大体如下</p><ul><li><code>remote</code> 函数接收类或者函数作为参数</li><li><code>_make_remote</code> 函数将其封装为类 <code>RemoteFunction</code></li><li><code>RemoteFunction</code> 里头有 <code>self.remote</code> 属性，存放传入的函数 <code>f</code></li><li><code>f.remote</code> 调用原来的方法</li></ul><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><h4 id="基于-Task-的批量预测"><a href="#基于-Task-的批量预测" class="headerlink" title="基于 Task 的批量预测"></a>基于 Task 的批量预测</h4><p>通过 Ray 的 Task，可以构建一个批处理预测程序，大概分为三个步骤</p><ul><li>加载模型</li><li>部署 Ray Task，每一个 Task 包含了模型以及共享的输入数据集</li><li>每一个 worker 都在被分配的分片上执行预测，并输出结果</li></ul><p>假设我们有这样一个简单的模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_model</span>():<br>    <span class="hljs-comment"># A dummy model.</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">model</span>(<span class="hljs-params">batch: pd.DataFrame</span>) -&gt; pd.DataFrame:<br>        <span class="hljs-comment"># Dummy payload so copying the model will actually copy some data</span><br>        <span class="hljs-comment"># across nodes.</span><br>        model.payload = np.zeros(<span class="hljs-number">100_000_000</span>)<br>        <span class="hljs-keyword">return</span> pd.DataFrame(&#123;<span class="hljs-string">&quot;score&quot;</span>: batch[<span class="hljs-string">&quot;passenger_count&quot;</span>] % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>&#125;)<br>    <br>    <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></table></figure><p>为每个 worker 分配 Task</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pyarrow.parquet <span class="hljs-keyword">as</span> pq<br><span class="hljs-keyword">import</span> ray<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_prediction</span>(<span class="hljs-params">model, shard_path</span>):<br>    df = pq.read_table(shard_path).to_pandas()<br>    result = model(df)<br><br>    <span class="hljs-comment"># Write out the prediction result.</span><br>    <span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> unless the driver will have to further process the</span><br>    <span class="hljs-comment"># result (other than simply writing out to storage system),</span><br>    <span class="hljs-comment"># writing out at remote task is recommended, as it can avoid</span><br>    <span class="hljs-comment"># congesting or overloading the driver.</span><br>    <span class="hljs-comment"># ...</span><br><br>    <span class="hljs-comment"># Here we just return the size about the result in this example.</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(result)<br></code></pre></td></tr></table></figure><p>驱动程序负责管理所有的 Tasks</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 12 files, one for each remote task.</span><br>input_files = [<br>        <span class="hljs-string">f&quot;s3://anonymous@air-example-data/ursa-labs-taxi-data/downsampled_2009_full_year_data.parquet&quot;</span><br>        <span class="hljs-string">f&quot;/fe41422b01c04169af2a65a83b753e0f_<span class="hljs-subst">&#123;i:06d&#125;</span>.parquet&quot;</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">12</span>)<br>]<br><br><span class="hljs-comment"># ray.put() the model just once to local object store, and then pass the</span><br><span class="hljs-comment"># reference to the remote tasks.</span><br>model = load_model()<br>model_ref = ray.put(model)<br><br>result_refs = []<br><br><span class="hljs-comment"># Launch all prediction tasks.</span><br><span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> input_files:<br>    <span class="hljs-comment"># Launch a prediction task by passing model reference and shard file to it.</span><br>    <span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> it would be highly inefficient if you are passing the model itself</span><br>    <span class="hljs-comment"># like make_prediction.remote(model, file), which in order to pass the model</span><br>    <span class="hljs-comment"># to remote node will ray.put(model) for each task, potentially overwhelming</span><br>    <span class="hljs-comment"># the local object store and causing out-of-disk error.</span><br>    result_refs.append(make_prediction.remote(model_ref, file))<br><br>results = ray.get(result_refs)<br><br><span class="hljs-comment"># Let&#x27;s check prediction output size.</span><br><span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> results:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Prediction output size:&quot;</span>, r)<br></code></pre></td></tr></table></figure><p><img src="/../assets/ray/Xu3vbaalIo7AlixmWnvc0sRgnRg.png"></p><p><img src="/../assets/ray/XEoOb1oxEoMobuxs84JcT6bPn3b.png"></p><h4 id="基于-Actor-的批量预测"><a href="#基于-Actor-的批量预测" class="headerlink" title="基于 Actor 的批量预测"></a>基于 Actor 的批量预测</h4><p>上述基于 Tasks 的批量预测算法中，每个 Task 必须从驱动节点获取模型才能开启预测，如果模型很大这将是一个很大的开销。我们通过 Ray Actor 的方式，只需要加载一次模型就能够复用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> pyarrow.parquet <span class="hljs-keyword">as</span> pq<br><span class="hljs-keyword">import</span> ray<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BatchPredictor</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model</span>):<br>        self.model = model<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, shard_path</span>):<br>        df = pq.read_table(shard_path).to_pandas()<br>        result =self.model(df)<br><br>        <span class="hljs-comment"># Write out the prediction result.</span><br>        <span class="hljs-comment"># <span class="hljs-doctag">NOTE:</span> unless the driver will have to further process the</span><br>        <span class="hljs-comment"># result (other than simply writing out to storage system),</span><br>        <span class="hljs-comment"># writing out at remote task is recommended, as it can avoid</span><br>        <span class="hljs-comment"># congesting or overloading the driver.</span><br>        <span class="hljs-comment"># ...</span><br><br>        <span class="hljs-comment"># Here we just return the size about the result in this example.</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(result)<br></code></pre></td></tr></table></figure><p>构造函数只会在每个 Worker 被调用一次，我们使用 <code>ActorPool</code> 库来接收预测请求</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> ray.util.actor_pool <span class="hljs-keyword">import</span> ActorPool<br><br>model = load_model()<br>model_ref = ray.put(model)<br>num_actors = <span class="hljs-number">4</span><br>actors = [BatchPredictor.remote(model_ref) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_actors)]<br>pool = ActorPool(actors)<br>input_files = [<br>        <span class="hljs-string">f&quot;s3://anonymous@air-example-data/ursa-labs-taxi-data/downsampled_2009_full_year_data.parquet&quot;</span><br>        <span class="hljs-string">f&quot;/fe41422b01c04169af2a65a83b753e0f_<span class="hljs-subst">&#123;i:06d&#125;</span>.parquet&quot;</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">12</span>)<br>]<br><span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> input_files:<br>    pool.submit(<span class="hljs-keyword">lambda</span> a, v: a.predict.remote(v), file)<br><span class="hljs-keyword">while</span> pool.has_next():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Prediction output size:&quot;</span>, pool.get_next())<br></code></pre></td></tr></table></figure><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><ul><li>对于大模型的加载，应当传递的是模型引用而不是模型本身，<code>ray</code> 提供了 <code>ray.put(model)</code> 传递模型引用</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># GOOD: the model will be stored to driver&#x27;s object store only once</span><br>model = load_model()<br>model_ref = ray.put(model)<br><span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> input_files:<br>    make_prediction.remote(model_ref, file)<br><br><span class="hljs-comment"># BAD: the same model will be stored to driver&#x27;s object store repeatedly for each task</span><br>model = load_model()<br><span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> input_files:<br>    make_prediction.remote(model, file)<br></code></pre></td></tr></table></figure><h2 id="Ray-Train"><a href="#Ray-Train" class="headerlink" title="Ray Train"></a>Ray Train</h2><ul><li>训练函数：包含了训练逻辑的 Python 代码</li><li>Worker：一个运行了训练函数的进程</li><li>可扩展配置：对于 Worker 的配置以及计算资源的配置</li><li>训练器：将上述三个概念打包起来构建一个分布式训练任务</li></ul><p><img src="/../assets/ray/FbZTbh6NXorjG1xQBmtc1RmnnRg.png"></p><h3 id="编程模型-1"><a href="#编程模型-1" class="headerlink" title="编程模型"></a>编程模型</h3><h4 id="Trainer"><a href="#Trainer" class="headerlink" title="Trainer"></a>Trainer</h4><p><code>trainer</code> 会构建一个 <code>TorchTriainer</code>，当调用 <code>trainer.fit</code> 的时候，会构建 <code>Actor</code> 自动部署；其实在 <code>dataset</code> 的时候也部署了一个 <code>Actor</code></p><p><img src="/../assets/ray/HQDHboqcyo6aVKxssuEcrJ5Ynjb.png"></p><p>从调用堆栈可以看出，最后会调用到 <code>actor_manager.py</code>。</p><p>经过我花费了 2 个小时的分析，其训练器训练函数的大体流程如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># main.py</span><br>trainer.fit()<br><br><span class="hljs-comment"># base_trainer.py</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BaseTrainer</span>(abc.ABC):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self</span>) -&gt; Result:<br>        ...<br>        <span class="hljs-keyword">try</span>:<br>            **result_grid = tuner.fit()**<br>        <span class="hljs-keyword">except</span>:<br>            ...<br>        result = result_grid[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">return</span> result<br>        <br><span class="hljs-comment"># ray/tune/tuner.py</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tuner</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self</span>) -&gt; ResultGrid:<br>        ...<br>**        <span class="hljs-keyword">return</span> self._local_tuner.fit()**<br><br><span class="hljs-comment"># ray/tune/impl/tuner_internal.py</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TunerInternal</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self</span>) -&gt; ResultGrid:<br>**        analysis = self._fit_internal(trainable, param_space)**<br>        <span class="hljs-keyword">return</span> ResultGrid(analysis)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_fit_internal</span>(<span class="hljs-params">self, trainable: TrainableType, param_space: <span class="hljs-type">Optional</span>[<span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>,<span class="hljs-type">Any</span>]] -&gt; ExperimentAnalysis:</span><br><span class="hljs-params">        ...</span><br><span class="hljs-params">        analysis = run(<span class="hljs-params">**args</span>)</span><br><span class="hljs-params">        <span class="hljs-keyword">return</span> analysis</span><br><span class="hljs-params">        </span><br><span class="hljs-params"><span class="hljs-comment"># ray/tune/tune.py</span></span><br><span class="hljs-params"><span class="hljs-keyword">def</span> run(<span class="hljs-params"></span>):</span><br><span class="hljs-params">    ...</span><br><span class="hljs-params">    <span class="hljs-keyword">try</span>:</span><br><span class="hljs-params">        <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> runner.is_finished(<span class="hljs-params"></span>) <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> experiment_interrupted_event.is_set(<span class="hljs-params"></span>):</span><br><span class="hljs-params">            **runner.step(<span class="hljs-params"></span>)**</span><br><span class="hljs-params">            <span class="hljs-keyword">if</span> has_verbosity(<span class="hljs-params">Verbosity.V1_EXPERIMENT</span>):</span><br><span class="hljs-params">                _report_progress(<span class="hljs-params">runner, progress_reporter</span>)</span><br><span class="hljs-params"></span><br><span class="hljs-params">            <span class="hljs-keyword">if</span> air_verbosity <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:</span><br><span class="hljs-params">                _report_air_progress(<span class="hljs-params">runner, air_progress_reporter</span>)</span><br><span class="hljs-params">    <span class="hljs-keyword">except</span> Exception:</span><br><span class="hljs-params">        runner.cleanup(<span class="hljs-params"></span>)</span><br><span class="hljs-params">        <span class="hljs-keyword">raise</span></span><br><span class="hljs-params">    ...</span><br><span class="hljs-params">    </span><br><span class="hljs-params"> <span class="hljs-comment"># ray/tune/execution/tune_controller.py</span></span><br><span class="hljs-params"> <span class="hljs-keyword">class</span> TuneController:</span><br><span class="hljs-params">     <span class="hljs-keyword">def</span> step(<span class="hljs-params">self</span>):</span><br><span class="hljs-params">        ...</span><br><span class="hljs-params">        <span class="hljs-comment"># Start actors for added trials</span></span><br><span class="hljs-params">        self._maybe_add_actors(<span class="hljs-params"></span>)</span><br><span class="hljs-params"></span><br><span class="hljs-params">        <span class="hljs-comment"># Handle one event</span></span><br><span class="hljs-params">        **<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self._actor_manager.<span class="hljs-built_in">next</span>(<span class="hljs-params">timeout=<span class="hljs-number">0.1</span></span>):**</span><br><span class="hljs-params">            <span class="hljs-comment"># If there are no actors running, warn about potentially</span></span><br><span class="hljs-params">            <span class="hljs-comment"># insufficient resources</span></span><br><span class="hljs-params">            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self._actor_manager.num_live_actors:</span><br><span class="hljs-params">                self._insufficient_resources_manager.on_no_available_trials(<span class="hljs-params"></span></span><br><span class="hljs-params"><span class="hljs-params">                    self.get_trials(<span class="hljs-params"></span>)</span></span><br><span class="hljs-params"><span class="hljs-params">                </span>)</span><br><span class="hljs-params"></span><br><span class="hljs-params">        ...</span><br><span class="hljs-params">        </span><br><span class="hljs-params"><span class="hljs-comment"># ray/air/execution/_internal/actor_manager.py</span></span><br><span class="hljs-params"><span class="hljs-keyword">class</span> RayActorManager:</span><br><span class="hljs-params">    <span class="hljs-keyword">def</span> <span class="hljs-built_in">next</span>(<span class="hljs-params">self, timeout: <span class="hljs-type">Optional</span>[<span class="hljs-type">Union</span>[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">float</span>]] = <span class="hljs-literal">None</span></span>) -&gt; <span class="hljs-built_in">bool</span>:</span><br><span class="hljs-params">        ...</span><br><span class="hljs-params"></span><br><span class="hljs-params">        <span class="hljs-comment"># We always try to start actors as this won&#x27;t trigger an event callback</span></span><br><span class="hljs-params">        self._try_start_actors(<span class="hljs-params"></span>)</span><br><span class="hljs-params"></span><br><span class="hljs-params">        ...</span><br><span class="hljs-params">        self._try_start_actors(<span class="hljs-params"></span>)</span><br><span class="hljs-params">        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span></span><br><span class="hljs-params">        </span><br><span class="hljs-params">    <span class="hljs-keyword">def</span> _try_start_actors(<span class="hljs-params">self, max_actors: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span></span>) -&gt; <span class="hljs-built_in">int</span>:</span><br><span class="hljs-params">        ...</span><br><span class="hljs-params">                <span class="hljs-comment"># Start Ray actor</span></span><br><span class="hljs-params">                **actor = remote_actor_cls.remote(<span class="hljs-params">**kwargs</span>)**</span><br><span class="hljs-params"></span><br><span class="hljs-params">                ...</span><br><span class="hljs-params"></span><br><span class="hljs-params">        <span class="hljs-keyword">return</span> started_actors</span><br><span class="hljs-params"></span><br><span class="hljs-params"><span class="hljs-comment"># ray/actor.py</span></span><br><span class="hljs-params"><span class="hljs-keyword">class</span> ActorClass:</span><br><span class="hljs-params">    <span class="hljs-keyword">def</span> options(<span class="hljs-params">self, **actor_options</span>):</span><br><span class="hljs-params">        <span class="hljs-keyword">class</span> ActorOptionWrapper:</span><br><span class="hljs-params">            <span class="hljs-keyword">def</span> remote(<span class="hljs-params">self, *args, **kwargs</span>):</span><br><span class="hljs-params">                <span class="hljs-keyword">return</span> actor_cls._remote(<span class="hljs-params">args=args, kwargs=kwargs, **updated_options</span>)</span><br></code></pre></td></tr></table></figure><h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><h4 id="数据加载与预处理"><a href="#数据加载与预处理" class="headerlink" title="数据加载与预处理"></a>数据加载与预处理</h4><p>Ray Train 集成了用于数据加载与预处理的库。</p><p>数据迁移可以通过以下四个基本步骤执行</p><ul><li>创建一个 Ray 数据集</li><li>预处理 Ray 数据集</li><li>将预处理好的 Ray 数据集输入到 Ray Train 训练器中</li><li>通过 <code>Train Function</code> 消费数据集</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> ray<br><span class="hljs-keyword">from</span> ray <span class="hljs-keyword">import</span> train<br><span class="hljs-keyword">from</span> ray.train <span class="hljs-keyword">import</span> Checkpoint, ScalingConfig<br><span class="hljs-keyword">from</span> ray.train.torch <span class="hljs-keyword">import</span> TorchTrainer<br><br><span class="hljs-comment"># Set this to True to use GPU.</span><br><span class="hljs-comment"># If False, do CPU training instead of GPU training.</span><br>use_gpu = <span class="hljs-literal">False</span><br><br><span class="hljs-comment"># Step 1: Create a Ray Dataset from in-memory Python lists.</span><br><span class="hljs-comment"># You can also create a Ray Dataset from many other sources and file</span><br><span class="hljs-comment"># formats.</span><br>train_dataset = ray.data.from_items([&#123;<span class="hljs-string">&quot;x&quot;</span>: [x], <span class="hljs-string">&quot;y&quot;</span>: [<span class="hljs-number">2</span> * x]&#125; <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>)])<br><br><span class="hljs-comment"># Step 2: Preprocess your Ray Dataset.</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">increment</span>(<span class="hljs-params">batch</span>):<br>    batch[<span class="hljs-string">&quot;y&quot;</span>] = batch[<span class="hljs-string">&quot;y&quot;</span>] + <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> batch<br><br>train_dataset = train_dataset.map_batches(increment)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_func</span>(<span class="hljs-params">config</span>):<br>    batch_size = <span class="hljs-number">16</span><br><br>    <span class="hljs-comment"># Step 4: Access the dataset shard for the training worker via</span><br>    <span class="hljs-comment"># ``get_dataset_shard``.</span><br>    train_data_shard = train.get_dataset_shard(<span class="hljs-string">&quot;train&quot;</span>)<br>    train_dataloader = train_data_shard.iter_torch_batches(<br>        batch_size=batch_size, dtypes=torch.float32<br>    )<br><br>    <span class="hljs-keyword">for</span> epoch_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:<br>            inputs, labels = batch[<span class="hljs-string">&quot;x&quot;</span>], batch[<span class="hljs-string">&quot;y&quot;</span>]<br>            <span class="hljs-keyword">assert</span> <span class="hljs-built_in">type</span>(inputs) == torch.Tensor<br>            <span class="hljs-keyword">assert</span> <span class="hljs-built_in">type</span>(labels) == torch.Tensor<br>            <span class="hljs-keyword">assert</span> inputs.shape[<span class="hljs-number">0</span>] == batch_size<br>            <span class="hljs-keyword">assert</span> labels.shape[<span class="hljs-number">0</span>] == batch_size<br>            <span class="hljs-keyword">break</span> <span class="hljs-comment"># Only check one batch. Last batch can be partial.</span><br><br><span class="hljs-comment"># Step 3: Create a TorchTrainer. Specify the number of training workers and</span><br><span class="hljs-comment"># pass in your Ray Dataset.</span><br><span class="hljs-comment"># The Ray Dataset is automatically split across all training workers.</span><br>trainer = TorchTrainer(<br>    train_func,<br>    datasets=&#123;<span class="hljs-string">&quot;train&quot;</span>: train_dataset&#125;,<br>    scaling_config=ScalingConfig(num_workers=<span class="hljs-number">2</span>, use_gpu=use_gpu)<br>)<br>result = trainer.fit()<br></code></pre></td></tr></table></figure><h4 id="配置持久化存储"><a href="#配置持久化存储" class="headerlink" title="配置持久化存储"></a>配置持久化存储</h4><p>Ray Train 运行会生成报告指标、检查点和其他工件的历史记录。您可以将它们配置为保存到持久存储位置。</p><p><img src="/../assets/ray/Q9GWbgQDvodZdBxPq5DcVGGpnOd.png"></p><p>持久化存储能够</p><ul><li>做标记点以及容错：从持久化存储系统保存标记可以从上一次节点故障的检查点恢复</li><li>实验后分析：存储所有试验数据的统一位置对于实验后分析非常有用，例如在集群终止后访问最佳检查点和超参数配置</li><li>通过下游服务和批量推理任务桥接训练&#x2F;微调：您可以轻松访问模型和工件以与其他人共享或在下游任务中使用它们。</li></ul><h4 id="保存加载检查点"><a href="#保存加载检查点" class="headerlink" title="保存加载检查点"></a>保存加载检查点</h4><p>Ray Train 提供了一个快照训练过程的进程</p><ul><li>储存性能最后的模型比重：将模型保存到持久化存储中</li><li>容错：让长时运行工作从节点错误中恢复</li><li>分布式检查点：当进行模型并行训练时，Ray Train 检查点提供了一个简单的方法用于更新模型分片，而不是将整个模型集中到单节点</li><li>与 Ray Tune 集成</li></ul><h4 id="MNIST"><a href="#MNIST" class="headerlink" title="MNIST"></a>MNIST</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Dict</span><br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> filelock <span class="hljs-keyword">import</span> FileLock<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms<br><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> Normalize, ToTensor<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-keyword">import</span> ray.train<br><span class="hljs-keyword">from</span> ray.train <span class="hljs-keyword">import</span> ScalingConfig<br><span class="hljs-keyword">from</span> ray.train.torch <span class="hljs-keyword">import</span> TorchTrainer<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataloaders</span>(<span class="hljs-params">batch_size</span>):<br>    <span class="hljs-comment"># Transform to normalize the input images</span><br>    transform = transforms.Compose([ToTensor(), Normalize((<span class="hljs-number">0.5</span>,), (<span class="hljs-number">0.5</span>,))])<br><br>    <span class="hljs-keyword">with</span> FileLock(os.path.expanduser(<span class="hljs-string">&quot;~/data.lock&quot;</span>)):<br>        <span class="hljs-comment"># Download training data from open datasets</span><br>        training_data = datasets.FashionMNIST(<br>            root=<span class="hljs-string">&quot;~/data&quot;</span>,<br>            train=<span class="hljs-literal">True</span>,<br>            download=<span class="hljs-literal">True</span>,<br>            transform=transform,<br>        )<br><br>        <span class="hljs-comment"># Download test data from open datasets</span><br>        test_data = datasets.FashionMNIST(<br>            root=<span class="hljs-string">&quot;~/data&quot;</span>,<br>            train=<span class="hljs-literal">False</span>,<br>            download=<span class="hljs-literal">True</span>,<br>            transform=transform,<br>        )<br><br>    <span class="hljs-comment"># Create data loaders</span><br>    train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br>    test_dataloader = DataLoader(test_data, batch_size=batch_size)<br><br>    <span class="hljs-keyword">return</span> train_dataloader, test_dataloader<br><br><br><span class="hljs-comment"># Model Definition</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">NeuralNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(NeuralNetwork, self).__init__()<br>        self.flatten = nn.Flatten()<br>        self.linear_relu_stack = nn.Sequential(<br>            nn.Linear(<span class="hljs-number">28</span> * <span class="hljs-number">28</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Dropout(<span class="hljs-number">0.25</span>),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Dropout(<span class="hljs-number">0.25</span>),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">10</span>),<br>            nn.ReLU(),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.flatten(x)<br>        logits = self.linear_relu_stack(x)<br>        <span class="hljs-keyword">return</span> logits<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_func_per_worker</span>(<span class="hljs-params">config: <span class="hljs-type">Dict</span></span>):<br>    lr = config[<span class="hljs-string">&quot;lr&quot;</span>]<br>    epochs = config[<span class="hljs-string">&quot;epochs&quot;</span>]<br>    batch_size = config[<span class="hljs-string">&quot;batch_size_per_worker&quot;</span>]<br><br>    <span class="hljs-comment"># Get dataloaders inside the worker training function</span><br>    train_dataloader, test_dataloader = get_dataloaders(batch_size=batch_size)<br><br>    <span class="hljs-comment"># [1] Prepare Dataloader for distributed training</span><br>    <span class="hljs-comment"># Shard the datasets among workers and move batches to the correct device</span><br>    <span class="hljs-comment"># =======================================================================</span><br>    train_dataloader = ray.train.torch.prepare_data_loader(train_dataloader)<br>    test_dataloader = ray.train.torch.prepare_data_loader(test_dataloader)<br><br>    model = NeuralNetwork()<br><br>    <span class="hljs-comment"># [2] Prepare and wrap your model with DistributedDataParallel</span><br>    <span class="hljs-comment"># Move the model to the correct GPU/CPU device</span><br>    <span class="hljs-comment"># ============================================================</span><br>    model = ray.train.torch.prepare_model(model)<br><br>    loss_fn = nn.CrossEntropyLoss()<br>    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=<span class="hljs-number">0.9</span>)<br><br>    <span class="hljs-comment"># Model training loop</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        <span class="hljs-keyword">if</span> ray.train.get_context().get_world_size() &gt; <span class="hljs-number">1</span>:<br>            <span class="hljs-comment"># Required for the distributed sampler to shuffle properly across epochs.</span><br>            train_dataloader.sampler.set_epoch(epoch)<br><br>        model.train()<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> tqdm(train_dataloader, desc=<span class="hljs-string">f&quot;Train Epoch <span class="hljs-subst">&#123;epoch&#125;</span>&quot;</span>):<br>            pred = model(X)<br>            loss = loss_fn(pred, y)<br><br>            optimizer.zero_grad()<br>            loss.backward()<br>            optimizer.step()<br><br>        model.<span class="hljs-built_in">eval</span>()<br>        test_loss, num_correct, num_total = <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> tqdm(test_dataloader, desc=<span class="hljs-string">f&quot;Test Epoch <span class="hljs-subst">&#123;epoch&#125;</span>&quot;</span>):<br>                pred = model(X)<br>                loss = loss_fn(pred, y)<br><br>                test_loss += loss.item()<br>                num_total += y.shape[<span class="hljs-number">0</span>]<br>                num_correct += (pred.argmax(<span class="hljs-number">1</span>) == y).<span class="hljs-built_in">sum</span>().item()<br><br>        test_loss /= <span class="hljs-built_in">len</span>(test_dataloader)<br>        accuracy = num_correct / num_total<br><br>        <span class="hljs-comment"># [3] Report metrics to Ray Train</span><br>        <span class="hljs-comment"># ===============================</span><br>        ray.train.report(metrics=&#123;<span class="hljs-string">&quot;loss&quot;</span>: test_loss, <span class="hljs-string">&quot;accuracy&quot;</span>: accuracy&#125;)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_fashion_mnist</span>(<span class="hljs-params">num_workers=<span class="hljs-number">2</span>, use_gpu=<span class="hljs-literal">False</span></span>):<br>    global_batch_size = <span class="hljs-number">32</span><br><br>    train_config = &#123;<br>        <span class="hljs-string">&quot;lr&quot;</span>: <span class="hljs-number">1e-3</span>,<br>        <span class="hljs-string">&quot;epochs&quot;</span>: <span class="hljs-number">10</span>,<br>        <span class="hljs-string">&quot;batch_size_per_worker&quot;</span>: global_batch_size // num_workers,<br>    &#125;<br><br>    <span class="hljs-comment"># Configure computation resources</span><br>    scaling_config = ScalingConfig(num_workers=num_workers, use_gpu=use_gpu)<br><br>    <span class="hljs-comment"># Initialize a Ray TorchTrainer</span><br>    trainer = TorchTrainer(<br>        train_loop_per_worker=train_func_per_worker,<br>        train_loop_config=train_config,<br>        scaling_config=scaling_config,<br>    )<br><br>    <span class="hljs-comment"># [4] Start distributed training</span><br>    <span class="hljs-comment"># Run `train_func_per_worker` on all workers</span><br>    <span class="hljs-comment"># =============================================</span><br>    result = trainer.fit()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Training result: <span class="hljs-subst">&#123;result&#125;</span>&quot;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    train_fashion_mnist(num_workers=<span class="hljs-number">4</span>, use_gpu=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><ul><li>机器没有 GPU</li></ul><p><img src="/../assets/ray/ZjPtb7jL4oCsrPxx695cgbIhn7c.png"></p><ul><li>使用 CPU</li></ul><p><img src="/../assets/ray/S1O8bVWCvoXX9CxK0d3c2gJdnib.png"></p><p><img src="/../assets/ray/Npwhb1ZWOoAxwPxrCzgcXlOcnvc.png"></p><p><img src="/../assets/ray/WXQkbtT3WoxiyOxMh9FcYENnnJe.png"></p><p><img src="/../assets/ray/HRY8bsoNdo686txUKytcvOuTngf.png"></p><p><img src="/../assets/ray/Kc3cbm5VpoaZ8HxWeMwcFHkOn5c.png"></p><h2 id="Ray-Cluster"><a href="#Ray-Cluster" class="headerlink" title="Ray Cluster"></a>Ray Cluster</h2><h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><p><img src="/../assets/ray/HkAOb5DcAowy0uxM2lkcWFl8nfe.png"></p><ul><li>Ray Cluster: 包含了一个 head 节点以及多个 worker 节点</li><li>head 节点：与 worker 节点不同，它还运行着一个全局控制存储以及自动扩缩容以及驱动进程</li><li>worker 节点：只负责管理 tasks 以及 actors</li><li>Ray autoscaler：运行在 head 节点上的一个进程。当资源需求超过了当前的负载，autoscaler 就会创建新的 worker</li><li>Ray Jobs：一套集合了 task、actor 以及 object 的工作流</li></ul><h3 id="部署到-k8s-集群"><a href="#部署到-k8s-集群" class="headerlink" title="部署到 k8s 集群"></a>部署到 k8s 集群</h3><h4 id="KubeRay"><a href="#KubeRay" class="headerlink" title="KubeRay"></a>KubeRay</h4><p>KubeRay 提供了一个简单的 k8s 操作集合，简化了部署在 k8s 上部署 Ray 的流程，有 3 种自定义资源(CRDs)</p><ul><li><p>RayCluster：KubeRay 全程管理集群的生命周期</p></li><li><p>RayJob：将一个 Job 提交到集群</p></li><li><p>RayServce：由两个部分创建起来</p><ul><li>RayCluster</li><li>Ray Serve</li></ul></li></ul><h5 id="Ray-Cluster-1"><a href="#Ray-Cluster-1" class="headerlink" title="Ray Cluster"></a>Ray Cluster</h5><blockquote><p>其实它部署的是 k8s 的一个 service</p></blockquote><p><a href="https://docs.ray.io/en/latest/cluster/kubernetes/getting-started/raycluster-quick-start.html">RayCluster Quickstart — Ray 2.10.0</a></p><ul><li>前提：安装 kubectl, helm</li><li></li></ul><h1 id="Ray-系统架构"><a href="#Ray-系统架构" class="headerlink" title="Ray 系统架构"></a>Ray 系统架构</h1><h2 id="全局控制存储（GCS）"><a href="#全局控制存储（GCS）" class="headerlink" title="全局控制存储（GCS）"></a>全局控制存储（GCS）</h2><h3 id="GCS-客户端"><a href="#GCS-客户端" class="headerlink" title="GCS 客户端"></a>GCS 客户端</h3><h4 id="Accessor"><a href="#Accessor" class="headerlink" title="Accessor"></a>Accessor</h4><ul><li>ActorInfoAccessor：访问 Actor 的信息</li><li>JobInfoAccessor：访问 Job 的信息</li><li>NodeInfoAccessor：访问工作节点的信息</li><li>NodeResourceInfoAccessor：访问工作节点资源的信息</li><li>ErrorInfoAccessor：访问错误信息</li><li>TaskInfoAccessor：访问任务信息</li><li>WorkerInfoAccessor：访问 Worker 的信息</li><li>PlacementGroupInfoAccessor：访问工作组的信息</li><li>InternalKVAccessor：内部 KV 访问</li></ul><h4 id="GlobalStateAccessor"><a href="#GlobalStateAccessor" class="headerlink" title="GlobalStateAccessor"></a>GlobalStateAccessor</h4><h3 id="GCS-服务端"><a href="#GCS-服务端" class="headerlink" title="GCS 服务端"></a>GCS 服务端</h3><h3 id="发布订阅模型"><a href="#发布订阅模型" class="headerlink" title="发布订阅模型"></a>发布订阅模型</h3><h2 id="分级部署调度器"><a href="#分级部署调度器" class="headerlink" title="分级部署调度器"></a>分级部署调度器</h2><h2 id="分布式对象存储"><a href="#分布式对象存储" class="headerlink" title="分布式对象存储"></a>分布式对象存储</h2><h2 id="计算图模型"><a href="#计算图模型" class="headerlink" title="计算图模型"></a>计算图模型</h2><p>Ray 可以通过构建一张任务图进行计算，相当于定义了一个 Job（workflow），实现任务的并行以及体现任务的依赖关系</p><blockquote><p>注意：Ray 里头所有的参数、数据，都是对象存储，也就是说，他们都是引用！！</p></blockquote><ul><li><p>图</p><ul><li>节点<ul><li>数据节点：对象引用，可以给其他任务节点共享</li><li>任务节点：actor or task</li></ul></li><li>边<ul><li>数据边：从任务节点连到数据节点</li><li>控制边：从任务节点连到任务节点</li></ul></li></ul></li><li><p>例子</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> ray<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Actor</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, init_value</span>):<br>        self.i = init_value<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inc</span>(<span class="hljs-params">self, x</span>):<br>        self.i += x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.i<br><br><span class="hljs-meta">@ray.remote</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">combine</span>(<span class="hljs-params">x,y</span>):<br>    <span class="hljs-keyword">return</span> x+y<br><br>a1 = Actor.bind(<span class="hljs-number">10</span>)<br>res = a1.get.bind()<br><span class="hljs-comment"># print(res)</span><br><span class="hljs-comment"># assert ray.get(res.execute()) == 10</span><br><br>a2 = Actor.bind(<span class="hljs-number">10</span>)<br>a1.inc.bind(<span class="hljs-number">2</span>)<br>a1.inc.bind(<span class="hljs-number">4</span>)<br>a2.inc.bind(<span class="hljs-number">6</span>)<br>dag = combine.bind(a1.get.bind(), a2.get.bind())<br><br><span class="hljs-built_in">print</span>(dag)<br><span class="hljs-comment"># assert ray.get(dag.execute()) == 32</span><br></code></pre></td></tr></table></figure><p><img src="/../assets/ray/P0zWbSg5woe47Dx4wugcQTGJnwh.png"></p><details><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><code class="hljs text">(FunctionNode, 22f7de9ad6e545bf9421165c9b0daa2e)(<br>    body=&lt;function combine at 0x7ff1c6bdad40&gt;<br>    args=[<br>        (ClassMethodNode, 28d860ab781e4f4f94e362a923be0e9f)(<br>            body=get()<br>            args=[]<br>            kwargs=&#123;&#125;<br>            options=&#123;&#125;<br>            other_args_to_resolve=&#123;<br>                parent_class_node:    <br>                    (ClassNode, 3f006ec011b54f06af2118f01eaad8d1)(<br>                        body=&lt;class &#x27;__main__._modify_class.&lt;locals&gt;.Class&#x27;&gt;<br>                        args=[<br>                            10, <br>                        ]<br>                        kwargs=&#123;&#125;<br>                        options=&#123;&#125;<br>                        other_args_to_resolve=&#123;&#125;<br>                    )<br>                prev_class_method_call:    <br>                    (ClassMethodNode, c0bfa13f0dd240ab954fa9506e64c1d1)(<br>                        body=inc()<br>                        args=[<br>                            4, <br>                        ]<br>                        kwargs=&#123;&#125;<br>                        options=&#123;&#125;<br>                        other_args_to_resolve=&#123;<br>                            parent_class_node:    <br>                                (ClassNode, 3f006ec011b54f06af2118f01eaad8d1)(<br>                                    body=&lt;class &#x27;__main__._modify_class.&lt;locals&gt;.Class&#x27;&gt;<br>                                    args=[<br>                                        10, <br>                                    ]<br>                                    kwargs=&#123;&#125;<br>                                    options=&#123;&#125;<br>                                    other_args_to_resolve=&#123;&#125;<br>                                )<br>                            prev_class_method_call:    <br>                                (ClassMethodNode, 2b0b97a018db4b4b86c537f12a7b29a7)(<br>                                    body=inc()<br>                                    args=[<br>                                        2, <br>                                    ]<br>                                    kwargs=&#123;&#125;<br>                                    options=&#123;&#125;<br>                                    other_args_to_resolve=&#123;<br>                                        parent_class_node:    <br>                                            (ClassNode, 3f006ec011b54f06af2118f01eaad8d1)(<br>                                                body=&lt;class &#x27;__main__._modify_class.&lt;locals&gt;.Class&#x27;&gt;<br>                                                args=[<br>                                                    10, <br>                                                ]<br>                                                kwargs=&#123;&#125;<br>                                                options=&#123;&#125;<br>                                                other_args_to_resolve=&#123;&#125;<br>                                            )<br>                                        prev_class_method_call:    <br>                                            (ClassMethodNode, 5d4bd2c5d7da46e4981e305a66111bcd)(<br>                                                body=get()<br>                                                args=[]<br>                                                kwargs=&#123;&#125;<br>                                                options=&#123;&#125;<br>                                                other_args_to_resolve=&#123;<br>                                                    parent_class_node:    <br>                                                        (ClassNode, 3f006ec011b54f06af2118f01eaad8d1)(<br>                                                            body=&lt;class &#x27;__main__._modify_class.&lt;locals&gt;.Class&#x27;&gt;<br>                                                            args=[<br>                                                                10, <br>                                                            ]<br>                                                            kwargs=&#123;&#125;<br>                                                            options=&#123;&#125;<br>                                                            other_args_to_resolve=&#123;&#125;<br>                                                        )<br>                                                    prev_class_method_call: None<br>                                                &#125;<br>                                            )<br>                                    &#125;<br>                                )<br>                        &#125;<br>                    )<br>            &#125;<br>        )<br>        (ClassMethodNode, 40f69b66ce6847c5a80753b6a0287bf1)(<br>            body=get()<br>            args=[]<br>            kwargs=&#123;&#125;<br>            options=&#123;&#125;<br>            other_args_to_resolve=&#123;<br>                parent_class_node:    <br>                    (ClassNode, c46160cae7a84e9ba3534c846df006f0)(<br>                        body=&lt;class &#x27;__main__._modify_class.&lt;locals&gt;.Class&#x27;&gt;<br>                        args=[<br>                            10, <br>                        ]<br>                        kwargs=&#123;&#125;<br>                        options=&#123;&#125;<br>                        other_args_to_resolve=&#123;&#125;<br>                    )<br>                prev_class_method_call:    <br>                    (ClassMethodNode, d4b285407bd9409584aef8cad7289c09)(<br>                        body=inc()<br>                        args=[<br>                            6, <br>                        ]<br>                        kwargs=&#123;&#125;<br>                        options=&#123;&#125;<br>                        other_args_to_resolve=&#123;<br>                            parent_class_node:    <br>                                (ClassNode, c46160cae7a84e9ba3534c846df006f0)(<br>                                    body=&lt;class &#x27;__main__._modify_class.&lt;locals&gt;.Class&#x27;&gt;<br>                                    args=[<br>                                        10, <br>                                    ]<br>                                    kwargs=&#123;&#125;<br>                                    options=&#123;&#125;<br>                                    other_args_to_resolve=&#123;&#125;<br>                                )<br>                            prev_class_method_call: None<br>                        &#125;<br>                    )<br>            &#125;<br>        )<br>    ]<br>    kwargs=&#123;&#125;<br>    options=&#123;&#125;<br>    other_args_to_resolve=&#123;&#125;<br>)<br></code></pre></td></tr></table></figure></details>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Serverless</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Serverless 函数编排</title>
    <link href="/2025/07/20/serverless_orchestration/"/>
    <url>/2025/07/20/serverless_orchestration/</url>
    
    <content type="html"><![CDATA[<h1 id="Serverless-函数编排"><a href="#Serverless-函数编排" class="headerlink" title="Serverless 函数编排"></a>Serverless 函数编排</h1><h1 id="系统目标"><a href="#系统目标" class="headerlink" title="系统目标"></a>系统目标</h1><ul><li>构建一套基于事件驱动的有限状态机模型的函数编排系统，可以编排不同云平台上的 Serverless 函数<ul><li>异构平台的标准化<ul><li>支持不同云平台函数的运行时</li><li>支持不同云平台的事件处理</li></ul></li><li>高效执行<ul><li>基于事件驱动的有限状态机模型</li><li>函数并行度优化</li></ul></li><li>简单部署<ul><li>前端：函数式编程</li><li>中端：Workflow 静态图</li><li>后端：运行时组件</li></ul></li></ul></li></ul><h1 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h1><h2 id="有限状态机模型"><a href="#有限状态机模型" class="headerlink" title="有限状态机模型"></a>有限状态机模型</h2><p>使用有限状态机管理触发器</p><h2 id="事件抽象"><a href="#事件抽象" class="headerlink" title="事件抽象"></a>事件抽象</h2><p>事件作为外部输入关系触发器</p><h2 id="函数流"><a href="#函数流" class="headerlink" title="函数流"></a>函数流</h2><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><h2 id="Triggerflow-Trigger-based-orchestration-of-serverless-workflows"><a href="#Triggerflow-Trigger-based-orchestration-of-serverless-workflows" class="headerlink" title="Triggerflow: Trigger-based orchestration of serverless workflows"></a><a href="https://www.sciencedirect.com/science/article/pii/S0167739X21001989">Triggerflow: Trigger-based orchestration of serverless workflows</a></h2><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>现有的云编排系统要么专注于短期运行的工作流程，要么为同步大规模并行作业带来相当大的开销。没有能够对自定义工作流进行可扩展拦截以及优化的开放系统</p><ul><li>短期运行：IBM Composer、Amazon Step Functions Express Workflows</li><li>大开销：Azure Durable Functions、Amazon Step Functions</li></ul><h3 id="工作难点"><a href="#工作难点" class="headerlink" title="工作难点"></a>工作难点</h3><ul><li><p>通过 CEP 规则执行业务流程</p><ul><li>CEP：Complex Event Processing</li></ul></li><li><p>使用触发器做服务工作流编排是可能的但是往往不理想</p><ul><li>有必要为每个步骤创建不同的队列或目录</li><li>触发器不能够一直等到前面多个函数的执行结束</li><li>触发器不适用于错误处理</li></ul></li></ul><h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><ul><li><p>利用基于内容的发布&#x2F;订阅系统中的复合订阅来提供分散的基于事件的工作流程管理 <a href="https://link.springer.com/chapter/10.1007/11587552_13">link.springer.com</a></p></li><li><p><a href="https://serverlessworkflow.io/">serverlessworkflow.io</a> 该工作提出将工作流声明为 YAML 文件，其中包含要使用的 CloudEvents 概述、无服务器函数的事件驱动调用以及工作流数据管理和控制流逻辑的状态转换。</p><ul><li>定义了一个可以被不同系统解释的抽象定义，从而保证可移植性避免供应商锁定</li></ul></li><li><p>当下的 Serverless 编排系统大多数依赖于集中式的服务器资源（虚拟机）或者是专有资源</p><ul><li>坏处<ul><li>不能将资源占有量降为 0</li><li>工作流执行时编排组件持续活跃，工作流执行时间长时造成资源浪费</li></ul></li></ul></li><li><p>IBM Composer 生成一个状态机代表着即将要被执行的 IBM Cloud Functions</p><ul><li>能够表示顺序、条件分支、循环、并行以及任务映射</li><li><code>fork/join</code> 同步阻塞了外部用户提供的 <code>Redis</code> 服务，限制了其对短期运行任务的适用性</li></ul></li><li><p>Amazon Step Functions and Amazon Step Functions Express Workflows 使用 JSON 模型化任务转移、选择、等待、并行、映射，ASF 是一个支持 Workflow 错误容忍服务，ASFE 时用户支撑短时运行的工作负载</p></li><li><p>微软的 Azure Durable Functions（ADF）提出了使用代码生成 Workflows 的方式，使用 <code>async/await</code> 结构，使用事件源重启被挂起的工作流</p><ul><li>不支持映射工作</li><li>只包含了 <code>Task.whenAll</code> 抽象来实现 <code>fork/join</code></li></ul></li><li><p>谷歌云提供了 Google Cloud Workflows 服务。它的工作流包括了一系列的基于逻辑的步骤，逻辑类似于条件或者循环。可以通过对每一个步骤发出一个 HTTP Request 的方式来触发 Google Cloud Function</p><ul><li>不适合用来做广播的并行任务</li></ul></li></ul><h3 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h3><ul><li><p>ECA 模型：Event-Condition-Action, <code>Event Sources</code> and <code>Programmable Conditions</code> and <code>Actions</code></p><ul><li>包含触发器和规则：适合定义表示工作流的有限状态机的状态转移</li></ul></li><li><p>触发器服务</p><ul><li>Workflow: 由 6 元组组成的一个有限状态机<ul><li>输入事件的集合</li><li>上下文变量</li><li>将 Actions 映射到 ECA 模型</li><li>初始状态</li><li>终止状态</li><li>状态转移方程，通过 ECA 触发器转移</li></ul></li><li>Trigger: 可以看作是状态转移方程，由四元组构成<ul><li>事件：驱动云应用的院原子信息。使用 subject 字段匹配事件对应的触发器，使用 type 字段描述事件的类型</li><li>上下文：一个 key-value 的数据结构，包含了触发器运行周期的状态</li><li>条件：由用户定义的决定事件是否匹配行为</li><li>行为：用于异步地触发一个 Serverless 函数</li></ul></li></ul><blockquote><p>触发器的生命周期可以表示如下：</p><ol><li>一个事件由某些事件源产生</li><li>事件被系统消费，激活对应的触发器</li><li>事件由 Condition 函数处理，若结果是正确的，就交由 Action 函数处理</li><li>Action 函数被激活了，就称作该触发器被 fired</li><li>当一个触发器被 fired 的时候，他就可以被 disabled 或者由系统 maintain<ul><li>Mapping Workflows to Triggers：一个工作流可以通过一系列触发器进行映射</li><li>任意工作流抽象都可以通过有限状态机表示，可以被转化为各种各样的触发器，并且通过 TriggerFlow 表示</li><li>Substitution Principle：工作流本身通过初始化和终止遵守操作。工作流可以嵌套</li><li>Dynamic Trigger Interception：</li></ul></li></ol></blockquote></li><li><p>错误容忍：</p><ul><li>事件总线保证事件的至少一次传递<ul><li>事件可以重复无序</li></ul></li><li>通过 CloudEvent 标准为每个事件赋予一个 ID<ul><li>在事件处理阶段，同样 ID 的事件就会丢弃</li></ul></li><li>通过辨别两种事件组合类型来处理无序消息<ul><li>聚合：如计数器。由于消息顺序不会改变最终结果，故不用考虑</li><li>序列：仅仅处理激活序列开头的触发器的事件，其他事件将被延迟，直到启用他们激活的触发器</li></ul></li></ul></li></ul><h2 id="Comparison-of-FaaS-Orchestration-Systems"><a href="#Comparison-of-FaaS-Orchestration-Systems" class="headerlink" title="Comparison of FaaS Orchestration Systems"></a><a href="https://ieeexplore.ieee.org/abstract/document/8605772">Comparison of FaaS Orchestration Systems</a></h2><h3 id="解决问题-1"><a href="#解决问题-1" class="headerlink" title="解决问题"></a>解决问题</h3><p>本文章比较了四种函数编排平台 AWS Lambda, IBM Cloud Functions, Google Cloud Functions,Azure Functions</p><h3 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h3><ul><li><p>IBM Serverless 的三大难题</p><ul><li>函数需要在一个沙箱中进行</li><li>函数组合应该遵循同步调用的替换原则（即组合也应该是一个函数）</li><li>调用不应该重复计费</li></ul></li><li><p>编排函数不需要外部的运行时支持</p><ul><li>两种解决模式<ul><li>使用函数进行编排<ul><li>函数的编排是在一个 Serverless 函数中进行的</li><li>带来双重付费的问题</li></ul></li><li>使用外部的客户端进行编排<ul><li>能够解决双重付费问题</li><li>不能视为函数，违反替换原则</li></ul></li></ul></li></ul></li></ul><h3 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h3><ul><li>ST-safeness：符合三难困境的编排服务被称为 STsafe。</li><li>Programming model：编程简单性和编码抽象集，是否提供反射 API 来观察函数组合的当前状态。</li><li>Parallel execution support：并行执行支持</li><li>State management：数据如何从一个函数转移到下一个函数</li><li>Architecture：编排器是客户端调度程序或者是本身就是一个函数，用于事件的响应</li><li>Overhead：鉴于编排服务对函数调度程序的依赖，应针对代表性函数组合（例如链和并行模式）来衡量编排开销的重要性</li><li>Billing model</li></ul><h3 id="评估结果"><a href="#评估结果" class="headerlink" title="评估结果"></a>评估结果</h3><table><thead><tr><th></th><th>ST-safeness</th><th>Programming model</th><th>Parallel execution support</th><th>State management</th><th>Architecture</th><th>Overhead</th></tr></thead><tbody><tr><td>Amazon Step Functions (ASF)</td><td>不满足，因为函数编排不是函数</td><td>- 支持顺序和分支，函数重试以及并行。- 只能静态图- 提供了反射 API 查询状态以及取消执行- 通过 CloudWatch 监控</td><td>支持</td><td>32KB 的限制</td><td>外部编排器</td><td></td></tr><tr><td>IBM Composer</td><td>满足，也是第一个满足的</td><td>- 提供了完整的编排库- 不提供并行的 DSL- 但是可以将函数作为前端接口暴露- 不支持反射 API，只能通过日志</td><td>不支持</td><td>5MB 的状态转移限制</td><td>集成在反应式核心中</td><td>提供了包，支持用户上传包</td></tr><tr><td>Azure Durable Functions (ADF)</td><td>满足</td><td>- 通过 C#代码创建函数流- 提供了反射 API，不仅能获取当前的状态，也能触发事件到一个挂起的函数</td><td>支持</td><td>不限制</td><td>外部编排器</td><td>提供了非常简单的包</td></tr></tbody></table><h2 id="FaaSFlow-enable-efficient-workflow-execution-for-function-as-a-service"><a href="#FaaSFlow-enable-efficient-workflow-execution-for-function-as-a-service" class="headerlink" title="FaaSFlow: enable efficient workflow execution for function-as-a-service"></a><a href="https://dl.acm.org/doi/10.1145/3503222.3507717">FaaSFlow: enable efficient workflow execution for function-as-a-service</a></h2><h3 id="解决问题-2"><a href="#解决问题-2" class="headerlink" title="解决问题"></a>解决问题</h3><ul><li>传统的 master-worker 架构性能太差<ul><li>master 的调度模式，通过该模式，功能在 master 节点中触发并分配给工作节点来执行。</li><li>worker 之间的数据移动也会降低吞吐量。</li></ul></li></ul><blockquote><p>These serverless workflow systems usually provide a centralized workflow engine on the master node to manage the workflow execution state and assign function tasks to the worker nodes. We refer to this scheduling pattern as master-side workflow schedule pattern (denoted by MasterSP), as the central workflow engine in the master node determines whether a function task is triggered to run or not<br><img src="/../assets/serverless_workflow/ZlhlbGgQ7oYaSrx0LlycRwvinbg.png"><br>这些无服务器工作流系统通常在主节点上提供集中式工作流引擎来管理工作流执行状态并将功能任务分配给工作节点。我们将这种调度模式称为主端工作流调度模式（记为 MasterSP），由主节点中的中央工作流引擎决定是否触发功能任务运行</p></blockquote><ul><li>带来的问题<ul><li>中央工作流引擎负责动态管理和调度所有功能。函数执行状态频繁地从主节点转移到工作节点，带来大量的调度开销。由于函数很短，这种传输会频繁发生。</li><li>引擎“随机”将触发的函数分发到工作节点以实现负载均衡，云厂商对函数的输入输出数据大小进行配额，以避免严重消耗网络带宽。在生产无服务器平台中，用户通常依赖额外的数据库存储服务来进行临时数据存储和交付，从而承受巨大的数据移动开销</li></ul></li></ul><h3 id="工作难点-1"><a href="#工作难点-1" class="headerlink" title="工作难点"></a>工作难点</h3><ul><li><p>WorkerSP: 大规模工作流划分为控制平面以及数据平面</p><ul><li>worker 函数可以执行自动缩放并重用热容器，这导致控制平面中的每个功能节点在数据中可能具有多个不同的数据平面</li><li>在无服务器工作流的实际控制平面（用户预定义）和数据平面（数据依赖）不一定相同的情况下，将大规模工作流划分为两个不同平面的多个工作人员时具有挑战性</li><li>考虑到集群中资源动态变化的前提，还需要一种基于实时资源可用性来划分和调度工作流的机制</li></ul></li><li><p>FaaStore: 利用主内存在函数之间交换数据</p><ul><li>没有理论指导</li></ul></li></ul><h3 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h3><ul><li>函数冷启动问题</li><li>Serverless Workflow 优化</li></ul><h3 id="模型定义-1"><a href="#模型定义-1" class="headerlink" title="模型定义"></a>模型定义</h3><ul><li>FaaSFlow<ul><li>工作流图调度程序在 <code>Master</code> 节点上运行。图调度器解析用户上传的工作流，根据每个工作节点上的可用资源和相邻功能之间传输的数据量将工作流划分为子图。</li><li>在每个 <code>Worker</code> 节点上，<ul><li>FaaSFlow 运行一个 <code>pre-worker</code> 工作流引擎来管理函数状态并触发本地函数任务，</li><li>一个集成的 FaaStore 在运行时动态分配容器中超额配置的内存</li></ul></li><li>FaaStore<ul><li>使用适当的数据存储（容器中分配良好的主内存或远程存储）来支持基于功能的位置和依赖性的通信。</li></ul></li></ul></li></ul><h4 id="Graph-Scheduler"><a href="#Graph-Scheduler" class="headerlink" title="Graph Scheduler"></a>Graph Scheduler</h4><h4 id="Per-Worker-Workflow-Engine"><a href="#Per-Worker-Workflow-Engine" class="headerlink" title="Per-Worker Workflow Engine"></a>Per-Worker Workflow Engine</h4><h4 id="Memory-Reclamation-in-FaaStore"><a href="#Memory-Reclamation-in-FaaStore" class="headerlink" title="Memory Reclamation in FaaStore"></a>Memory Reclamation in FaaStore</h4><h3 id="开源代码"><a href="#开源代码" class="headerlink" title="开源代码"></a>开源代码</h3><p><a href="https://github.com/lzjzx1122/FaaSFlow">https://github.com/lzjzx1122/FaaSFlow</a></p><h2 id="Distributed-Transactions-on-Serverless-Stateful-Functions"><a href="#Distributed-Transactions-on-Serverless-Stateful-Functions" class="headerlink" title="Distributed Transactions on Serverless Stateful Functions"></a><a href="https://dl.acm.org/doi/abs/10.1145/3465480.3466920">Distributed Transactions on Serverless Stateful Functions</a></h2><h3 id="解决问题-3"><a href="#解决问题-3" class="headerlink" title="解决问题"></a>解决问题</h3><p>当前的 Serverless 计算缺乏正确的状态管理支持，也缺乏函数到函数之间的调用能力</p><ul><li>在一个有状态的数据流引擎实现事务处理</li><li>提出一个在有状态的 Serverless 函数之间进行事务处理的编程模型</li><li>实现了两个在云应用使用的主要方法来实现事务处理保证：两阶段提交协议以及 Saga Workflow</li><li>在云基础设施上使用 YCSB 基准的扩展版本来评估两种事务方案</li></ul><h3 id="相关工作-3"><a href="#相关工作-3" class="headerlink" title="相关工作"></a>相关工作</h3><ul><li><p>Beldi 在有状态函数之间提供了拥有错误容忍的 ACID 事务处理</p><ul><li>方法：将函数的操作记录到 Serverless 云数据库</li></ul></li><li><p>Cloudburst 为形成 DAG 的功能工作流提供了因果一致性</p><ul><li>方法：通过 Anna，一个具有冲突解决策略的键值存储</li></ul></li></ul><h2 id="Durable-functions-semantics-for-stateful-serverless"><a href="#Durable-functions-semantics-for-stateful-serverless" class="headerlink" title="Durable functions: semantics for stateful serverless"></a><a href="https://dl.acm.org/doi/abs/10.1145/3485510">Durable functions: semantics for stateful serverless</a></h2><h3 id="解决问题-4"><a href="#解决问题-4" class="headerlink" title="解决问题"></a>解决问题</h3><p>FaaS 编程模式的无状态问题</p><h3 id="工作难点-2"><a href="#工作难点-2" class="headerlink" title="工作难点"></a>工作难点</h3><ul><li>持久化执行进度。许多应用需要大型或者长时间运行的函数的可靠执行，因此执行进度必须可持久化。由于大部分的语言运行时都不支持在一个正在运行的程序中检查状态，因此很难有一个简单自动且稳健的方式去持久化函数的执行进度</li><li>持久化应用状态。所有的可持久化的状态都必须通过外部的数据库进行存储，并且在使用时还必须显式地读写。由于 FaaS 的执行能力弱加上存储 API 的复杂性，这个过程也是困难的</li><li>恰好一次执行。旨在可靠的处理事件的触发存储器实际上并不能保证一次性执行。例如，当一个触发器触发一个函数处理消息队列中所有的消息的时候，就会带来消息的重复消费</li><li>同步性。并发控制必须通过外部服务来实现。租约迫使开发商根据时间假设进行工作，而电子标签只能检测冲突，而不能阻止冲突</li></ul><h3 id="相关工作-4"><a href="#相关工作-4" class="headerlink" title="相关工作"></a>相关工作</h3><ul><li>两种常见的有状态的 Serverless 抽象是 workflow 以及 actor<ul><li>Workflow<ul><li>Amazon Step functions</li><li>Azure Durable Functions</li><li>IBM Composer</li></ul></li><li>Actor<ul><li>Orleans</li><li>Durable Objects</li><li>Akka Serverless</li><li>Azure Durable Entities</li></ul></li></ul></li></ul><h3 id="Durable-Functions"><a href="#Durable-Functions" class="headerlink" title="Durable Functions"></a>Durable Functions</h3><p>  DF定义了三种基本的函数</p><ul><li>活动函数是DF中的无状态函数</li><li>实体是封装应用程序状态和流程操作的一个actor</li><li>编排函数使用任务并行的风格去协调活动函数和实体</li></ul><h4 id="Orchestrations"><a href="#Orchestrations" class="headerlink" title="Orchestrations"></a>Orchestrations</h4><p>编排允许开发人员通过将计算分解为任务来创建长时间运行的计算和工作流程。</p><ul><li>顺序组合</li><li>并行组合</li><li>持久化组合</li><li>客户端操作。客户端对象用来提供DF运行时的接口</li></ul><h4 id="Entities"><a href="#Entities" class="headerlink" title="Entities"></a>Entities</h4><p>实体允许应用程序封装持久状态，并定义可以对其执行的操作</p><ul><li>编排调用以及信号触发。编排函数可以通过调用或者发送信号的方式access实体</li><li>实体间信号。这可以实现有用的模式，例如使用实体来表示有状态的流操作符，甚至是复杂的数据流图</li><li>有序信号。DF 支持按指定传送时间安排信号。这对于需要在特定时间执行的操作非常有用</li></ul><h2 id="The-Serverless-Trilemma-Function-Composition-for-Serverless-Computing"><a href="#The-Serverless-Trilemma-Function-Composition-for-Serverless-Computing" class="headerlink" title="The Serverless Trilemma Function Composition for Serverless Computing"></a><a href="https://dl.acm.org/doi/pdf/10.1145/3133850.3133855">The Serverless Trilemma Function Composition for Serverless Computing</a></h2><h3 id="解决问题-5"><a href="#解决问题-5" class="headerlink" title="解决问题"></a>解决问题</h3><ul><li>描述了 Serverless 计算中关于函数组合的困难：Serverless trilemma<ul><li>函数需要在黑盒中进行</li><li>维护函数调用的可替代性原则</li><li>避免重复付费</li></ul></li></ul><h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h3><p>在论文《The Serverless Trilemma: Function Composition for Serverless Computing》中的“Serverless Computing 简介”章节，提到了几个关键的概念和实践，以下是对这些概念的介绍：</p><ol><li><strong>Serverless Computing（无服务器计算）</strong>: 这一部分通过一个实例来介绍无服务器计算的价值提案。它描述了如何通过事件驱动的数据管道将两个现有服务连接起来。具体例子中，应用程序监控 Travis（持续集成工具）的构建失败，并通过 Slack（消息服务平台）发送通知。</li><li><strong>Functions as a Service（<strong><strong>函数即服务</strong></strong>，FaaS）</strong>: 描述了如何使用函数来响应特定事件。例如，在 Travis 构建完成时触发事件，这时需要一个用于数据格式转换的函数（Format），以及一个用于向 Slack 发送通知的函数（Post）。这些函数作为独立的单元被部署和调用，而不需要预先配置基础设施。</li><li><strong>Event-Driven Invocation（事件驱动调用）</strong>: 描述了如何基于特定事件（如 Travis 构建完成）触发函数调用。这类调用通常通过发布-订阅系统来实现，其中 OpenWhisk 使用触发器（trigger）来代表一个命名的话题。</li><li><strong>Componentization and Composition（组件化和组合)</strong>: 论文强调了将功能分解为更小、更专注的函数的重要性，这不仅促进了代码重用，也简化了整体架构。这部分讨论了如何在无服务器运行时环境中实现函数的组合，以及如何将一个函数的输出作为另一个函数的输入。</li></ol><h3 id="反应式模型"><a href="#反应式模型" class="headerlink" title="反应式模型"></a>反应式模型</h3><p>该章节描述了 OpenWhisk 的编程模型，刻画了反应式模型在 OpenWhisk 中的应用</p><ol><li><strong>OpenWhisk 编程模型</strong>: 这一节为论文的其他部分奠定了基础，通过介绍 OpenWhisk 的核心编程模型。OpenWhisk 是一个开源的无服务器平台，其核心特性包括反应式调度器和反射能力。</li><li><strong>反应式调度器(<strong><strong>reactive</strong></strong> scheduler)</strong>: OpenWhisk 的核心包括一个反应式调度器，用于调度单一的、完整的动作（actions）。这种调度方式是基于事件驱动的，意味着动作的执行是由外部事件触发的。</li><li><strong>反射能力(reflective capability)</strong>: 通过反射调用（reflective invocation），一个动作可以控制其他动作的调度。这意味着在 OpenWhisk 中，一个函数可以触发或控制另一个函数的执行。</li><li><strong>外部调度器的能力与限制</strong>: 第四节将展示这种类型的外部调度器的能力与限制，其中“外部调度器”指的是不属于 OpenWhisk 核心部分的实体，它管理动作的调用。在这种情况下，程序完全利用核心调度器进行操作，这些程序被称为静态或静态调度程序。</li><li><strong>模型的抽象语法</strong>: 论文中还描述了该模型的抽象语法的语法表，从这个模型中可以直接映射到 OpenWhisk 的实际编程实践。</li></ol><p><img src="/../assets/serverless_workflow/FUeqbOFuHoswTYx6dgbclH28nMc.png"></p><ol><li><strong>触发器(triggers)<strong>：模型使用触发器来表示事件。一个程序包含了一个或者多个规则，一个规则描述了一个触发器</strong>何时</strong>执行并且<strong>执行什么</strong>；</li></ol><h4 id="OpenWhisk-Actions"><a href="#OpenWhisk-Actions" class="headerlink" title="OpenWhisk Actions"></a>OpenWhisk Actions</h4><ol><li><strong>Stateless Function</strong>: OpenWhisk 中的动作（Action）被定义为一个无状态的函数，每个动作都有一个唯一的名称。</li><li><strong>输入与输出</strong>: 动作的输入是一个字典（Dictionary），即一组键值对。动作的输出是另一个字典（如果动作成功完成），或者是一个失败的指示。这里采用了 Scala 的 Try 类型，表示动作调用的结果可能是成功的类型 T 或者是系统的错误类型。一个 Action 可以通过下列公式进行表示</li></ol><p>$$<br>a.invoke: Dictionary \rightarrow Try[Dictionary]<br>$$</p><ol><li><p><strong>日志输出</strong>: 除了正常的响应外，动作也可能产生日志输出的副通道。一个动作的日志被认为是一个可能为空的日志记录列表。为了性能考虑，日志记录仅在事后可访问。</p></li><li><p><strong>无状态性（Statelessness）</strong>: 一个 action 不能假设从一个调用到下一个调用会<strong>持续存在词法状态</strong>。这种无状态性简化了调度和扩展的解决方案</p><ol><li>如果需要将状态传递给未来的调用，action 负责安排适当的外部机制。例如，状态可以外部化到托管的文档存储，如 Amazon 的 S3 或 IBM 的 Cloudant。</li></ol></li><li><p><strong>最多一次调用语义（At-Most-Once Invocation Semantics）</strong>: 在分布式系统中，无法保证完全准确一次的传递。因此，实现只需保证最多一次的语义，即每次动作的调用。</p></li></ol><h4 id="柯里化函数应用"><a href="#柯里化函数应用" class="headerlink" title="柯里化函数应用"></a>柯里化函数应用</h4><p>在论文《The Serverless Trilemma: Function Composition for Serverless Computing》中提到的“Curried Function Application”（柯里化函数应用）是指在无服务器计算环境中，将特定的值（键值对）绑定到一个函数上，从而创建一个新的函数版本的过程。</p><p>具体来说，当你有一个动作（函数）<code>a</code> 和一组键值对 <code>M</code> 时，你可以通过将 <code>a</code> 根据 <code>M</code> 中的变量赋值进行柯里化，来创建一个新的动作 <code>a&#39;</code>。这个过程被称为 <code>a.with(M)</code>。结果产生的动作 <code>a&#39;</code> 被视为 <code>a</code> 的一个绑定版本。</p><p>操作上，如果你调用 <code>a.with(M).invoke(D)</code>，你实际上是在调用一个与映射 <code>M</code> 柯里化并且用实际参数 <code>D</code> 调用的动作。</p><p>柯里化函数应用在无服务器架构中特别有用，因为它允许动态地创建具有特定配置的函数版本，而无需为每种可能的配置编写单独的代码。这种方法提高了代码的复用性，并简化了在无服务器环境中函数组合的处理。</p><h4 id="包：命名空间与批量柯里化"><a href="#包：命名空间与批量柯里化" class="headerlink" title="包：命名空间与批量柯里化"></a>包：命名空间与批量柯里化</h4><ol><li>命名空间和动作分组: OpenWhisk 允许将动作（Actions）在特定的命名空间下进行分组。这种分组以包（Package）的形式出现，一个包 <code>P</code> 是一组动作 <code>Ap</code> 的集合。</li><li>批量柯里化: 包中的动作可以通过 <code>with</code> 绑定组合。例如，对于包 <code>P</code> 和其中的动作 <code>a</code>，调用 <code>P.with(Mp).a.with(Ma).invoke(P)</code> 表示首先应用包级别的变量赋值 <code>Mp</code>，然后是动作级别的 <code>Ma</code>，最后是实际参数。这样的处理方式使得变量赋值 <code>Mp</code> 在实际参数和动作级别柯里化之后，作为第三优先级来源。</li><li>抽象和隔离: 包的柯里化提供了一个有用的抽象，特别是在处理凭证和其他秘密信息时。绑定允许程序隔离凭证，以便它们只暴露给需要它们的动作。</li></ol><h4 id="OpenWhisk-Triggers"><a href="#OpenWhisk-Triggers" class="headerlink" title="OpenWhisk Triggers"></a>OpenWhisk Triggers</h4><ol><li>消息队列的表示: OpenWhisk 的编程模型将消息队列表现为两种操作，这些操作是基于命名主题的，称为触发器（triggers）。</li><li>触发器类型构造: 使用类型构造函数 <code>Trigger[t]</code>，可以构建一个新的触发器子类型，其中 <code>t</code> 是应用程序中识别主题的字符串。</li><li>触发器代表消息类: 触发器 <code>Trigger[t]</code> 代表一类消息，可以简单地表示为 <code>t</code>。消息被认为是字典类型（Dictionary），与动作的输入和输出格式相同。</li><li>创建和通知消息: 对于给定主题 <code>t</code> 和有效载荷 <code>D</code>，<code>t.fire(D)</code> 操作用于构造一个带有此有效载荷的新消息，并通知消息队列其到达。例如，要在 “build_done” 主题上创建表示成功构建的消息，可以使用 <code>Trigger[&quot;build_done&quot;].fire(status → &quot;success&quot;)</code>。</li></ol><h4 id="通过触发器进行反应式调用"><a href="#通过触发器进行反应式调用" class="headerlink" title="通过触发器进行反应式调用"></a>通过触发器进行反应式调用</h4><p>我们已经介绍了触发器(trigger)以及动作(action)，他们直接通过一个 <code>when</code> 的语法进行连接。</p><p><img src="/../assets/serverless_workflow/DTyibRzCconL1Lxg0CjchBLfnJh.png"></p><ul><li>规则(Rule): 描述了从触发器到动作之间的联系。<code>t.when(a)</code><ul><li>包含多个状态位：决定了 t 是否发送消息</li><li>允许程序分离他们对于 actions 触发的管理</li></ul></li></ul><h4 id="部署与反思"><a href="#部署与反思" class="headerlink" title="部署与反思"></a>部署与反思</h4><ol><li>动作部署（Deployment）: 当一个动作的源代码准备好后，它可以被部署。只有在部署之后，这个动作才可以被调用。每个已部署的动作都有一个独特的远程调用端点。</li><li>触发器部署: 类似地，一旦触发器（Trigger）被部署，它也会收到一个独特的远程触发端点。</li><li>反射式调用（Reflective Invocation）: 使用这些远程端点，一个动作在其调用期间可以调用另一个动作。这种动作调用动作的过程被称为反射式调用。</li><li>内省功能（Introspective Facilities）: 这些内省功能允许在核心提供的组合器之外，使用一般用途语言的全部功能进行新类型组合器的实验。通过对静态组合的属性进行内省，可以将新的组合器作为无服务器动作编程。</li><li>内省 API: 论文假设内省 API 以 JavaScript 库的形式呈现，可供实现为 JavaScript 的无服务器动作使用。为了清晰的展示，将使用由核心模型提供的内省函数的符号表示，这些包括动作、触发器和规则函数，它们分别代表各自实体的构造器。这些反射式构造器允许进行元编程，这是论文后续将更详细探讨的一个场景。</li></ol><h3 id="The-Serverless-Trilemma"><a href="#The-Serverless-Trilemma" class="headerlink" title="The Serverless Trilemma"></a>The Serverless Trilemma</h3><ol><li>序列组合的引入: 在核心模型中，序列组合允许程序从两个给定的动作中构造一个新的动作。这种新动作的调用含义将通过 flatMap 单子组合的语义来精确定义：序列表现为数据管道，其中唯一的隐式通信发生在动作间的连接点，且在第一个失败的动作处执行短路。</li><li>序列组合器“then”: 作者引入了一个所期望的序列组合器，称为“then”。例如，组合 <code>a.then(b).then(c)</code> 应该等同于一个新的动作 <code>s</code>，使得输入到 <code>s</code> 的内容成为输入到 <code>a</code> 的内容，而 <code>s</code> 的输出与表达式 <code>c(b(a()))</code> 的输出相同。</li></ol><h4 id="双重计费约束"><a href="#双重计费约束" class="headerlink" title="双重计费约束"></a>双重计费约束</h4><p>文章首先定义了什么是双重计费，即一个函数调用另一个函数的时候，该调用函数必须等待被调用函数执行完毕才停止，带来了执行时间上的浪费问题</p><p><img src="/../assets/serverless_workflow/TuPQbU3Xdox42IxIDI6ca8WPnHd.png"></p><h4 id="黑盒约束"><a href="#黑盒约束" class="headerlink" title="黑盒约束"></a>黑盒约束</h4><ul><li>函数流上的多个函数需要能够支持不同语言的函数执行</li><li>函数需要通过 Action 进行触发</li></ul><h4 id="可替代原则"><a href="#可替代原则" class="headerlink" title="可替代原则"></a>可替代原则</h4><p>希望动作的组合本身就是动作。以下是可能得解决方案</p><ol><li><p>反射调用</p><ol><li>使用调度程序调用多个函数，但是调度程序在其组成部分的活动时间内要保持活跃状态，带来双重计费</li></ol></li><li><p>连续传递</p><ol><li>通过让操作调用延续（即序列的其余部分）来调度序列。</li><li>该方法使用 <code>triggers</code> 和 <code>rules</code> 来实现</li><li>通过关联每个完成触发器与每个动作，当一个动作的调用完成时，调用会触发被关联的完全触发器。例如一个序列$a.then(b)$,a 的一个完全触发器被表示为$ct(a)$,那么就创建一个规则$ct(a).when(b)$。当 a 的完全触发器被调用时，就计划一个对于 b 的调用</li><li>当通过触发调用实现函数组合时，这种连续性可能会被破坏，因为触发的调用<strong>往往涉及到<strong><strong>异步处理</strong></strong>和事件驱动的机制</strong>。这可能意味着当一个函数调用另一个函数时，后者可能不会立即执行，而是在满足某些条件或接收到特定事件时才触发。这种行为的差异可能导致无法保持原始的同步调用模式，从而违反了可替代原则。<br>在这样的场景中，组合的函数无法简单地被视为相互替代的，因为它们的执行依赖于外部事件或触发器，而不仅仅是输入参数。这种异步性和依赖于事件的特性使得函数的组合变得更加复杂，并引入了额外的考虑因素，如状态管理、事件处理和调用顺序的控制。</li></ol></li><li><p>客户端调度程序</p><ol><li>当前仅当客户端程序实现了所有在 OpenWhisk 中可能的组合，该方法才算实现了可替代原则</li></ol></li></ol><h3 id="OpenWhisk-Invocation-Flow"><a href="#OpenWhisk-Invocation-Flow" class="headerlink" title="OpenWhisk Invocation Flow"></a>OpenWhisk Invocation Flow</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><p>包含了 4 个组件</p><p><img src="/../assets/serverless_workflow/DSBCbxR8ooLUF6xPamYcNmOWnfe.png"></p><p>当一个调用请求到来时</p><ol><li><code>controller</code> 首先选择 hosts 池子中的一个 <code>invoker</code></li><li>将请求信息放到一个 <code>message queue</code> 中</li><li>每个 <code>invoker</code> 都托管了多个容器，将多个调用分离开</li><li><code>invoker</code> 订阅了指向他们的事件，当资源可用时，将调用请求注入到容器中，此时，调用开始</li><li>当一个调用结束时，<code>invoker</code> 将结果存储到 <code>system of record</code> 中，向控制器指示它现在可以响应客户端</li></ol><h4 id="Active-ack"><a href="#Active-ack" class="headerlink" title="Active ack"></a>Active ack</h4><ul><li>管道旁路的微架构策略</li></ul><p><img src="/../assets/serverless_workflow/OpgobpKlxoUeVbxd5HccFkHsnWf.png"></p><p>调用者以绕过系统记录的方式发出完成信号。<code>ack action</code> 使用消息队列作为计分板，将调用者的结果转发到控制器，以便控制器可以在调用完成时快速采取行动。</p><h4 id="Active-ACK-应用"><a href="#Active-ACK-应用" class="headerlink" title="Active ACK 应用"></a>Active ACK 应用</h4><p>通过应用 Active ACK 后，将发生如下的变化</p><ol><li>创建一个 <code>action</code> 的时候，必须指定该 <code>action</code> 为序列，然后指定构成组合的组件 OpenWhisk actions</li><li>控制器必须特殊处理序列 <code>action</code> 的调用</li></ol><p><img src="/../assets/serverless_workflow/BEvob9xv5oLYXNxz5U9cPSoAnWg.png"></p><p>在处理序列的调用时，在收到主动确认后，控制器会排列序列中下一个操作的调用。重复此排队调用和主动确认消息的循环，直到控制器到达操作列表的末尾。此时，它用最终的主动确认负载响应客户端。</p><h3 id="未来展望"><a href="#未来展望" class="headerlink" title="未来展望"></a>未来展望</h3><p>对序列之外的组合模式的需求，有三类这样的组合器：ECA 模型、重试以及数据转发。</p><p><img src="/../assets/serverless_workflow/FQXgbU5o5oTsAfxCFLCcLwmOn1c.png"></p><h4 id="ECA"><a href="#ECA" class="headerlink" title="ECA"></a>ECA</h4><p>来自 Travis 的通知消息包含无关的详细信息。因此，应用程序在步骤 1 中投影出相关字段：构建标识符和构建状态。如果构建失败（步骤 2），应用程序将继续执行步骤 3。</p><p>为了实现 ECA 这样的模型，下列代码展示了一个组合器，通过 condition 以及 action。当提供了入参 args 时，它将触发条件。</p><p><img src="/../assets/serverless_workflow/JG2jbcdMJoljKxxC7qEcr3pqnAb.png"></p><h4 id="元程序重试"><a href="#元程序重试" class="headerlink" title="元程序重试"></a>元程序重试</h4><p>为了重试，我们可以编写一个元程序，将函数作为输入，并调用它直到成功。清单 5 说明了这个重试元程序。我们想要的 VerifyAndAnalyze 函数现在可以表示为 Retry 的绑定，其中操作参数 A 绑定到 VerifyThenAnalyze。</p><p><img src="/../assets/serverless_workflow/Q3sObQMVAowi7Mx8WzDc2Ls2nmc.png"></p><h4 id="元程序数据转发"><a href="#元程序数据转发" class="headerlink" title="元程序数据转发"></a>元程序数据转发</h4><p>图中步骤 3 的输出(a,b)其中之一将进入到步骤 4 跟 5，另一个需要在 4 跟 5 执行后跟着 c 一起呗转发到 6，由于从 Retry action 返回的值还未实现，因此只能通过下列代码进行</p><p><img src="/../assets/serverless_workflow/Kq8rbg0g3o8iUexQ8rjcZ6UnnjS.png"></p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Serverless</tag>
      
      <tag>Function orchestration</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>高级机器学习</title>
    <link href="/2024/06/09/aml/"/>
    <url>/2024/06/09/aml/</url>
    
    <content type="html"><![CDATA[<h1 id="高级机器学习"><a href="#高级机器学习" class="headerlink" title="高级机器学习"></a>高级机器学习</h1><h1 id="第一讲-机器学习概述"><a href="#第一讲-机器学习概述" class="headerlink" title="第一讲 机器学习概述"></a>第一讲 机器学习概述</h1><h2 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h2><ul><li>定义：机器利用数据学习人类经验，不断提高性能的过程</li><li>目标：模型具有泛化能力</li></ul><h2 id="人工智能发展阶段"><a href="#人工智能发展阶段" class="headerlink" title="人工智能发展阶段"></a>人工智能发展阶段</h2><ul><li>60-70 年代：推理期</li><li>80 年代：知识期</li><li>90 年代：学习期</li></ul><h1 id="第二讲-模型评估和选择"><a href="#第二讲-模型评估和选择" class="headerlink" title="第二讲 模型评估和选择"></a>第二讲 模型评估和选择</h1><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><h3 id="泛化误差-vs-经验误差"><a href="#泛化误差-vs-经验误差" class="headerlink" title="泛化误差 vs 经验误差"></a>泛化误差 vs 经验误差</h3><ul><li>泛化误差：在测试样本上的误差</li><li>经验误差：在训练集上的误差，也叫做训练误差</li></ul><h3 id="过拟合-vs-欠拟合"><a href="#过拟合-vs-欠拟合" class="headerlink" title="过拟合 vs 欠拟合"></a>过拟合 vs 欠拟合</h3><ul><li>在不存在严重过拟合或欠拟合现象时，经验误差和泛化误差可以进行相互界定</li></ul><h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><h3 id="经验误差"><a href="#经验误差" class="headerlink" title="经验误差"></a>经验误差</h3><ul><li>三个关键问题<ul><li>如何获得测试结果：评估方法</li><li>如何评估性能优劣：性能度量</li><li>如何判断实质差别：比较检验</li></ul></li></ul><h4 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h4><ul><li><p>留出法</p><ul><li>将数据集分为两个互斥集合——训练和测试集</li><li>训练和测试集分得尽可能保持数据分布的一致性</li><li>分层采样：保持类别比例一致</li><li>通常比例控制在 2:1~4:1</li></ul></li><li><p>交叉验证法</p><ul><li>先分为 k 个子集，每次用 k-1 个做训练集，剩下的做测试集</li></ul></li><li><p>留一法</p></li></ul><h4 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h4><p>性能度量是衡量模型泛化能力的评价标准，反映了任务需求</p><ul><li><p>回归任务：均方误差</p><ul><li>$$<br>E(f;D) &#x3D; \frac{1}{m}\sum_{i&#x3D;1}^{m}(f(x_i)-y_i)^2<br>$$</li></ul></li><li><p>分类任务：错误率和精度</p><ul><li>分类错误率：$E(f;D) &#x3D; \frac{1}{m}\sum_{i&#x3D;1}^{m}(f(x_i)\neq y_i)$</li><li>精度：$acc(f;D) &#x3D; 1-E(f;D)$</li></ul></li><li><p>信息搜索：查准率与查全率</p><ul><li>查准率：$P &#x3D; \frac{TP}{TP+FP}$（预测为正例的正确率）</li><li>查全率：$R &#x3D; \frac{TP}{TP+FN}$（所有正例能否预测出来）</li><li>F1 度量：$F1 &#x3D; \frac{2\times P\times R}{P+R} &#x3D; \frac{2\times TP}{样例总数+TP-TN}$<ul><li>更一般的形式：$F_\beta &#x3D; \frac{1+\beta^2\times P \times R}{(\beta^2\times P)+R}$</li></ul></li></ul></li></ul><h4 id="比较检验"><a href="#比较检验" class="headerlink" title="比较检验"></a>比较检验</h4><ul><li>测试性能不等于泛化性能</li><li>测试性能随着测试集的变化而变化</li><li>评估方法：T-检验</li></ul><h1 id="第三讲-线性模型"><a href="#第三讲-线性模型" class="headerlink" title="第三讲 线性模型"></a>第三讲 线性模型</h1><ul><li>线性模型一般形式<ul><li>$$<br>f(x) &#x3D; \omega_1x_1 + \omega_2x_2 + \dots + \omega_dx_d + b<br>$$</li><li>如何确定$\omega$和$b$的值，使得线性模型具有优良性能</li></ul></li></ul><h2 id="回归任务模型：最小二乘法"><a href="#回归任务模型：最小二乘法" class="headerlink" title="回归任务模型：最小二乘法"></a>回归任务模型：最小二乘法</h2><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><ul><li>最小化均方误差：$E_{(\omega,b)} &#x3D; \sum_{i&#x3D;1}^m(y_i-\omega x_i-b)^2$<ul><li>分别对$\omega$和$b$求导：<ul><li>$$<br>\frac{\partial E_{(\omega,b)}}{\partial \omega} &#x3D; 2(\omega\sum_{i&#x3D;1}^mx_i^2-\sum_{i&#x3D;1}^m(y_i-b)x_i)<br>$$</li><li>$$<br>\frac{\partial E_{(\omega,b)}}{\partial b} &#x3D; 2(mb-\sum_{i&#x3D;1}^m(y_i-\omega x_i))<br>$$</li></ul></li><li>得到闭式解<ul><li>$$<br>\omega &#x3D; \frac{\sum_{i&#x3D;1}^my_i(x_i-\bar x)}{\sum_{i&#x3D;1}^mx_i^2-\frac{1}{m}(\sum_{i&#x3D;1}^mx_i)^2}<br>$$</li><li>$$<br>b &#x3D; \frac{1}{m}\sum_{i&#x3D;1}^{m}(y_i-\omega x_i)<br>$$</li><li>$$<br>\bar x &#x3D; \frac{1}{m}\sum_{i&#x3D;1}^mx_i<br>$$</li></ul></li></ul></li></ul><h3 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h3><p>$$<br>f(\boldsymbol{x_i}) &#x3D; \boldsymbol{\omega^Tx_i} +b<br>$$</p><ul><li><p>齐次表达<br>$$<br>  X &#x3D; \begin{pmatrix}<br>  x_{11} &amp; x_{12} &amp; \dots &amp; x_{1d} &amp; 1 \<br>  x_{21} &amp; x_{22} &amp; \dots &amp; x_{2d} &amp; 1 \<br>  \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \<br>  x_{m1} &amp; x_{m2} &amp; \dots &amp; x_{md} &amp; 1 \<br>  \end{pmatrix} &#x3D; \begin{pmatrix}<br>  \boldsymbol{x_1^T} &amp; 1 \<br>  \boldsymbol{x_2^T} &amp; 1 \<br>  \vdots &amp; \vdots \<br>  \boldsymbol{x_m^T} &amp; 1 \<br>  \end{pmatrix}<br>$$</p></li><li><p>最小二乘法：$\hat w^* &#x3D; \argmin_{\hat w}(y-X\hat w)^T(y-X\hat w)$</p><ul><li>求导得到：$\frac{\partial E_{\hat \omega}}{\partial \hat\omega} &#x3D; 2X^T(X\hat\omega - y)$</li></ul></li><li><p>满秩讨论</p><ul><li>$X^TX$是满秩矩阵或正定矩阵，则<ul><li>$$<br>\hat\omega^* &#x3D; (X^TX)^{-1}X^Ty<br>$$</li><li>$$<br>f(\hat x_i) &#x3D; \hat x_i^T(X^TX)^{-1}X^Ty<br>$$</li></ul></li><li>如果不是满秩矩阵，则引入正则化</li></ul></li></ul><h3 id="广义线性回归模型"><a href="#广义线性回归模型" class="headerlink" title="广义线性回归模型"></a>广义线性回归模型</h3><ul><li>$$<br>y &#x3D; g^{-1}(\boldsymbol{\omega^Tx} +b)<br>$$</li></ul><h2 id="二分类任务模型：对数几率回归"><a href="#二分类任务模型：对数几率回归" class="headerlink" title="二分类任务模型：对数几率回归"></a>二分类任务模型：对数几率回归</h2><ul><li><p>线性分类函数缺点：单位阶跃函数不连续，不可导</p></li><li><p>对数几率函数：$\ln \frac{y}{1-y} &#x3D; \boldsymbol{\omega^Tx} +b$</p><ul><li>对数几率：$\ln \frac{p(y&#x3D;1|x)}{p(y&#x3D;0|x)} &#x3D; \boldsymbol{\omega^Tx} +b$</li></ul></li><li><p>对数几率回归：极大似然法</p><ul><li>对数似然函数：$\ell(\omega,b) &#x3D; \sum_{i&#x3D;1}^{m}\ln p(y_i|x_i; \omega_i,b)$</li><li>可重写为：$\ell(\beta) &#x3D; \sum_{i&#x3D;1}^{m}(-y_i\beta^T\hat x_i + \ln(1+e^{\beta^T\hat x_i}))$</li></ul></li></ul><h2 id="多分类任务模型"><a href="#多分类任务模型" class="headerlink" title="多分类任务模型"></a>多分类任务模型</h2><h3 id="一对一"><a href="#一对一" class="headerlink" title="一对一"></a>一对一</h3><ul><li><p>拆分阶段</p><ul><li>N 个类别两两配对</li><li>各个二类任务学习分类器</li></ul></li><li><p>测试阶段</p><ul><li>新样本提交给所有分类器预测</li><li>投票产生最终分类结果</li></ul></li></ul><h3 id="一对其余"><a href="#一对其余" class="headerlink" title="一对其余"></a>一对其余</h3><ul><li><p>任务拆分</p><ul><li>某一类作为正例，其他反例<ul><li>N 个分类任务</li></ul></li><li>各个二类任务学习分类器<ul><li>N 个二类分类器</li></ul></li></ul></li><li><p>测试阶段</p><ul><li>新样本提交给所有分类器预测<ul><li>N 个分类结果</li></ul></li><li>比较各分类器预测置信度<ul><li>置信度最大类别作为最终类别</li></ul></li></ul></li></ul><h3 id="两种策略比较"><a href="#两种策略比较" class="headerlink" title="两种策略比较"></a>两种策略比较</h3><ul><li><p>一对一</p><ul><li>需要$\frac{N(N-1)}{2}$个分类器，存储开销和测试时间大</li><li>训练只用两个类的样例，训练时间短</li></ul></li><li><p>一对其余</p><ul><li>训练 N 个分类器，存储开销和测试时间小</li><li>训练用到全部训练样例，训练时间长</li></ul></li></ul><h3 id="多对多"><a href="#多对多" class="headerlink" title="多对多"></a>多对多</h3><ul><li>纠错输出码<ul><li>ECOC 编码对分类器错误的容忍和修正能力：编码越长、纠错能力越强</li><li>同等长度的编码，理论上，两个类别的编码距离越远，纠错能力越强</li></ul></li></ul><h1 id="第四讲-支持向量机"><a href="#第四讲-支持向量机" class="headerlink" title="第四讲 支持向量机"></a>第四讲 支持向量机</h1><h2 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h2><ul><li>将训练样本分开的超平面可能有很多个，但是哪个最好？<ul><li>泛化能力最强的</li></ul></li></ul><h2 id="间隔与支持向量"><a href="#间隔与支持向量" class="headerlink" title="间隔与支持向量"></a>间隔与支持向量</h2><ul><li>支持向量机：大间隔分类器</li><li>超平面方程: $\omega^T x + b &#x3D; 0$</li><li>间隔：$\gamma &#x3D; \frac{2}{\begin{Vmatrix}\omega\end{Vmatrix}}$</li></ul><h3 id="支持向量机-基本型"><a href="#支持向量机-基本型" class="headerlink" title="支持向量机-基本型"></a>支持向量机-基本型</h3><ul><li><p>最大间隔：寻找参数$\omega$跟$b$，使得$\gamma$最大</p></li><li><p>优化问题：$\argmax_{\omega, b}\frac{2}{\begin{Vmatrix}\omega\end{Vmatrix}} s.t. y_i(\omega^T x_i +b) \ge 1, i&#x3D;1,2,…,m$</p><ul><li>等价转化：$\argmin_{\omega, b}\frac{1}{2}\begin{Vmatrix}\omega\end{Vmatrix}^2\space<br>s.t.\space<br>y_i(\omega^T x_i +b) \ge 1, i&#x3D;1,2,…,m$</li><li>凸二次规划问题</li></ul></li></ul><h3 id="支持向量机-对偶型"><a href="#支持向量机-对偶型" class="headerlink" title="支持向量机-对偶型"></a>支持向量机-对偶型</h3><ul><li><p>引入拉格朗日乘子$\alpha_i \ge 0$得到拉格朗日函数</p><ul><li>$$<br>L(\omega,b,\alpha) &#x3D; \frac{1}{2}\begin{Vmatrix}\omega\end{Vmatrix}^2 + \sum_{i&#x3D;1}^m\alpha_i(1-y_i(\omega^Tx_i+b))<br>$$</li></ul></li><li><p>求偏导：</p><ul><li>$$<br>\omega &#x3D; \sum_{i&#x3D;1}^{m}\alpha_iy_ix_i, \quad 0 &#x3D; \sum_{i&#x3D;1}^{m}\alpha_iy_i<br>$$</li></ul></li><li><p>回代解得$\max_\alpha \sum_{i&#x3D;1}^m\alpha_i-\frac{1}{2}\sum_{i&#x3D;1}^m\sum_{j&#x3D;1}^m\alpha_i\alpha_jy_iy_jx_i^Tx_y, \quad s.t. \sum_{i&#x3D;1}^m\alpha_iy_i &#x3D; 0, \alpha_i \ge 0, \quad i&#x3D;1,2,\dots,m$</p></li></ul><h3 id="基本型跟对偶型比较"><a href="#基本型跟对偶型比较" class="headerlink" title="基本型跟对偶型比较"></a>基本型跟对偶型比较</h3><ul><li><p>基本型比较善于处理</p><ul><li>低维数据</li><li>高维稀疏数据</li></ul></li><li><p>对偶型善于处理高维稠密数据，容易吸收核函数处理非线性分类</p></li></ul><h2 id="特征空间映射"><a href="#特征空间映射" class="headerlink" title="特征空间映射"></a>特征空间映射</h2><ul><li>若不存在一个能正确划分两类样本的超平面，怎么办<ul><li>将样本从原始空间映射到一个更高维的特征空间，使样本在这个特征空间内线性可分</li></ul></li></ul><h3 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h3><p>基本思路：设计核函数</p><p>$$<br>\kappa(x_i,x_j) &#x3D; \phi(x_i)^T\phi(x_j)<br>$$</p><h2 id="软间隔支持向量机"><a href="#软间隔支持向量机" class="headerlink" title="软间隔支持向量机"></a>软间隔支持向量机</h2><ul><li><p>不再假设所有样本都可分，而是引入损失函数，计算每个样本的损失</p><ul><li>$$<br>\min_{\omega,b}\frac{1}{2}||\omega||^2 + C\sum_{i&#x3D;1}^ml_{0&#x2F;1}(y_i(\omega^T\phi(x_i)+b)-1)<br>$$</li></ul></li><li><p>存在问题</p><ul><li>0&#x2F;1 损失函数非凸非连续，不好优化</li></ul></li><li><p>替换方法</p><ul><li>采用 hinge 损失函数</li></ul></li><li><p>基本型和对偶型</p><ul><li>原始问题：$\min_{\omega,b}\frac{1}{2}||\omega||^2 + C\sum_{i&#x3D;1}^m\max(0,1-y_i(w_ix+b))$</li><li>对偶问题：$\min_\alpha\frac{1}{2}\sum_{i&#x3D;1}^m\sum_{j&#x3D;1}^m\alpha_i\alpha_jy_iy_j\phi(x_i)^T\phi(x_j)-\sum_{i&#x3D;1}^m\alpha_i, \quad s.t. \sum_{i&#x3D;1}^m\alpha_iy_i &#x3D; 0, 0\le \alpha_i\le C, i&#x3D;1,2,\dots,m$</li></ul></li><li><p>SVM 拓展-正则化</p></li></ul><h1 id="第五讲-神经网络"><a href="#第五讲-神经网络" class="headerlink" title="第五讲 神经网络"></a>第五讲 神经网络</h1><h2 id="神经网络发展史"><a href="#神经网络发展史" class="headerlink" title="神经网络发展史"></a>神经网络发展史</h2><ul><li>第一阶段：感知机为代表</li><li>第二阶段：反向传播为代表</li><li>第三阶段：深度网络为代表</li></ul><h2 id="神经元模型"><a href="#神经元模型" class="headerlink" title="神经元模型"></a>神经元模型</h2><h3 id="M-P-神经元模型"><a href="#M-P-神经元模型" class="headerlink" title="M-P 神经元模型"></a>M-P 神经元模型</h3><ul><li>输入：来自其他 n 个神经元传递过来的信号</li><li>处理：通过带权重连接进行传递，总值与神经元的阈值比较</li><li>输出：通过激活函数得到输出</li></ul><h3 id="神经元模型-激活函数"><a href="#神经元模型-激活函数" class="headerlink" title="神经元模型-激活函数"></a>神经元模型-激活函数</h3><ul><li>理想激活函数时阶跃函数，0 表示抑制神经元而 1 表示激活神经元</li><li>阶跃函数不连续不光滑，常用 Sigmoid 函数</li></ul><h2 id="感知机与多层网络"><a href="#感知机与多层网络" class="headerlink" title="感知机与多层网络"></a>感知机与多层网络</h2><ul><li>感知机由两层神经元组成，输入层接受外界输入信号传递给输出层，输出层是 M-P 神经元</li></ul><h3 id="感知机学习能力"><a href="#感知机学习能力" class="headerlink" title="感知机学习能力"></a>感知机学习能力</h3><ul><li><p>当两类模式线性可分时，感知机的学习过程一定会收敛；否则感知机的学习过程将会发生震荡</p></li><li><p>单层感知机的学习能力有限，只能解决线性可分问题</p><ul><li>对于异或等不能线性可分的问题，感知机不能求得合适解</li></ul></li></ul><h3 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h3><ul><li>输出层和输入层之间的一层神经元，称为隐层或隐含层</li><li>隐含层和输出层神经元都是具有激活函数的功能神经元</li></ul><h3 id="多层前馈神经网络"><a href="#多层前馈神经网络" class="headerlink" title="多层前馈神经网络"></a>多层前馈神经网络</h3><ul><li>定义：每两层神经元全互联，不存在同层连接和跨层连接</li><li>前馈：接受外界输入信号，隐含层与输出层神经元对信号进行加工输出</li><li>学习：根据训练数据调整神经元的“连接权”以及功能神经元的“阈值”</li><li>多层网络：包含隐层的网络</li></ul><h2 id="误差逆传播算法"><a href="#误差逆传播算法" class="headerlink" title="误差逆传播算法"></a>误差逆传播算法</h2><ul><li>误差逆传播算法是最成功训练多层前馈神经网络的学习算法<ul><li>给定训练集：$D &#x3D; {(x_i,y_i)}, x_i\in R^d, y_i\in R^l$，输入示例有$d$个属性描述，输出$l$维实值向量</li></ul></li></ul><p><img src="/../assets/aml/KuRGbu51AoQocpxqrjgcTxdunAS.png"></p><ul><li><p>前向计算</p><ul><li>$$<br>b_h&#x3D;f(\alpha_h-\gamma_h),\alpha_h &#x3D; \sum_{i&#x3D;1}^dv_{ih}x_i<br>$$</li><li>$$<br>\hat{y}<em>j^k &#x3D; f(\beta_j-\theta_j), \beta_j &#x3D; \sum</em>{i&#x3D;q}^d\omega_{hj}b_h<br>$$</li><li>$$<br>E_k &#x3D; \frac{1}{2}\sum_{j&#x3D;1}^l(\hat{y}_j^k-y_j^k)^2<br>$$</li></ul></li><li><p>基于梯度下降策略，以误差率为目标，计算负梯度方向对参数进行调整</p><ul><li>$$<br>\Delta\omega_{hj} &#x3D; -\eta\frac{\partial E_k}{\partial \omega_{hj}}<br>$$</li><li>$$<br>\frac{\partial E_k}{\partial \omega_{hj}} &#x3D; \frac{\partial E_k}{\partial\hat y_j^k}. \frac{\partial\hat y_j^k}{\partial\beta_j}.\frac{\partial\beta_j}{\partial\omega_{hj}}<br>$$</li><li>$$<br>g_j &#x3D; -\frac{\partial E_k}{\partial\hat y_j^k}.\frac{\partial\hat y_j^k}{\partial\beta_j}<br>$$</li></ul></li><li><p>学习率$\eta \in (0,1)$控制算法每一轮迭代的更新步长，太长容易震荡，太小收敛速度又会过慢</p></li></ul><p><img src="/../assets/aml/QKNBbMsAEoAfYcxYQVKcARdon9h.png"></p><h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3><ul><li><p>标准 BP 算法</p><ul><li>每次对单个训练样例更新权值和阈值；单次计算开销小，但参数更新频繁，不同样例可能会相互冲突，迭代次数较多</li></ul></li><li><p>累计 BP 算法</p><ul><li>最小化整个训练集上的累计误差$E &#x3D; \frac{1}{m}\sum_{k&#x3D;1}^mE_k$</li><li>读取整个训练集后对更新参数，参数更新频率低，但单次计算开销大</li></ul></li></ul><h3 id="多层前馈网络优缺点"><a href="#多层前馈网络优缺点" class="headerlink" title="多层前馈网络优缺点"></a>多层前馈网络优缺点</h3><ul><li><p>强大的学习能力：多行足够多的神经元的隐层，多层前馈神经网络能以任意精度逼近任意复杂度的连续函数</p></li><li><p>局限</p><ul><li>经常过拟合</li><li>如何设置隐层神经元个数是个难题</li></ul></li><li><p>缓解过拟合的策略</p><ul><li>早停：训练过程中，若训练误差降低，但验证误差身高，则停止训练</li><li>正则化：在误差目标函数中增加一项描述网络复杂程度的成分，防止模型过于复杂</li></ul></li></ul><h2 id="全局最小与局部最小"><a href="#全局最小与局部最小" class="headerlink" title="全局最小与局部最小"></a>全局最小与局部最小</h2><ul><li>跳出局部最小的常见策略<ul><li>模拟退火</li><li>不同的初始参数</li><li>随机扰动</li><li>遗传算法</li></ul></li></ul><h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><ul><li><p>深度学习模型是具有很多个隐层的神经网络</p></li><li><p>增加模型复杂程度的方式</p><ul><li>模型宽度：增加隐层神经元的数目</li><li>模型深度：增加隐层数目</li><li>实际应用中，增加模型深度比增加宽度相对更有效</li></ul></li></ul><h3 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h3><ul><li><p>预训练 + 微调</p><ul><li>预训练：监督逐层，每次训练时间上一层隐层结构的输出作为输入，本层隐节点的输出作为输出，仅训练一层网络</li><li>微调：预训练全部完成后，对整个网络进行微调训练，一般采用 BP 算法</li></ul></li><li><p>权共享</p><ul><li>一组神经元使用相同的连接权值</li></ul></li></ul><h3 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><ul><li>卷积层：每个卷积层包含多个特征映射，每个特征映射通过一种卷积滤波器提取一种数据的特征</li><li>采样层：也叫作汇合层，其作用是基于局部相关性原理进行亚采样，从而在减少数据量的同时保留有用信息</li><li>连接层：每个神经元被全连接到上一层每个神经元，本质就是传统的神经网络，其目的是通过连接层和输出层的连接完成识别任务</li></ul><h1 id="第六讲-决策树"><a href="#第六讲-决策树" class="headerlink" title="第六讲 决策树"></a>第六讲 决策树</h1><h2 id="基本流程"><a href="#基本流程" class="headerlink" title="基本流程"></a>基本流程</h2><ul><li><p>策略：分而治之</p></li><li><p>递归过程：每个中间节点寻找一个划分属性</p></li><li><p>三种停止条件</p><ul><li>当前节点包含的样本全属于同一类别，无需划分</li><li>当前属性集为空，或是所有样本在所有属性上取值相同，无法划分</li><li>当前结点包含的样本集合为空，不能划分</li></ul></li></ul><h2 id="划分选择"><a href="#划分选择" class="headerlink" title="划分选择"></a>划分选择</h2><h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>$$<br>Gain(D,a) &#x3D; Ent(D)-\sum_{v&#x3D;1}^V\frac{|D^v|}{|D|}Ent(D^v)<br>$$</p><ul><li><p>信息熵</p><ul><li>度量样本集合纯度最常用的一种指标，假定当前样本第 k 类样本所占比例为$p_k(k&#x3D;1,2,…,|\gamma|)$，则 D 的信息熵定义为</li><li>$$<br>Ent(D) &#x3D; -\sum_{k&#x3D;1}^{|\gamma|}p_k\log_2p_k<br>$$</li><li>$Ent(D)$的值越少，$D$的纯度越高</li></ul></li><li><p>ID3</p><ul><li>信息增益越大，意味着使用属性 a 来进行划分所获得的纯度提升最大</li><li>可以用信息增益来进行决策树的划分属性选择</li></ul></li><li><p>信息增益偏好取值数多的属性</p></li></ul><p><img src="/../assets/aml/QX0yb8X6OoiZfIxW7xMcIqE9nAb.png"></p><h3 id="增益率"><a href="#增益率" class="headerlink" title="增益率"></a>增益率</h3><ul><li><p>C4.5</p><ul><li>信息增益准则对可取值数目较多的属性有偏好，会带来不利影响</li><li>不直接使用信息增益，而是用信息增益率</li><li>$$<br>Gain_ratio(D,a)&#x3D;\frac{Gain(D,a)}{IV(a)}<br>$$</li><li>$$<br>IV(a) &#x3D; -\sum_{v&#x3D;1}^V\frac{|D^v|}{|D|}\log_2\frac{|D^v|}{|D|}<br>$$</li></ul></li><li><p>增益率准则偏好取值数较少的属性</p></li></ul><h2 id="过拟合和剪枝"><a href="#过拟合和剪枝" class="headerlink" title="过拟合和剪枝"></a>过拟合和剪枝</h2><ul><li><p>决策树的不足：过拟合</p><ul><li>决策树的 决策分支较多，以至于把训练集自身的一些特点当作所有数据都具有一般性质而导致的过拟合</li></ul></li><li><p>剪枝的基本策略</p><ul><li>预剪枝：边建树，边剪枝</li><li>后剪枝：先建树，后剪枝</li></ul></li></ul><h3 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h3><ul><li><p>决策树生成过程中，对每个节点在划分前先进行估计，若当前节点的划分不能带来决策树泛化性能提升，则停止划分并将当前节点标记为叶节点，其类别标记为训练样例数最多的类别</p></li><li><p>优点</p><ul><li>降低过拟合的风险</li><li>显著减少训练时间和测试时间的开销</li></ul></li><li><p>缺点</p><ul><li>欠拟合。单看一步划分虽然不能提升泛化性能，但多看几步有可能提高性能</li><li>基于贪心本质禁止分支展开，带来欠拟合风险</li></ul></li></ul><h3 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h3><ul><li><p>优点</p><ul><li>保留了更多的分支，欠拟合风险小，泛化性能往往优于预剪枝决策树</li></ul></li><li><p>缺点</p><ul><li>训练时间开销大</li></ul></li></ul><h2 id="多变量决策树"><a href="#多变量决策树" class="headerlink" title="多变量决策树"></a>多变量决策树</h2><ul><li>单变量决策树分类边界：轴平行</li><li>多变量决策树</li></ul><h1 id="第七讲-贝叶斯分类器"><a href="#第七讲-贝叶斯分类器" class="headerlink" title="第七讲 贝叶斯分类器"></a>第七讲 贝叶斯分类器</h1><h2 id="贝叶斯决策论"><a href="#贝叶斯决策论" class="headerlink" title="贝叶斯决策论"></a>贝叶斯决策论</h2><p>给定$N$个类别，令$\lambda_{ij}$代表将第$j$类样本误分为第$i$类所产生的损失，则基于后验概率将样本$x$分到第$j$类的风险为</p><p>$$<br>R(c_i|x) &#x3D; \sum_{j&#x3D;1}^N\lambda_{ij}P(c_j|x)<br>$$</p><ul><li><p>贝叶斯判定法则</p><ul><li><p>$$<br>h^*(x) &#x3D; \argmin_{c\in \gamma}R(c|x)<br>$$</p><ul><li>$h^*$称为贝叶斯最优分类器，其总体风险称为贝叶斯风险</li><li>反映了学习性能的理论上限</li></ul></li><li><p>贝叶斯的核心工作:$P(c|x)$，但是很不好求</p></li></ul></li><li><p>转化</p><ul><li><p>$$<br>P(c|x) &#x3D; \frac{P(c)P(x|c)}{P(x)}<br>$$</p><ul><li>可以假定每个样本出现概率一样</li><li>每个样本的频率可以算</li><li>所以只需要基于分类，判断一个样本的概率即可</li><li>还是不好算<ul><li>在于$x$的维度可能会很大，会存在组合爆炸</li></ul></li></ul></li></ul></li></ul><h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><p>主要障碍，所有属性上的联合概率难以从有限训练样本估计获得</p><ul><li><p>$$<br>P(c|x) &#x3D; \frac{P(c)P(x|c)}{P(x)} &#x3D; \frac{P(c)}{P(x)}\prod_{i&#x3D;1}^dP(x_i|c)<br>$$</p><ul><li>$d$为属性数，$x_i$为$x$在第$i$个属性上的取值</li><li>$P(x)$对所有类别相同，于是$h_{nb}(x) &#x3D; \argmax_{c\in \gamma}P(c)\prod_{i&#x3D;1}^dP(x_i|c)$</li></ul></li><li><p>估计$P(c) &#x3D; \frac{|D_c|}{|D|}$</p></li><li><p>估计$P(x|c)$</p><ul><li>对离散属性，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则$P(x_i|c) &#x3D; \frac{|D_{c,x_i}|}{|D_c|}$</li><li>对连续属性，考虑概率密度函数，假定$p(x_i|c) \sim N(\mu_{c,i},\sigma^2_{c,i})$</li></ul></li><li><p>拉普拉斯修正</p><ul><li>若某个属性值在训练集中没有与某个类同时出现过，则直接计算会出现问题，因为概率连乘会抹去其他属性提供的信息</li><li>令$N$表示训练集$D$中可能得类别数，$N_i$表示第$i$个属性可能得取值数<ul><li>$$<br>\hat P(c) &#x3D; \frac{|D_c|+1}{|D|+N}<br>$$</li><li>$$<br>\hat P(x_i|c) &#x3D; \frac{|D_{c,x_i}|+1}{|D_c|+N_i}<br>$$</li></ul></li></ul></li><li><p>使用</p><ul><li>若对预测速度要求高<ul><li>预计算所有概率估值，使用的时候查表</li></ul></li><li>若数据更替频繁<ul><li>不进行任何训练，收到预测请求时再估值（懒惰学习）</li></ul></li><li>若数据不断增加<ul><li>基于现有估值，对新样本涉及的概率估值进行修正（增量学习）</li></ul></li></ul></li></ul><h2 id="半朴素贝叶斯"><a href="#半朴素贝叶斯" class="headerlink" title="半朴素贝叶斯"></a>半朴素贝叶斯</h2><ul><li><p>基本思路：适当考虑一部分属性间的相互依赖信息</p></li><li><p>最常用策略：ODE</p><ul><li>$$<br>P(c|x) \propto P(c)\prod_{i&#x3D;1}^dP(x_i|c,pa_i)<br>$$</li></ul></li><li><p>两种常见方法</p><ul><li>SPODE<ul><li>假设所有属性都依赖于同一属性，称为超父，然后通过交叉验证登模型选择方法来确定超父属性</li></ul></li><li>TAN<ul><li>以属性间的条件互信息为边的权重，构建完全图，再利用最大带权生成树算法，仅保留强相关属性间的依赖性</li></ul></li></ul></li></ul><h2 id="贝叶斯网络"><a href="#贝叶斯网络" class="headerlink" title="贝叶斯网络"></a>贝叶斯网络</h2><ul><li><p>贝叶斯网：$B &#x3D; &lt;G,\Theta&gt;$</p></li><li><p>概率图模型</p><ul><li>有向图模型-&gt; 贝叶斯网</li><li>无向图模型-&gt; 马尔科夫网</li></ul></li></ul><h1 id="第八讲-集成学习"><a href="#第八讲-集成学习" class="headerlink" title="第八讲 集成学习"></a>第八讲 集成学习</h1><h2 id="个体与集成"><a href="#个体与集成" class="headerlink" title="个体与集成"></a>个体与集成</h2><ul><li><p>定义：集成学习通过多学习器来提升性能</p></li><li><p>理想情况</p><ul><li>假设基分类器的错误率为$P(h_i(x)\neq f(x)) &#x3D; \epsilon$</li><li>投票法结合$T$个分类器，超过半数的基分类器正确则分类就正确$H(x) &#x3D; sign(\sum_{i&#x3D;1}^{T}h_i(x))$</li><li>假设基分类器的错误率相互独立，则由 Hoeffding 不等式可得$P(H(x)\neq f(x)) \le exp(-\frac{1}{2}T(1-2\epsilon)^2)$</li><li>在一定条件下，随着集成分类器的数目增加，集成的错误率将指数级下降</li></ul></li><li><p>现实</p><ul><li>关键假设：基分类器的误差相互独立</li><li>现实任务重，个体学习器来自同一个问题，不可能完全独立</li><li>事实上，个体学习器的准确性和多样性本身就存在冲突</li><li>如何产生好而不同的个体学习器是集成学习研究的核心</li><li>集成学习大致可以分为两大类：串行和并行</li></ul></li></ul><h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><ul><li>每次调整训练数据的样本分布</li><li>串行生成</li><li>个体学习器存在强依赖关系</li></ul><p><img src="/../assets/aml/VwaQb5atMo9imJx1e7YcodCinLg.png"></p><h3 id="AdaBoost-推导"><a href="#AdaBoost-推导" class="headerlink" title="AdaBoost 推导"></a>AdaBoost 推导</h3><ul><li>基学习器的线性组合$H(x) &#x3D; \sum_{t&#x3D;1}^{T}\alpha_th_t(x)$</li><li>最小化指数损失函数$\ell_{exp}(H|D) &#x3D; E_{x\sim D}[e^{-f(x)H(x)}]$</li><li>令上式对的 H 的偏导值为 0，即$\frac{\partial\ell_{exp}(H|D)}{\partial H(x)} &#x3D; -e^{-H(x)}P(f(x) &#x3D; 1|x) + e^{H(x)}P(f(x)&#x3D;-1|x)$</li></ul><h2 id="Bagging-与随机森林"><a href="#Bagging-与随机森林" class="headerlink" title="Bagging 与随机森林"></a>Bagging 与随机森林</h2><ul><li>个体学习不存在强依赖关系</li><li>并行化生成</li><li>自主采样法</li><li>时间复杂度低</li><li>可使用包外估计</li></ul><h3 id="包外估计"><a href="#包外估计" class="headerlink" title="包外估计"></a>包外估计</h3><ul><li>$H^{oob}(x)$表示对样本$x$的包外预测，即仅考虑那些未使用样本$x$训练的基学习器在$x$上的预测$H^{oob}(x) &#x3D; \argmax_{y\in \gamma}\sum_{t&#x3D;1}^T|h_t(x)&#x3D;y|*|x\notin D_t|$</li></ul><h2 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h2><h3 id="投票法"><a href="#投票法" class="headerlink" title="投票法"></a>投票法</h3><ul><li>绝对多数投票法</li><li>相对多数投票法</li><li>加权投票法</li></ul><h3 id="学习法"><a href="#学习法" class="headerlink" title="学习法"></a>学习法</h3><ul><li>Stacking</li></ul><h2 id="多样性"><a href="#多样性" class="headerlink" title="多样性"></a>多样性</h2><ul><li>数据样本扰动</li><li>输入属性扰动</li><li>输出表示扰动</li><li>算法参数扰动</li></ul><h1 id="第九讲-聚类"><a href="#第九讲-聚类" class="headerlink" title="第九讲 聚类"></a>第九讲 聚类</h1><h2 id="聚类任务"><a href="#聚类任务" class="headerlink" title="聚类任务"></a>聚类任务</h2><ul><li>目标：将数据样本划分为若干个通常不相交的簇</li></ul><h2 id="性能度量-1"><a href="#性能度量-1" class="headerlink" title="性能度量"></a>性能度量</h2><ul><li><p>外部指标</p><ul><li>将聚类结果与某个参考模型进行比较，Jaccard 系数、FM 指数，Rand 指数</li></ul></li><li><p>内部指标</p><ul><li>直接参考聚类结果，DB 指数，Dunn 指数等</li></ul></li><li><p>基本想法：</p><ul><li>簇内相似度高且簇间相似度低</li></ul></li></ul><h2 id="距离计算"><a href="#距离计算" class="headerlink" title="距离计算"></a>距离计算</h2><ul><li><p>距离度量需要满足的基本性质</p><ul><li>非负性：$dist(x_i,x_j) \ge 0$</li><li>同一性：$dist(x_i,x_j) &#x3D; 0$当且仅当$x_i&#x3D;x_j$</li><li>对称性：$dist(x_i,x_j) &#x3D; dist(x_j,x_i)·$</li><li>直递性：$dist(x_i,x_j) \le dist(x_i,x_k)+dist(x_k,x_j)$</li></ul></li><li><p>常用距离公式</p><ul><li>闵可夫斯基距离$dist_{mk}(x_i,x_j) &#x3D; (\sum_{u&#x3D;1}^n|x_{iu}-x_{ju}|^p)^{\frac{1}{p}}$</li><li>$p&#x3D;2$欧氏距离</li><li>$p&#x3D;1$曼哈顿距离</li></ul></li><li><p>对无序属性，可使用 VDM</p><ul><li>令$m_{u，a}$表示属性$u$上取值为$a$的样本数，$m_{u,a,i}$表示在第$i$个样本簇中在属性$u$上取值为$a$的样本数，$k$为样本簇数，则属性$u$上两个离散值$a$与$b$之间的 VDM 距离为$VDM_p(a,b) &#x3D; \sum_{i&#x3D;1}^k|\frac{m_{u,a,i}}{m_{u,a}} - \frac{m_{u,b,i}}{m_{u,b}}|^p$</li></ul></li><li><p>对混合属性，可使用 MinkovVDM</p><ul><li>$$<br>MinkovDM_p(x_i,x_j) &#x3D; (\sum_{u&#x3D;1}^{n_c}|x_{iu}-x_{j,u}|^p + \sum_{u&#x3D;n_c+1}^n VDM_p(x_{i,u},x_{j,u}))^{\frac{1}{p}}<br>$$</li></ul></li><li><p>聚类的好坏没有绝对标准</p></li></ul><h2 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h2><h3 id="k-means"><a href="#k-means" class="headerlink" title="k-means"></a>k-means</h3><ul><li>每个簇中心以该簇中所有样本点的均值表示<ul><li>随机选取$k$个样本中心点作为簇中心</li><li>将其他样本点根据其与簇中心的距离，划分给最近的簇</li><li>更新各簇的均值向量，将其作为新的簇中心</li><li>若所有的簇中心未发生改变，则停止；否则执行步骤 2</li></ul></li></ul><h3 id="学习向量量化（LVQ）"><a href="#学习向量量化（LVQ）" class="headerlink" title="学习向量量化（LVQ）"></a>学习向量量化（LVQ）</h3><ul><li>也是试图找到一组原型向量来刻画聚类结构，但数据样本带有类别标记</li></ul><p><img src="/../assets/aml/DmbPbsMf5o6D1BxOco9cTkJKnoc.png"></p><h3 id="高斯混合聚类（GMM）"><a href="#高斯混合聚类（GMM）" class="headerlink" title="高斯混合聚类（GMM）"></a>高斯混合聚类（GMM）</h3><ul><li>采用高斯概率分布来表达聚类原型，簇中心&#x3D;均值，簇半径&#x3D;方差</li></ul><h2 id="密度聚类"><a href="#密度聚类" class="headerlink" title="密度聚类"></a>密度聚类</h2><h3 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h3><ul><li>关键概念<ul><li>核心对象：若$x_j$的$\epsilon$-邻域至少包含$MinPts$个样本，即$|N_{\epsilon}(x_j)| \ge MinPts$，则$x_j$是一个核心对象</li><li>密度直达：若$x_j$位于$x_i$的$\epsilon$-领域中，且$x_i$是核心对象，则称$x_j$由$x_i$密度直达</li><li>密度可达：对$x_i$与$x_j$，若存在样本序列$p_1,p_2,\dots,p_n$其中$p_1&#x3D;x_i$，$p_n&#x3D;x_j$且$p_{i+1}$由$p_i$密度直达，则称$x_j$由$x_i$密度可达</li><li>密度相连</li></ul></li></ul><h2 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h2><h3 id="AGNES"><a href="#AGNES" class="headerlink" title="AGNES"></a>AGNES</h3><ul><li>从最细的粒度开始（一个样本一个簇），逐渐合并相似的簇，知道最粗的粒度（所有样本一个簇）<ul><li>将每个样本点作为一个簇</li><li>合并最近的两个簇</li><li>若所有样本点都存在于一个簇中，则停止；否则继续步骤 2</li></ul></li></ul><h1 id="第十章-降维与度量学习"><a href="#第十章-降维与度量学习" class="headerlink" title="第十章 降维与度量学习"></a>第十章 降维与度量学习</h1><h2 id="k-近邻学习"><a href="#k-近邻学习" class="headerlink" title="k-近邻学习"></a>k-近邻学习</h2><ul><li><p>k 近邻学习室懒惰学习的代表</p><ul><li>懒惰学习：事先没有分类器，见到测试样本才开始准备分类器</li></ul></li><li><p>基本思路</p><ul><li>近朱者赤，近墨者黑</li><li>关键：k 值选取，距离计算</li></ul></li><li><p>重要性质</p><ul><li>给定测试样本 x，若其最近样本为 z，则最近邻分类器出错的概率就是 x 和 z 类别标记不同的概率<ul><li>$$<br>\begin{aligned}<br>P(err) &amp;&#x3D; 1-\sum_{c\in \gamma}P(c|x)P(c|z) \<br>&amp;\simeq 1-\sum_{c\in \gamma}P^2(c|x) \<br>&amp;\le 1-P^2(c^*|x) \<br>&amp;&#x3D; (1+P(c^*|x))(1-P(c^*|x)) \<br>&amp;\le 2\times (1-P(c^*|x)<br>\end{aligned}<br>$$</li></ul></li></ul></li><li><p>维数灾难</p><ul><li>高维空间给距离计算带来很大的麻烦</li><li>样本变得稀疏，近邻容易不准</li></ul></li></ul><h2 id="低维嵌入"><a href="#低维嵌入" class="headerlink" title="低维嵌入"></a>低维嵌入</h2><h3 id="多维缩放方法（MDS）"><a href="#多维缩放方法（MDS）" class="headerlink" title="多维缩放方法（MDS）"></a>多维缩放方法（MDS）</h3><ul><li><p>MDS 旨在寻找一个低维子空间，使得距离和样本原有距离近似不变</p></li><li><p>寻找低维子空间尽量保持样本内积不变</p><ul><li>思路：特征值分解</li><li>设样本之间的内积矩阵均为 B，对 B 进行特征值分解：$B &#x3D; V\Lambda V^T$</li></ul></li></ul><h2 id="流形学习"><a href="#流形学习" class="headerlink" title="流形学习"></a>流形学习</h2><h3 id="ISOMAP"><a href="#ISOMAP" class="headerlink" title="ISOMAP"></a>ISOMAP</h3><ul><li>基本步骤<ul><li>构造近邻图</li><li>基于最短路径算法近似任意两点之间的测地线距离</li><li>基于距离矩阵通过 MDS 获得低维嵌入</li></ul></li></ul><h3 id="LLE"><a href="#LLE" class="headerlink" title="LLE"></a>LLE</h3><ul><li>基本步骤<ul><li>为每个样本构造近邻集合$Q_i$</li><li>为每个样本计算基于$Q_i$的线性重构系数：$\min_{w_1,w_2,\dots,w_m} \sum_{i&#x3D;1}^m\lVert x_i-\sum_{j\in Q_i}w_{ij}x_j \rVert^2_2 \quad s.t. \sum_{j\in Q_i}w_{ij} &#x3D; 1$</li><li>在低维空间中保持$w_{ij}$不变，求解下式$\min_{z_1,z_2,\dots,z_m} \sum_{i&#x3D;1}^m\lVert z_i-\sum_{j\in Q_i}w_{ij}z_j \rVert^2_2$</li></ul></li></ul><h2 id="度量学习"><a href="#度量学习" class="headerlink" title="度量学习"></a>度量学习</h2><p>降维希望找到一个合适低维空间下的距离度量</p><ul><li><p>能够通过参数化来学习距离度量</p><ul><li>马氏距离$dist^2_{mah}(x_i,x_j) &#x3D; (x_i-x_j)^TM(x_i-x_j) &#x3D; \lVert x_i-x_j\rVert^2_M$</li></ul></li><li><p>欧氏距离</p><ul><li>缺陷：各个方向同等重要</li></ul></li></ul><h2 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析 PCA"></a>主成分分析 PCA</h2><ul><li><p>正交属性空间中的样本点，如何使用一个超平面对所有样本进行恰当的表达</p></li><li><p>若存在这样的超平面，那么它大概具有这样的性质</p><ul><li>最近重构性：样本点到这个超平面的距离都足够近</li><li>最大可分性：样本点在这个超平面上的投影能尽可能分开</li></ul></li></ul><h3 id="最近重构性"><a href="#最近重构性" class="headerlink" title="最近重构性"></a>最近重构性</h3><ul><li>对样本进行中心化：$\sum_ix_i &#x3D; 0$</li><li>假定投影变换后得到的新坐标系为${\omega_1,\omega_2,\dots,\omega_d}$，其中$\omega_i$是标准正交基向量：$\lVert \omega_i\rVert_2 &#x3D; 1, \omega_i^T\omega_j &#x3D; 0(i\neq j)$</li><li>若丢弃新坐标系中的部分坐标，即将维度降低到$d^{\prime}\lt d$则样本点在低维坐标系中的投影是$z_i &#x3D; (z_{i1};z_{i2};\dots;z_{id^{\prime}}) \quad z_{ij} &#x3D; \omega_j^Tx_i$</li><li>若基于$z_i$来重构$x_i$，则会得到$\hat x_i &#x3D; \sum_{j&#x3D;1}^{d^{\prime}}z_{ij}\omega_j$</li><li>原样本点$x_i$与基于投影重构的样本点$\hat x_i$之间的距离为:$\sum_{i&#x3D;1}^m\lVert\sum_{j&#x3D;1}^{d^{\prime}}z_{ij}w_j - x_i\rVert^2_2 &#x3D; \sum_{i&#x3D;1}^mz_i^Tz_i - 2\sum_{i&#x3D;1}^mz_i^TW^Tx_i+const \propto -tr(W^T(\sum_{i&#x3D;1}^mx_ix_i^T)W)$</li></ul><h3 id="最大可分性"><a href="#最大可分性" class="headerlink" title="最大可分性"></a>最大可分性</h3><ul><li>样本点$x_i$在新空间中超平面上的投影是$W^Tx$，若所有样本点的投影尽可能分开，则应该是的投影后的样本方差最大化</li></ul>]]></content>
    
    
    <categories>
      
      <category>南大</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>面试常问问题</title>
    <link href="/2024/05/28/interview/"/>
    <url>/2024/05/28/interview/</url>
    
    <content type="html"><![CDATA[<h2 id="项目篇"><a href="#项目篇" class="headerlink" title="项目篇"></a>项目篇</h2><blockquote><p>Faasit项目有什么难点 or 创新点 ？</p></blockquote><ul><li><p>首先Faasit项目我负责了几个模块，分别有部署模块、运行时模块、AI训练模块</p><ul><li><p>部署模块中我遇到的难点有原生的<code>Knative</code>部署非常慢并且有着国内的网络问题，于是我通过<code>kn</code>的API自己搭建了一套<code>kn</code>的部署方案</p><ul><li><p>方案中的创新点包括：使用base镜像+代码目录映射的方式进行部署，可以加快部署的效率</p></li><li><p>方案中的难点包括：</p><ul><li><code>k8s</code>or<code>kn</code>并不支持像<code>docker</code>那样的目录映射功能</li><li><code>kn</code>支持持久化卷<code>pvc</code>，但要求那个卷是只读的，而我们需要可读可写的（因为要上传代码）</li></ul></li></ul></li><li><p>运行时模块中遇到的难点包括 <code>durable function</code> 模型的设计，由于不像<code>Azure</code>一样有一个事件机制，因此只能手动模拟一个调用堆栈</p></li></ul></li></ul><blockquote><p>你在项目中用到了哪些设计模式</p></blockquote><ul><li><p>工厂方法</p><ul><li>不同的运行时行为不同，我定义了一个<code>create_handler</code>方法创建对应平台的运行时</li></ul></li><li><p>生成器模式</p><ul><li>设计<code>workflow</code>的时候其需要指定较多的函数，使用了一个<code>builder</code>实现<code>workflow</code>的构建</li><li>实现函数状态类的时候，有一个<code>DurableFunctionState</code>类以及<code>ScopedClient</code>类，以此做不同类型的状态存储</li></ul></li><li><p>单例模式</p></li><li><p>适配器模式</p><ul><li>将一个函数适配到多个平台使用了</li></ul></li></ul><h2 id="后端篇"><a href="#后端篇" class="headerlink" title="后端篇"></a>后端篇</h2><blockquote><p>有用户说他登录不上某个网页了，你该怎么排查</p></blockquote><ul><li><p>可能的原因</p><ul><li>服务器出口带宽不够用。</li><li>服务器过载太大忙不过来，CPU或内存消耗完了</li><li>代码没写好，MySQL语句没有优化</li><li>数据库瓶颈，数据库太大了</li></ul></li><li><p>排查方法</p><ul><li>自己先打开一下，看看是服务端的问题还是客户端的问题</li><li>使用浏览器的调试功能查看是哪个数据加载的太慢</li><li>看一下硬件资源（带宽，CPU和内存）</li><li>如果硬件资源消耗都不高，看一下日志</li></ul></li></ul><blockquote><p>Redis是如何加锁的</p></blockquote><ul><li><p>Redis的SET命令有个NX参数可以实现”当key不存在的时候才插入”，所以可以用它来实现分布式锁</p><ul><li>如果<code>key</code>不存在，则显示插入成功，可以用来表示加锁成功</li><li>如果<code>key</code>存在，则显示插入失败，可以用来表示加锁失败</li></ul></li><li><p>Redis实现分布式锁时，对于加锁操作，需要满足3个条件</p><ul><li>加锁包括了读取锁变量、检测锁变量和设置锁变量的操作，因此他们必须是原子的，可以使用SET命令带上NX选项实现加锁</li><li>锁变量需要设置过期时间，以免客户端拿到锁后发生异常</li><li>锁变量的值需要能够区分来自不同客户端的加锁操作，使用SET命令设置锁变量值时，每个客户端设置的值是一个唯一值</li></ul></li></ul><blockquote><p>https</p></blockquote><ul><li><p>解决的HTTP的问题</p><ul><li>信息加密：交互信息无法被窃取</li><li>校验机制：无法篡改通信内容，篡改了就无法显示了</li><li>身份证书：验证访问的对象是不是真的对象</li></ul></li></ul><blockquote><p>能不能写一个CPU消耗为100%的程序，50%呢</p></blockquote><ul><li>100%运行的只要<code>while(1)</code>就好了</li><li>50%的可以设置忙等时间和休息时间相等，忙等时间就可以写不断地获取时间，计算忙等的时间够不够了</li></ul><blockquote><p>你去办卡接入了一个网络，你怎么判断你连接到的网络是不是安全的</p></blockquote><ul><li><p>检查网络配置</p><ul><li>使用加密协议，确保无限网络使用了加密协议</li><li>检查路由器确保更改了默认的用户名和密码</li></ul></li><li><p>验证证书和加密</p><ul><li>https</li><li>DNS</li></ul></li></ul><blockquote><p>你连接到一个网络之后打开淘宝之类的APP，使用HTTP协议输入用户名和密码，会导致密码泄露吗</p></blockquote><ul><li>不安全，因为http协议是明文传输，这意味着数据在传输过程中可以被拦截和读取</li></ul><blockquote><p>如果是在登录态访问淘宝，会有密码泄露吗？</p></blockquote><ul><li><p>会话劫持</p><ul><li>可以获取会话令牌</li><li>中间人攻击</li></ul></li><li><p>重放攻击</p></li></ul><blockquote><p>使用了https，有可能发生密码泄露吗？</p></blockquote><ul><li>会的，中间服务器伪造证书，但是会提示用户是否信任中间证书，怕危险就不要点，本质上是不会泄露的。</li></ul><blockquote><p>数据库的范式有哪些</p></blockquote><ul><li><p>第一范式——无重复列</p><ul><li>每一列都是不可分割的基本数据项</li></ul></li><li><p>第二范式——属性完全依赖于主键（消除部分子函数依赖）</p><ul><li>满足第一范式的基础上，每一个非主属性完全函数依赖于某个候选键</li><li>例如如果有属性学号、课程名称、成绩、学分的属性，那就不满足，因为学分不完全依赖于学号</li></ul></li><li><p>第三范式——属性不依赖于其他非主属性（消除传递依赖）</p><ul><li>每个非主属性都不传递依赖于候选键</li></ul></li><li><p>BCNF范式</p><ul><li>数据库表中的每个属性都不传递依赖于候选键</li></ul></li><li><p>第四范式</p><ul><li>非主属性不应该有多值</li></ul></li><li><p>第五范式</p><ul><li>表必须可以分解为较小的表</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>面试</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch 面经</title>
    <link href="/2024/05/13/pytorch/"/>
    <url>/2024/05/13/pytorch/</url>
    
    <content type="html"><![CDATA[<h2 id="PyTorch-概述"><a href="#PyTorch-概述" class="headerlink" title="PyTorch 概述"></a>PyTorch 概述</h2><p>PyTorch 是一个开源的机器学习库，广泛应用于计算机视觉和自然语言处理等领域</p><p>PyTorch 的两个高级功能</p><ul><li>强大的GPU加速的张量计算（Numpy）</li><li>包含自动求导系统的深度神经网络</li></ul><p>PyTorch的核心特性</p><ul><li>动态计算图：使用动态计算图（命令式编程模型），计算图在每次运行的时候都会重新构建。使得模型比较灵活</li><li>自动微分系统：PyTorch 的<code>torch.autograd</code> 提供了自动微分的功能，可以自动计算导数和梯度</li></ul><h2 id="PyTorch-与深度学习"><a href="#PyTorch-与深度学习" class="headerlink" title="PyTorch 与深度学习"></a>PyTorch 与深度学习</h2><h3 id="Tensors-张量"><a href="#Tensors-张量" class="headerlink" title="Tensors 张量"></a>Tensors 张量</h3><p>在PyTorch中使用tensors来对模型的输入、输出和模型参数进行编码。<br>与Numpy的ndarrays相比，tensors可以运行在多GPU上以及其他的硬件上，拥有比Numpy更高的效率</p><h4 id="Tensors-初始化"><a href="#Tensors-初始化" class="headerlink" title="Tensors 初始化"></a>Tensors 初始化</h4><ul><li>直接通过<code>data</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">data = [[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]]<br>x_data = torch.tensor(data)<br></code></pre></td></tr></table></figure><ul><li>通过Numpy 数组</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">np_array = np.array(data)<br>x_np = torch.from_numpy(np_array)<br></code></pre></td></tr></table></figure><ul><li>从其他的tensor</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">x_ones = torch.ones_like(x_data) <span class="hljs-comment"># 维持原有的数据类型</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],<br>[<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]])<br><br>x_rand = torch.rand_like(x_data, dtype=torch.<span class="hljs-built_in">float</span>) <span class="hljs-comment"># 重写了数据类型</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>tensor([[<span class="hljs-number">0.8823</span>, <span class="hljs-number">0.9150</span>],<br>        [<span class="hljs-number">0.3829</span>, <span class="hljs-number">0.9593</span>]])<br></code></pre></td></tr></table></figure><ul><li>通过随机或常量值</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">shape = (<span class="hljs-number">2</span>, <span class="hljs-number">3</span>,)<br>rand_tensor = torch.rand(shape)<br>ones_tensor = torch.ones(shape)<br>zeros_tensor = torch.zeros(shape)<br><span class="hljs-meta">&gt;&gt;&gt; </span>Random Tensor:<br> tensor([[<span class="hljs-number">0.3904</span>, <span class="hljs-number">0.6009</span>, <span class="hljs-number">0.2566</span>],<br>        [<span class="hljs-number">0.7936</span>, <span class="hljs-number">0.9408</span>, <span class="hljs-number">0.1332</span>]])<br><br><span class="hljs-meta">&gt;&gt;&gt; </span>Ones Tensor:<br> tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br><br><span class="hljs-meta">&gt;&gt;&gt; </span>Zeros Tensor:<br> tensor([[<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>        [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>]])<br></code></pre></td></tr></table></figure><h4 id="Tensors-属性"><a href="#Tensors-属性" class="headerlink" title="Tensors 属性"></a>Tensors 属性</h4><p>Tensors的属性描述了他们的形状、数据类型以及他们存放的设备</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor = torch.rand(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Shape of tensor: <span class="hljs-subst">&#123;tensor.shape&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Datatype of tensor: <span class="hljs-subst">&#123;tensor.dtype&#125;</span>&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Device tensor is stored on: <span class="hljs-subst">&#123;tensor.device&#125;</span>&quot;</span>)<br><br><span class="hljs-meta">&gt;&gt;&gt; </span><br>Shape of tensor: torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br>Datatype of tensor: torch.float32<br>Device tensor <span class="hljs-keyword">is</span> stored on: cpu<br></code></pre></td></tr></table></figure><h4 id="Tensor-操作"><a href="#Tensor-操作" class="headerlink" title="Tensor 操作"></a>Tensor 操作</h4><ul><li>运行在GPU上</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># We move our tensor to the GPU if available</span><br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>  tensor = tensor.to(<span class="hljs-string">&#x27;cuda&#x27;</span>)<br>  <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Device tensor is stored on: <span class="hljs-subst">&#123;tensor.device&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><ul><li>行列操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor = torch.ones(<span class="hljs-number">4</span>,<span class="hljs-number">4</span>)<br>tensor[:,<span class="hljs-number">1</span>] = <span class="hljs-number">0</span><br><br><span class="hljs-meta">&gt;&gt;&gt; </span><br>tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br></code></pre></td></tr></table></figure><ul><li>拼接操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">t1 = torch.cat([tensor, tensor, tensor], dim=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(t1)<br><br><span class="hljs-meta">&gt;&gt;&gt; </span><br>tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br></code></pre></td></tr></table></figure><ul><li>置换操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(tensor, <span class="hljs-string">&quot;\n&quot;</span>)<br>tensor.add_(<span class="hljs-number">5</span>)<br><span class="hljs-built_in">print</span>(tensor)<br><br>&gt;&gt;&gt;<br>tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>],<br>        [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]])<br><br>tensor([[<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],<br>        [<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],<br>        [<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>],<br>        [<span class="hljs-number">6.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">6.</span>]])<br></code></pre></td></tr></table></figure><h3 id="torch-autograd"><a href="#torch-autograd" class="headerlink" title="torch.autograd"></a><code>torch.autograd</code></h3><h4 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h4><p>神经网络（NN）是在某些输入数据上执行的嵌套函数的集合。这些函数（W）通过参数进行定义，在PyTorch中通过张量进行保存</p><p>训练一个神经网络通常有两个步骤</p><ul><li><strong>前向传播</strong>：NN猜测输入的最可能输出，将输入传递到定义的几个函数</li><li><strong>反向传播</strong>：NN根据猜测值的误差调整自己的参数，通过梯度下降法优化参数</li></ul><h4 id="在-PyTorch-的使用"><a href="#在-PyTorch-的使用" class="headerlink" title="在 PyTorch 的使用"></a>在 PyTorch 的使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torchvision.models <span class="hljs-keyword">import</span> resnet18, ResNet18_Weights<br>model = resnet18(weight=ResNet18_Weights.DEFAULT)<br>data = torch.rand(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">64</span>,<span class="hljs-number">64</span>)<br>labels = torch.rand(<span class="hljs-number">1</span>,<span class="hljs-number">1000</span>)<br></code></pre></td></tr></table></figure><p>进行前向传播</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">prediction = model(data)<br></code></pre></td></tr></table></figure><p>获得与预测值的差值，然后惊醒方向传播</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">loss = (prediction-labels).<span class="hljs-built_in">sum</span>()<br>loss.backward()<br></code></pre></td></tr></table></figure><p>然后加载一个优化器，通过学习率为0.01步长为0.9，注册在优化器中的所有参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">optim = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-2</span>, momentum=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure><p>然后迭代参数下降法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">optim.step()<br></code></pre></td></tr></table></figure><h3 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h3><p>一个神经网络定义的过程</p><ul><li>定义神经网络的学习参数</li><li>迭代输入</li><li>在网络中传递</li><li>计算损失值</li><li>迭代反向梯度传播</li><li>更新权重</li></ul>]]></content>
    
    
    <categories>
      
      <category>面试</category>
      
      <category>机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>基于自建 Knative 的 k8s 集群部署</title>
    <link href="/2024/04/21/kn_deploy/"/>
    <url>/2024/04/21/kn_deploy/</url>
    
    <content type="html"><![CDATA[<h1 id="基于自建-Knative-的-k8s-集群部署"><a href="#基于自建-Knative-的-k8s-集群部署" class="headerlink" title="基于自建 Knative 的 k8s 集群部署"></a>基于自建 Knative 的 k8s 集群部署</h1><h1 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h1><p>Knative（下称 kn）的部署工具极为复杂，其对于 <code>func</code> 的部署流程也较为笨重，在 <code>kn</code> 中也不支持函数流的部署工作，因此我们需要在自己搭建的原生 k8s 集群上安装 kn，同时我自己编写了一套 kn 的部署工具，可以比原本的部署更加轻便快捷，也在原来的 <code>kn</code> 的基础上，增加了对多函数部署的支持。</p><h1 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h1><h2 id="原生-Knative-部署的问题"><a href="#原生-Knative-部署的问题" class="headerlink" title="原生 Knative 部署的问题"></a>原生 Knative 部署的问题</h2><p>kn 提供的函数部署工具 <code>kn-func</code> 通过 <code>func.yaml</code> 配置文件部署 <code>kn</code> 函数，其主要的流程可以概括为</p><ul><li>从 <code>gcr</code> 仓库中拉取对应的镜像</li><li>将用户编写的代码移动到镜像中，在所拉取的镜像中构建新的镜像</li><li>将构建好的镜像推送到用户提供的 Docker 仓库中</li><li>部署 k8s 服务，从 Docker 仓库拉取用户所需要的镜像</li></ul><p>以上的部署方式存在以下的问题</p><ul><li>从 <code>gcr</code> 仓库中拉取镜像的过程由于国内的网络问题往往会拉取失败，即便配置了代理也会出现拉取失败的问题</li><li>重新构建一个镜像的时间过长，而且每次都要重新构建显然是多余的</li></ul><h2 id="Base-Image-Code-Volume"><a href="#Base-Image-Code-Volume" class="headerlink" title="Base-Image+Code-Volume"></a>Base-Image+Code-Volume</h2><p>既然一个容器运行只需要用户的代码 + 运行环境，那么其实我们可以先将容器所需的运行环境准备好，然后想个办法将用户的代码打包到容器里头就好。然后我们只需要在 dockerhub 仓库上部署好自己的基础镜像，就可以复用该镜像来实现用户的所有 Serverless 函数。但是这样也会带来另外的一些问题：</p><ul><li><p><code>kn</code> 服务不支持映射本地的文件到运行时中，因为 <code>kn</code> 是运行在集群中的服务，而不是单个主机上的服务</p><ul><li>因此只能用持久化卷（<code>pv</code> 和 <code>pvc</code>）的方式来实现上传代码的功能</li></ul></li><li><p><code>kn</code> 服务不支持挂载在可读可写的持久化卷上，但是我们既要将用户的代码打包上去又要有下载功能</p></li></ul><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><h2 id="k8s-集群环境准备"><a href="#k8s-集群环境准备" class="headerlink" title="k8s 集群环境准备"></a>k8s 集群环境准备</h2><p>由于我们用的是自建的 k8s 集群，因此不再直接通过 <code>kn quickstart</code> 插件安装 <code>kn</code> 服务</p><h3 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h3><ul><li>k8s 版本 v1.27<ul><li>已经安装了 <code>kubeadm</code>，<code>kubelet</code>，<code>kubectl</code></li></ul></li></ul><h3 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h3><ul><li>启动集群</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo kubeadm init<br></code></pre></td></tr></table></figure><ul><li>安装 <code>serving-crds.yaml</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://github.com/knative/serving/releases/download/knative-v1.12.4/serving-crds.yaml<br>kubectl apply -f serving-crds.yaml<br></code></pre></td></tr></table></figure><ul><li>配置 <code>serving-core.yaml</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://github.com/knative/serving/releases/download/knative-v1.12.4/serving-core.yaml<br>kubectl apply -f serving-core.yaml<br></code></pre></td></tr></table></figure><ul><li>配置网络</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://github.com/knative/net-kourier/releases/download/knative-v1.12.3/kourier.yaml<br>kubectl apply -f kourier.yaml<br></code></pre></td></tr></table></figure><ul><li>配置 <code>kn</code> 的 <code>ingress</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl patch configmap/config-network <br>--namespace knative-serving <br>--<span class="hljs-built_in">type</span> merge <br>--patch <span class="hljs-string">&#x27;&#123;&quot;data&quot;:&#123;&quot;ingress-class&quot;:&quot;kourier.ingress.networking.knative.dev&quot;&#125;&#125;&#x27;</span><br></code></pre></td></tr></table></figure><ul><li>配置域名</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.12.4/serving-default-domain.yaml<br></code></pre></td></tr></table></figure><ul><li>随便拿一个 IP 作为服务</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 10.0.0.233 is an arbitary choice.EXTERNAL_IP=&quot;10.0.0.233&quot;# To get rid of the strange rules that default urls *.svc.cluster.local cannot be accessed from outside network. # sslip can avoid us from trouble of manipulating DNS record.</span><br>kubectl patch configmap/config-domain \--namespace knative-serving \--<span class="hljs-built_in">type</span> merge \--patch <span class="hljs-string">&quot;&#123;\&quot;data\&quot;:&#123;\&quot;<span class="hljs-variable">$EXTERNAL_IP</span>.sslip.io\&quot;:\&quot;\&quot;&#125;&#125;&quot;</span><br><br>kubectl patch svc kourier -n kourier-system -p <span class="hljs-string">&quot;&#123;\&quot;spec\&quot;: &#123;\&quot;type\&quot;: \&quot;LoadBalancer\&quot;, \&quot;externalIPs\&quot;: [\&quot;<span class="hljs-variable">$EXTERNAL_IP</span>\&quot;]&#125;&#125;&quot;</span><br></code></pre></td></tr></table></figure><ul><li>验证外部 IP</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl --namespace kourier-system get service kourier<br></code></pre></td></tr></table></figure><h2 id="持久化卷的部署"><a href="#持久化卷的部署" class="headerlink" title="持久化卷的部署"></a>持久化卷的部署</h2><p>通过创建 pv 以及 pvc 来部署持久化卷</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolume</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">faasit-code-volume</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">capacity:</span><br>    <span class="hljs-attr">storage:</span> <span class="hljs-string">1Gi</span><br>  <span class="hljs-attr">volumeMode:</span> <span class="hljs-string">Filesystem</span><br>  <span class="hljs-attr">accessModes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteOnce</span><br>  <span class="hljs-attr">persistentVolumeReclaimPolicy:</span> <span class="hljs-string">Retain</span><br>  <span class="hljs-attr">storageClassName:</span> <span class="hljs-string">&quot;&quot;</span><br>  <span class="hljs-attr">hostPath:</span><br>    <span class="hljs-attr">path:</span> <span class="hljs-comment"># 随便拿一个目录</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">PersistentVolumeClaim</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">faasit-code-volume-claim</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">resources:</span><br>    <span class="hljs-attr">requests:</span><br>      <span class="hljs-attr">storage:</span> <span class="hljs-string">512Mi</span><br>  <span class="hljs-attr">volumeMode:</span> <span class="hljs-string">Filesystem</span><br>  <span class="hljs-attr">accessModes:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">ReadWriteOnce</span><br></code></pre></td></tr></table></figure><h2 id="文件分发管理器"><a href="#文件分发管理器" class="headerlink" title="文件分发管理器"></a>文件分发管理器</h2><p>使用 Nginx 服务作为文件分发的管理器</p><h3 id="构建-Nginx-镜像"><a href="#构建-Nginx-镜像" class="headerlink" title="构建 Nginx 镜像"></a>构建 Nginx 镜像</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> nginx:alpine<br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">rm</span> /etc/nginx/conf.d/default.conf</span><br><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./nginx.conf /etc/nginx/conf.d/default.conf</span><br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">mkdir</span> -p /data/uploads</span><br><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">80</span><br></code></pre></td></tr></table></figure><p>其中配置文件如下，我也想做成一个纯 Nginx 服务器的，我也不知道为啥文件死活上传不上去</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;<br>    <span class="hljs-attribute">listen</span>       <span class="hljs-number">80</span>;<br>    <span class="hljs-attribute">server_name</span>  localhost;<br><br>    <span class="hljs-section">location</span> / &#123;<br>        <span class="hljs-attribute">root</span>   /usr/share/nginx/html;<br>        <span class="hljs-attribute">index</span>  index.html index.htm;<br>    &#125;<br><br>    <span class="hljs-comment"># # 配置文件上传的处理</span><br>    <span class="hljs-comment"># location /data/uploads &#123;</span><br>    <span class="hljs-comment">#     # 将客户端上传的文件保存在这个目录</span><br>    <span class="hljs-comment">#     alias /data/uploads;</span><br>    <span class="hljs-comment">#     # 限制上传文件的大小</span><br>    <span class="hljs-comment">#     client_max_body_size 100M;</span><br>    <span class="hljs-comment">#     # 启用 WebDAV 方法</span><br>    <span class="hljs-comment">#     dav_methods PUT DELETE MKCOL COPY MOVE;</span><br>    <span class="hljs-comment">#     # 自动创建目录</span><br>    <span class="hljs-comment">#     create_full_put_path on;</span><br>    <span class="hljs-comment">#     # 设置正确的权限</span><br>    <span class="hljs-comment">#     dav_access user:rw group:rw all:rw;</span><br><br>    <span class="hljs-comment">#     # 文件上传完成后，重定向或返回成功信息</span><br>    <span class="hljs-comment">#     return 201 &quot;Upload completed&quot;;</span><br>    <span class="hljs-comment"># &#125;</span><br><br>    <span class="hljs-comment"># 提供文件下载的目录</span><br>    <span class="hljs-section">location</span> /data &#123;<br>        <span class="hljs-attribute">alias</span> /data;<br>        <span class="hljs-attribute">autoindex</span> <span class="hljs-literal">on</span>;  <span class="hljs-comment"># 开启索引，方便直接浏览文件</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>然后执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker build -t docker.io/xdydy/faasit-file-server:v1<br>docker push docker.io/xdydy/faasit-file-server:v1<br></code></pre></td></tr></table></figure><h3 id="部署-Nginx-服务"><a href="#部署-Nginx-服务" class="headerlink" title="部署 Nginx 服务"></a>部署 Nginx 服务</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-file-server</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">1</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">matchLabels:</span><br>      <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-file-server</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-file-server</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">volumes:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">data-volume</span><br>        <span class="hljs-attr">persistentVolumeClaim:</span><br>          <span class="hljs-attr">claimName:</span> <span class="hljs-string">faasit-code-volume-claim</span><br>      <span class="hljs-attr">containers:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx</span><br>        <span class="hljs-attr">image:</span> <span class="hljs-string">docker.io/xdydy/faasit-file-server:v1</span><br>        <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">Always</span><br>        <span class="hljs-attr">ports:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span><br>        <span class="hljs-attr">volumeMounts:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">data-volume</span><br>          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/data/uploads</span><br>        <span class="hljs-attr">resources:</span><br>          <span class="hljs-attr">requests:</span><br>            <span class="hljs-attr">cpu:</span> <span class="hljs-string">100m</span><br>            <span class="hljs-attr">memory:</span> <span class="hljs-string">128Mi</span><br>          <span class="hljs-attr">limits:</span><br>            <span class="hljs-attr">cpu:</span> <span class="hljs-string">250m</span><br>            <span class="hljs-attr">memory:</span> <span class="hljs-string">256Mi</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-file-server</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">ClusterIP</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">port:</span> <span class="hljs-number">80</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">80</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-file-server</span><br></code></pre></td></tr></table></figure><h2 id="构建运行时环境镜像"><a href="#构建运行时环境镜像" class="headerlink" title="构建运行时环境镜像"></a>构建运行时环境镜像</h2><p>以 python 运行时为例，由于容器里头没有用户提交的代码，于是我们可以在应用程序启动时，从 Nginx 服务上获取相应的代码文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> zipfile<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">check_and_load_code</span>():<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(<span class="hljs-string">f&#x27;/<span class="hljs-subst">&#123;codeDir&#125;</span>/<span class="hljs-subst">&#123;codeName&#125;</span>.py&#x27;</span>):<br>        <span class="hljs-comment"># 不使用代理下载代码，是一个zip，解压后放到指定目录</span><br>        code_url = <span class="hljs-string">f&quot;http://10.102.131.24:80/data/uploads/<span class="hljs-subst">&#123;downLoadFile&#125;</span>&quot;</span><br>        r = requests.get(code_url, stream=<span class="hljs-literal">True</span>, proxies=&#123;<span class="hljs-string">&#x27;http&#x27;</span>: <span class="hljs-literal">None</span>, <span class="hljs-string">&#x27;https&#x27;</span>: <span class="hljs-literal">None</span>&#125;)<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;/tmp/code.zip&#x27;</span>, <span class="hljs-string">&#x27;wb&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> r.iter_content(chunk_size=<span class="hljs-number">1024</span>):<br>                <span class="hljs-keyword">if</span> chunk:<br>                    f.write(chunk)<br>        <span class="hljs-keyword">with</span> zipfile.ZipFile(<span class="hljs-string">&#x27;/tmp/code.zip&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> z:<br>            z.extractall(<span class="hljs-string">&#x27;/code&#x27;</span>)<br></code></pre></td></tr></table></figure><p>在镜像中，我们开启一个 <code>HTTP</code> 服务器响应用户的请求</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span>, methods=[<span class="hljs-string">&#x27;POST&#x27;</span>, <span class="hljs-string">&#x27;GET&#x27;</span>]</span>)</span><br><span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">local_invoke</span>():<br>    <span class="hljs-keyword">try</span> :<br>        req = request.get_json()<br>        logger.info(<span class="hljs-string">f&quot;[INPUT] <span class="hljs-subst">&#123;req&#125;</span>&quot;</span>)<br><br>        <span class="hljs-comment"># 导入用户代码</span><br>        check_and_load_code()<br>        code = importlib.import_module(codeName)<br>        result = <span class="hljs-keyword">await</span> code.handler(req)<br>        logger.info(<span class="hljs-string">f&quot;[OUTPUT] <span class="hljs-subst">&#123;result&#125;</span>&quot;</span>)<br><br>        resp = jsonify(result)<br>        <span class="hljs-keyword">return</span> resp<br>    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>        logger.error(<span class="hljs-string">f&quot;[ERROR] <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br>        <span class="hljs-keyword">return</span> make_response(jsonify(&#123;<span class="hljs-string">&#x27;error&#x27;</span>: <span class="hljs-built_in">str</span>(e)&#125;), <span class="hljs-number">500</span>)<br></code></pre></td></tr></table></figure><p>k8s 容器还需要服务提供一个就绪探针，用来让 k8s 知道服务已经就绪，于是我们随便写点代码让他返回就行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/health&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">health</span>():<br>    <span class="hljs-keyword">return</span> jsonify(&#123;<span class="hljs-string">&#x27;status&#x27;</span>: <span class="hljs-string">&#x27;ok&#x27;</span>&#125;)<br></code></pre></td></tr></table></figure><p>在该环境下，我们提供了 <code>faasit-runtime</code> 作为一系列运行环境的支撑，在 python 环境下，我们构建 python 的运行时容器</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.10</span><br><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /app</span><br><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./src /app</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./requirements.txt /app/requirements.txt</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> ./faasit-runtime /faasit-runtime</span><br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install --upgrade pip</span><br><br><span class="hljs-comment"># RUN pip install -r requirements.txt</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install <span class="hljs-string">&quot;flask[async]&quot;</span></span><br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install -e /faasit-runtime</span><br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">mkdir</span> -p /code &amp;&amp; <span class="hljs-built_in">cd</span> /code</span><br><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /code</span><br><br><span class="hljs-keyword">ENV</span> FAASIT_PROVIDER local<br><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [ <span class="hljs-string">&quot;bash&quot;</span> ]</span><br></code></pre></td></tr></table></figure><p>构建，推送</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">docker build -t docker.io/xdydy/faasit-python-runtime:<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span><br>docker push docker.io/xdydy/faasit-python-runtime:<span class="hljs-number">0.0</span>.<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><h2 id="Knative-服务部署"><a href="#Knative-服务部署" class="headerlink" title="Knative 服务部署"></a>Knative 服务部署</h2><p>使用 <code>kn</code> 的 API 部署 <code>kn</code> 服务的示例配置如下</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">serving.knative.dev/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-comment"># 函数名称</span><br>  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">containers:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">image:</span> <span class="hljs-string">docker.io/xdydy/faasit-python-runtime:0.0.1</span> <span class="hljs-comment"># 前文准备的镜像</span><br>          <span class="hljs-attr">ports:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">9000</span> <span class="hljs-comment"># 内部服务暴露的端口</span><br>          <span class="hljs-attr">readinessProbe:</span> <span class="hljs-comment"># 就绪探针</span><br>            <span class="hljs-attr">httpGet:</span><br>              <span class="hljs-attr">path:</span> <span class="hljs-string">/health</span><br>              <span class="hljs-attr">port:</span> <span class="hljs-number">9000</span><br>            <span class="hljs-attr">initialDelaySeconds:</span> <span class="hljs-number">5</span><br>            <span class="hljs-attr">periodSeconds:</span> <span class="hljs-number">10</span><br>            <span class="hljs-attr">timeoutSeconds:</span> <span class="hljs-number">1</span><br>            <span class="hljs-attr">successThreshold:</span> <span class="hljs-number">1</span><br>            <span class="hljs-attr">failureThreshold:</span> <span class="hljs-number">3</span><br>          <span class="hljs-attr">securityContext:</span> <span class="hljs-comment"># 安全策略，也是kn麻烦的地方</span><br>            <span class="hljs-attr">runAsNonRoot:</span> <span class="hljs-literal">false</span><br>            <span class="hljs-attr">allowPrivilegeEscalation:</span> <span class="hljs-literal">false</span><br>            <span class="hljs-attr">capabilities:</span><br>              <span class="hljs-attr">drop:</span><br>                <span class="hljs-bullet">-</span> <span class="hljs-string">ALL</span><br>            <span class="hljs-attr">seccompProfile:</span><br>              <span class="hljs-attr">type:</span> <span class="hljs-string">RuntimeDefault</span><br>          <span class="hljs-attr">env:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">FAASIT_FUNC_NAME</span><br>              <span class="hljs-attr">value:</span> <span class="hljs-string">split</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">FAASIT_PROVIDER</span><br>              <span class="hljs-attr">value:</span> <span class="hljs-string">knative</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">FAASIT_CODE_DIR</span><br>              <span class="hljs-attr">value:</span> <span class="hljs-string">wordcount-split.zip</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">FAASIT_WORKFLOW_NAME</span><br>              <span class="hljs-attr">value:</span> <span class="hljs-string">wordcount</span><br>          <span class="hljs-attr">command:</span> <span class="hljs-comment"># 容器启动命令</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-string">python</span><br>          <span class="hljs-attr">args:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-string">/app/server.py</span><br></code></pre></td></tr></table></figure><p>至于容器里头的代码，可以通过 <code>kubectl cp</code> 命令将本地的代码文件拷贝过去，可以通过一个简单的命令来查找运行文件分发器的 <code>pod</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pod=kubectl get pod | grep nginx-file-server | awk <span class="hljs-string">&#x27;&#123;print $1&#125;&#x27;</span><br>kubectl <span class="hljs-built_in">cp</span> code.zip $(pod):/data/uploads<br></code></pre></td></tr></table></figure><p>这样函数就部署完成了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl get ksvc<br><br><span class="hljs-comment"># NAME                 URL                                                     LATESTCREATED              LATESTREADY                READY   REASON</span><br><span class="hljs-comment"># wordcount-count      http://wordcount-count.default.10.0.0.233.sslip.io      wordcount-count-00001      wordcount-count-00001      True</span><br><span class="hljs-comment"># wordcount-executor   http://wordcount-executor.default.10.0.0.233.sslip.io   wordcount-executor-00001   wordcount-executor-00001   True</span><br><span class="hljs-comment"># wordcount-sort       http://wordcount-sort.default.10.0.0.233.sslip.io       wordcount-sort-00001       wordcount-sort-00001       True</span><br><span class="hljs-comment"># wordcount-split      http://wordcount-split.default.10.0.0.233.sslip.io      wordcount-split-00001      wordcount-split-00001      True</span><br></code></pre></td></tr></table></figure><p>也支持调用</p><p><img src="/../assets/kn_deploy/XSznbih1ko36wAxEVcMcXdcTnIc.png"></p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
      <category>项目</category>
      
    </categories>
    
    
    <tags>
      
      <tag>knative</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式系统复习提纲</title>
    <link href="/2024/01/01/dis_sys/"/>
    <url>/2024/01/01/dis_sys/</url>
    
    <content type="html"><![CDATA[<h1 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h1><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="分布式系统的定义"><a href="#分布式系统的定义" class="headerlink" title="分布式系统的定义"></a>分布式系统的定义</h2><ul><li>分布式系统是若干独立计算机的集合，这些计算机对于用户来说就像是单个相关系统</li><li>为了使各类异构的计算机和网络都呈现为单个的系统，分布式系统常常通过一个软件层组织起来，这样的分布式系统有时又称为中间件</li></ul><h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><ul><li><p>使资源可访问</p></li><li><p>透明性：如果一个分布式系统能够在用户和应用程序面前呈现为单个计算机系统，这样的分布式系统就称为是透明的</p><ul><li>访问透明性：对不同数据的表示形式以及资源访问的隐藏</li><li>位置透明性：用户无法感知到资源在系统中的物理位置</li><li>迁移透明性：分布式系统的资源迁移不会影响该资源的访问方式</li><li>重定向透明性：资源可以在接收访问的同时进行重新定位而不引起用户和应用程序的注意</li><li>复制透明性：对同一资源存在多个副本这样一个事实的隐藏</li><li>并发透明性：确保对共享资源的并发访问不会破坏资源的一致状态</li><li>故障透明性：用户不会注意到某个资源无法正常工作</li></ul></li><li><p>开放性</p><ul><li>开放的分布式系统：根据一系列准则来提供服务，这些准则描述了服务的语法与语义</li><li>分布式系统中服务通常通过接口指定，接口一般是通过接口定义语言描述</li><li>互操作性：来自不同厂商的系统或组件的两种实现能够在何种程度上共存并且协同工作</li><li>可移植性</li><li>做法：策略与机制分离<ul><li>机制：对应一个接口。例如万维网的缓存机制</li><li>策略：对应具体做法。允许用户修改缓存策略</li></ul></li></ul></li><li><p>可扩展性</p><ul><li>规模上扩展</li><li>地域上扩展</li><li>管理上扩展</li></ul></li></ul><h2 id="分布式系统的类型"><a href="#分布式系统的类型" class="headerlink" title="分布式系统的类型"></a>分布式系统的类型</h2><h3 id="分布式计算系统"><a href="#分布式计算系统" class="headerlink" title="分布式计算系统"></a>分布式计算系统</h3><h4 id="集群计算系统"><a href="#集群计算系统" class="headerlink" title="集群计算系统"></a>集群计算系统</h4><ul><li>每个群都是由一个计算机节点集组成的，它们可以由单个主节点来控制和访问</li></ul><h4 id="网格计算系统"><a href="#网格计算系统" class="headerlink" title="网格计算系统"></a>网格计算系统</h4><ul><li>网格计算系统具有高度的异构性：其硬件、操作系统、网络、管理域和安全策略等都不尽相同</li></ul><h3 id="分布式信息系统"><a href="#分布式信息系统" class="headerlink" title="分布式信息系统"></a>分布式信息系统</h3><h4 id="事务处理系统"><a href="#事务处理系统" class="headerlink" title="事务处理系统"></a>事务处理系统</h4><p>对事务处理的程序要求有特定的原函数，即必须能被底层的分布式系统或编程语言的运行时系统所支持。</p><ul><li>事务的 4 个特性<ul><li>原子性：对于外部来说，事务处理是不可见的</li><li>一致性：事务处理不会违反系统的不变性</li><li>独立性：并发的事务处理不会互相干扰</li><li>持久性：事务处理一旦提交，所发生的改变是永久性的</li></ul></li></ul><h4 id="企业应用集成"><a href="#企业应用集成" class="headerlink" title="企业应用集成"></a>企业应用集成</h4><ul><li>通信中间件<ul><li>远程过程调用：通过一个本地过程调用，有效地往另一个应用程序组件发送一个请求</li><li>远程方法调用：操作的是对象而不是应用程序</li><li>面向消息的中间件：发布订阅系统</li></ul></li></ul><h3 id="分布式普适系统"><a href="#分布式普适系统" class="headerlink" title="分布式普适系统"></a>分布式普适系统</h3><h1 id="体系结构"><a href="#体系结构" class="headerlink" title="体系结构"></a>体系结构</h1><h2 id="体系结构的样式"><a href="#体系结构的样式" class="headerlink" title="体系结构的样式"></a>体系结构的样式</h2><ul><li>分层体系结构：计算机网络</li><li>基于对象的体系结构：RPC</li><li>以数据为中心的体系结构：Web</li><li>基于事件的体系结构：发布订阅系统</li></ul><h2 id="系统体系结构"><a href="#系统体系结构" class="headerlink" title="系统体系结构"></a>系统体系结构</h2><h3 id="集中式体系结构"><a href="#集中式体系结构" class="headerlink" title="集中式体系结构"></a>集中式体系结构</h3><ul><li>应用分层</li><li>多层体系结构</li></ul><h3 id="非集中式体系结构"><a href="#非集中式体系结构" class="headerlink" title="非集中式体系结构"></a>非集中式体系结构</h3><ul><li>结构化点对点体系结构</li><li>非结构化的点对点体系结构</li><li>覆盖网络的拓扑管理</li><li>超级对等体</li></ul><h3 id="混合体系结构"><a href="#混合体系结构" class="headerlink" title="混合体系结构"></a>混合体系结构</h3><h1 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h1><h2 id="代码迁移"><a href="#代码迁移" class="headerlink" title="代码迁移"></a>代码迁移</h2><h3 id="代码迁移方案"><a href="#代码迁移方案" class="headerlink" title="代码迁移方案"></a>代码迁移方案</h3><ul><li><p>理由：把进程由负载较重的机器上转移到负载较轻的机器上去</p></li><li><p>代码迁移模型</p><ul><li>代码段</li><li>资源段</li><li>执行段</li></ul></li><li><p>形式</p><ul><li>弱可移动性：代码段与初始化数据</li><li>强可移动性：传输执行段</li></ul></li></ul><p><img src="/../assets/dissys/PbFmbBg6logxpXx6uk2cZPeQn5g.png"></p><h3 id="迁移与本地资源"><a href="#迁移与本地资源" class="headerlink" title="迁移与本地资源"></a>迁移与本地资源</h3><ul><li>按标识符绑定：进程明确指定的只是要引用哪些资源</li><li>按类型绑定：进程指指明它需要哪一种类型的资源</li></ul><h3 id="异构系统中的代码迁移"><a href="#异构系统中的代码迁移" class="headerlink" title="异构系统中的代码迁移"></a>异构系统中的代码迁移</h3><h1 id="通信"><a href="#通信" class="headerlink" title="通信"></a>通信</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="通信类型"><a href="#通信类型" class="headerlink" title="通信类型"></a>通信类型</h3><ul><li>持久通信：提交传输的消息一直由通信中间件存储，直到该消息被传送给接收方为止</li><li>瞬时通信：通信系统只有在发送和接收应用程序正在运行时才存储消息</li><li>异步通信：发送方在提交要传输的消息立即往下执行</li><li>同步通信：发送方将被阻塞，直到知道其请求被接受以后</li></ul><h2 id="远程过程调用"><a href="#远程过程调用" class="headerlink" title="远程过程调用"></a>远程过程调用</h2><p>机器 A 上的进程调用机器 B 上的进程时，A 上的调用进程被挂起，而 B 上的被调用进程开始执行</p><p>总的来说，远程过程调用包含下列步骤：</p><ol><li>客户过程以正常的方式调用客户存根</li><li>客户存根生成一个消息，然后调用本地操作系统</li><li>客户端操作系统将消息发送给远程操作系统</li><li>远程操作系统将消息发给服务器存根</li><li>服务器存根将参数提取出来，然后调用服务器</li><li>服务器执行要求的操作，操作完成后将结果返回给服务器存根</li><li>服务器存根将结果打包成一个消息，然后调用本地操作系统</li><li>服务器操作系统将含有结果的消息发送回客户端操作系统</li><li>客户端操作系统将消息交给客户存根</li><li>客户存根将结果从消息中提取出来，返回给调用它的客户过程</li></ol><h1 id="命名系统"><a href="#命名系统" class="headerlink" title="命名系统"></a>命名系统</h1><h2 id="名称、标识符和地址"><a href="#名称、标识符和地址" class="headerlink" title="名称、标识符和地址"></a>名称、标识符和地址</h2><ul><li><p>访问点：要对实体进行操作，就需要访问实体，因此需要一个访问点</p></li><li><p>地址：访问点的名称称为地址</p></li><li><p>标识符：具有以下属性的名称</p><ul><li>一个标识符最多引用一个实体</li><li>每个实体最多由一个标识符引用</li><li>一个标识符始终引用同一个实体</li></ul></li></ul><h2 id="无层次命名"><a href="#无层次命名" class="headerlink" title="无层次命名"></a>无层次命名</h2><h3 id="简单方法"><a href="#简单方法" class="headerlink" title="简单方法"></a>简单方法</h3><ul><li><p>广播与多播：随着网络的膨胀广播开始变得低效</p></li><li><p>转发指针：</p><ul><li>链可能会特别长</li><li>只要需要，链中的所有中间位置就必须维护它们的那一部分转发指针链</li><li>所在的链很脆弱，易断开</li></ul></li></ul><h3 id="基于宿主位置的方法"><a href="#基于宿主位置的方法" class="headerlink" title="基于宿主位置的方法"></a>基于宿主位置的方法</h3><ul><li><p>每个移动主机都有一个固定的 IP 地址，所有与该 IP 地址进行的通信一开始都被转发到移动主机的宿主代理中</p></li><li><p>当一台移动主机转移到另一个网络中时，它会请求一个可以用来通信的临时地址，这种转交地址要在宿主代理中注册</p></li><li><p>当宿主代理接收到发给移动主机的数据包时，它会查找主机的当前位置</p><ul><li>如果主机是在当前本地网络中，那么就只需转发数据包</li><li>否则，建立一条通往主机当前位置的通道，也就是说，它会把数据组装成 IP 包，然后发送给转交地址。同时，将把主机的当前位置告诉数据包的发送者</li></ul></li><li><p>缺点：</p><ul><li>必须保证宿主位置始终存在</li></ul></li></ul><h3 id="分层方法"><a href="#分层方法" class="headerlink" title="分层方法"></a>分层方法</h3><ul><li>分层方案中，网络被划分为一组域，有一个覆盖整个网络的顶级域，每个域又可以进一步分成多个更小的子域</li><li>查询操作</li></ul><p><img src="/../assets/dissys/OaQgbMXlFoTgVgx6s72cYO3vnmb.png"></p><ul><li>更新操作</li></ul><p><img src="/../assets/dissys/TNRob81TyoXRw7xLZMGc8yO0nBd.png"></p><h1 id="同步化"><a href="#同步化" class="headerlink" title="同步化"></a>同步化</h1><h2 id="时钟同步"><a href="#时钟同步" class="headerlink" title="时钟同步"></a>时钟同步</h2><h3 id="时钟同步算法"><a href="#时钟同步算法" class="headerlink" title="时钟同步算法"></a>时钟同步算法</h3><ul><li><p>网络时间协议：客户与时间服务器联系<br><img src="/../assets/dissys/XDwKbUnfEoxK9yxz57jc5TrTnKb.png"></p><ul><li>创建了两条连接，B 也可以探查 A 的当前时间，延时的计算如下</li></ul><p>$$<br>igma &#x3D; \frac{(T_2-T_1) + (T_4-T_3)}{2}<br>$$</p></li><li><p>Berkeley 算法</p><ul><li>时间服务器是主动的，定期地询问每台机器的时间</li><li>基于这些回答，计算出一个平均时间，并告诉所有其他机器将它们的时钟拨快到一个新的时间</li><li>基于这些回答，计算出一个平均时间</li></ul></li></ul><h2 id="逻辑时钟"><a href="#逻辑时钟" class="headerlink" title="逻辑时钟"></a>逻辑时钟</h2><h3 id="Lamport-逻辑时钟"><a href="#Lamport-逻辑时钟" class="headerlink" title="Lamport 逻辑时钟"></a>Lamport 逻辑时钟</h3><ul><li>计数器更新<ul><li>在执行一个事件之前（如在网络上发送一个消息，传送一个消息给应用程序，或者其他内部事件），$P_i$执行$C_i \leftarrow C_i+1$</li><li>当进程$P_i$发送一个消息 m 给$P_i$时，在执行前面的步骤后，把 m 的时间戳$ts(m)$设置为等于$C_i$</li><li>在接收消息 m 时，进程$P_i$调整自己的局部计数器为$C_j \leftarrow \max {C_i, ts(m)}$，然后执行第一步，并把消息传送给应用程序</li></ul></li></ul><h3 id="向量时钟"><a href="#向量时钟" class="headerlink" title="向量时钟"></a>向量时钟</h3><ul><li>Lamport 不能捕获因果关系</li></ul><p><img src="/../assets/dissys/LfSibII6goQqEqxuuGicjN01n1d.png"></p><ul><li><p>向量时钟的创建是通过让每个进程$P_i$维护一个向量$VC_i$来完成的，该向量具有下面两个性质</p><ul><li>$VC_i[i]$是到目前为止进程$P_i$发生的事件的数量</li><li>如果$VC_i[j]&#x3D;k$,那么进程$P_i$知道进程$P_j$中已经发生了 k 个事件。因此，$P_i$知道$P_j$的逻辑时间</li></ul></li><li><p>步骤</p><ul><li>在执行一个事件之前（如在网络上发送一个消息，传送一个消息给应用程序，或者其他内部事件），$P_i$执行$VC_i[i] \leftarrow VC_i[i] + 1$</li><li>当进程$P_i$发送一个消息 m 给$P_i$时，在执行前面的步骤后，把 m 的时间戳$ts(m)$设置为等于$VC_i$</li><li>当接收消息 m 时，进程$P_j$通过为每个 k 设置$VC_j[k] \leftarrow \max { VC_j[k], ts(m)[k] }$来调整自己的向量。然后，执行第一步，并把自己的消息传送给应用程序</li></ul></li></ul><h2 id="互斥"><a href="#互斥" class="headerlink" title="互斥"></a>互斥</h2><h3 id="集中式算法"><a href="#集中式算法" class="headerlink" title="集中式算法"></a>集中式算法</h3><p>选举一个进程作为协作者，无论何时一个进程要访问共享资源，都要向协作者发送一个请求消息，说明它想要访问哪个资源并请求准许</p><h3 id="分布式算法"><a href="#分布式算法" class="headerlink" title="分布式算法"></a>分布式算法</h3><p>该算法的工作过程如下：当一个进程要访间一个共享资源时，它构造一个消息，其中包含它要访问的资源名、它的进程号和当前（逻辑）时间。然后，它将该消息发送给所有其他的进程，理论上讲也包括它自己，假设消息的传送是可靠的，也就是说，没有消息丢失。</p><p>当一个进程接收到来自另一个进程的请求消息时，它根据自己与消息中的资源相关的状态来决定它要采取的动作。可以分为三种情况</p><ul><li>若接收者没有访问资源，而且也不想访问它，就向发送者发送一个 OK 消息。</li><li>若接收者已获得对资源的访问，那么它就不进行应答，而是将该请求放入队列中。</li><li>如果接收者想访问费源但尚未访问时，它收到的消息的时间截与包含在它发送给其他进程的消息中的时间藏进行比较。时间戳最早的那个进程获胜。如果收到的消息的时间截比较早，那么接收者向发送者发回一个 OK 消息，如果它自己的消息的时间截比较队列中，并且不发送任何消息</li></ul><p><img src="/../assets/dissys/WaBbb45MXonGXhx1ROcc5HhSnob.png"></p><h3 id="令牌环算法"><a href="#令牌环算法" class="headerlink" title="令牌环算法"></a>令牌环算法</h3><ul><li><p>环初始化时，进程 0 得到一个令牌</p></li><li><p>令牌绕着环运行，用点对点发送消息的方式把令牌从进程 k 传到进程 k+1</p></li><li><p>拿到令牌的资源检查自己是否需要访问资源</p><ul><li>要。继续完成要做的工作，然后释放资源</li><li>不要。向下传递</li></ul></li></ul><h2 id="选举算法"><a href="#选举算法" class="headerlink" title="选举算法"></a>选举算法</h2><h3 id="传统的选举算法"><a href="#传统的选举算法" class="headerlink" title="传统的选举算法"></a>传统的选举算法</h3><ul><li><p>欺负算法</p><ul><li>任何一个进程发现协作者不再响应请求的时候，它就发起一次选举，按照如下过程<ul><li>P 向所有编号比它大的进程发送一个 <code>ELECTION</code> 消息</li><li>如果无人响应，P 获胜并成为协作者</li><li>如果有编号比它大的进程的响应，则由响应者接管选举工作，P 的工作完成</li></ul></li></ul></li><li><p>环算法</p><ul><li>当任何一个进程注意到协作者不工作时，它就构造一个带有他自己的进程号的 <code>ELECTION</code> 消息并把消息发送给它的后继者</li><li>如果后继者崩溃了，发送者沿着此环跳过它的后继者发送给下一个进程，直到找到一个正在运行的进程</li><li>最终消息返回到此次选举的进程，当发起者进程接收到一个包含它自己的进程号的消息时，它识别出这个事件。此时该进程再一次绕环运行，向所有进程通知谁是协作者</li></ul></li></ul><h1 id="一致性与复制"><a href="#一致性与复制" class="headerlink" title="一致性与复制"></a>一致性与复制</h1><h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><ul><li><p>可靠性</p><ul><li>当一个副本被破坏后，文件系统只需转换到另一个数据副本就可以继续执行下去</li></ul></li><li><p>性能</p><ul><li>当分布式系统需要在服务器数量和地理区域上进行扩展时，复制对于提高性能时相当重要的</li></ul></li></ul><h2 id="以数据为中心的一致性模型"><a href="#以数据为中心的一致性模型" class="headerlink" title="以数据为中心的一致性模型"></a>以数据为中心的一致性模型</h2><h3 id="严格一致性"><a href="#严格一致性" class="headerlink" title="严格一致性"></a>严格一致性</h3><p>任何读的结果都是最近的一次写的结果</p><p><img src="/../assets/dissys/UYJqbDvyUoXXBZxnDydcKiwLn7g.png"></p><h3 id="顺序一致性"><a href="#顺序一致性" class="headerlink" title="顺序一致性"></a>顺序一致性</h3><p>任何执行结果都是相同的，就好像所有进程对数据存储的读写操作是按照某种序列顺序执行的，并且每个进程的操作按照程序所制定的顺序出现在这个序列中</p><p><img src="/../assets/dissys/Q4QGbhriBo58b6xgFERcVwOMnkf.png"></p><h3 id="线性一致性"><a href="#线性一致性" class="headerlink" title="线性一致性"></a>线性一致性</h3><p>所有进程的读写都以某种串行方式执行，顺序以及各个进程的操作维持的顺序是指定的</p><h3 id="因果一致性"><a href="#因果一致性" class="headerlink" title="因果一致性"></a>因果一致性</h3><p>一种弱化的顺序一致性模型，将具有潜在因果关系的事件和没有因果关系的事件区分开来</p><ul><li>所有进程必须以相同的顺序看到具有潜在因果关系的写操作，不同机器上可以以不同的顺序看到并发的写操作</li></ul><p><img src="/../assets/dissys/OJfIbPskSo5yuexGMaBcJAz1nYd.png"></p><h3 id="FIFO-一致性"><a href="#FIFO-一致性" class="headerlink" title="FIFO 一致性"></a>FIFO 一致性</h3><p>通过单一的进程写在其他的进程看来顺序是一致的，但是不同的进程写在其他的进程看来就未必一致</p><p><img src="/../assets/dissys/WwRsb4zvcoWtnuxdPqucYiCvnec.png"></p><h3 id="弱一致性"><a href="#弱一致性" class="headerlink" title="弱一致性"></a>弱一致性</h3><p>在所有先前的所有写入都已到处完成之前，不允许对同步变量进行任何操作</p><h3 id="释放一致性"><a href="#释放一致性" class="headerlink" title="释放一致性"></a>释放一致性</h3><p>在对共享变量的读写操作释放之前，之前所有的请求都必须被成功执行</p><p><img src="/../assets/dissys/N76ObRwxMokGQAxmdTXcsXrIn2f.png"></p><h3 id="入口一致性"><a href="#入口一致性" class="headerlink" title="入口一致性"></a>入口一致性</h3><p>不允许执行同步变量的获取访问，直到对受保护的共享数据的所有更新都已完成为止</p><p><img src="/../assets/dissys/HXtobaw3boKRzJxJ6BfcIwYgnUc.png"></p><h2 id="以客户为中心的一致性模型"><a href="#以客户为中心的一致性模型" class="headerlink" title="以客户为中心的一致性模型"></a>以客户为中心的一致性模型</h2><h3 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h3><ul><li><p>为什么要最终一致性？</p><ul><li>大多数进程几乎从不执行更新操作，而只从数据库读取数据</li><li>只有部分进程被允许更新名称空间中它所负责的部分，基本不会出现写-写操作冲突，唯一需要处理的情况是读-写操作冲突。这种情况通常允许以懒惰的方式传播更新操作</li></ul></li><li><p>什么是最终一致性？</p><ul><li>如果在一段很长的时间内没有更新操作，那么所有的副本将逐渐地成为一致的，这种形式的一致性称为最终一致性</li></ul></li></ul><h3 id="单调读一致性"><a href="#单调读一致性" class="headerlink" title="单调读一致性"></a>单调读一致性</h3><ul><li>定义<ul><li>如果一个进程读取数据项 x 的值，那么对该 x 执行的任何后续读操作将总是看到第一个读取的那个值或更新的值</li></ul></li></ul><p><img src="/../assets/dissys/BEzwbA9bmoqQeLx88yfcE5OEnUe.png"></p><h3 id="单调写一致性"><a href="#单调写一致性" class="headerlink" title="单调写一致性"></a>单调写一致性</h3><ul><li>定义<ul><li>一个进程对数据项 x 执行的写操作必须在对该进程对 x 执行的任何后续写操作之前完成<br><img src="/../assets/dissys/KAkEb4KQyow2VuxF9qucLjE4nVb.png"></li></ul></li></ul><h3 id="读写一致性"><a href="#读写一致性" class="headerlink" title="读写一致性"></a>读写一致性</h3><ul><li>定义<ul><li>一个进程对数据项 x 执行一次写操作的结果总是会被该进程对 x 执行的后续读操作看见</li></ul></li></ul><p><img src="/../assets/dissys/QC6SbovcCoKdkuxtCMXcsSOVnSf.png"></p><h3 id="写读一致性"><a href="#写读一致性" class="headerlink" title="写读一致性"></a>写读一致性</h3><ul><li>定义<ul><li>同一个进程对数据项 x 执行的读操作之后的写操作，保证发生在与 x 读取值相同或比之更新的值上</li></ul></li></ul><p><img src="/../assets/dissys/UIihbYByLoh8DKxN1Z4cLcQmnKj.png"></p><h2 id="一致性协议"><a href="#一致性协议" class="headerlink" title="一致性协议"></a>一致性协议</h2><h3 id="持续一致性"><a href="#持续一致性" class="headerlink" title="持续一致性"></a>持续一致性</h3><h3 id="基于主备份的协议"><a href="#基于主备份的协议" class="headerlink" title="基于主备份的协议"></a>基于主备份的协议</h3><p>事实证明，在顺序一致性中，基于主备份的协议比较盛行。在这些协议中，数据存储中的每个数据项有一个相关的主备份，该主备份负责协调在 x 上的写操作。根据主备份是否固定在一个远程服务器上，还是将主备份移动到启动写操作的进程那里之后写操作是否可以在本地执行，可以区分各种主备份协议</p><h4 id="远程写协议"><a href="#远程写协议" class="headerlink" title="远程写协议"></a>远程写协议</h4><ul><li>定义<ul><li>所有读操作和写操作都转发给单个固定的远程服务器的协议</li></ul></li></ul><p><img src="/../assets/dissys/DYmzbJcSNo9qvqxgykvc9MzrnRc.png"></p><ul><li>问题<ul><li>阻塞操作：性能问题，启动更新的进程在被允许继续执行前，可鞥需要等待较长的时间</li><li>非阻塞操作：容错能力。</li></ul></li></ul><h4 id="本地写协议"><a href="#本地写协议" class="headerlink" title="本地写协议"></a>本地写协议</h4><ul><li><p>定义</p><ul><li>其主副本在要执行写操作的进程之间迁移。当某个进程要更新数据项 x 时，先定位 x 的主副本，然后把它移到自己的位置上</li></ul></li><li><p>优点</p><ul><li>可以在本地执行多个连续的写操作，而读操作仍可以访问其本地副本</li></ul></li></ul><p><img src="/../assets/dissys/XlXqbGFH3oUgVLxCJOwciGs6n6f.png"></p><h3 id="复制的写协议"><a href="#复制的写协议" class="headerlink" title="复制的写协议"></a>复制的写协议</h3><p>写操作可以在多个副本上执行，而不是像主备份的副本那样只在一个副本上执行</p><h4 id="主动复制"><a href="#主动复制" class="headerlink" title="主动复制"></a>主动复制</h4><ul><li>定义<ul><li>每个副本有一个相关联的进程，该进程执行更新操作</li></ul></li></ul><h4 id="基于多数表决的协议"><a href="#基于多数表决的协议" class="headerlink" title="基于多数表决的协议"></a>基于多数表决的协议</h4><ul><li><p>定义（基本思想）</p><ul><li>要求客户在读或写一个复制的数据项之前向多个服务器提出请求，并获得他们的许可<ul><li>更新一个文件，必须先联系至少半数加一个服务器，得到他们的认可</li><li>读取一个复制文件，也必须联系至少半数加一个服务器，请求返回该文件的关联版本号，如果版本号一致，那么必定是最新的版本</li></ul></li></ul></li><li><p>Gifford 方案</p><ul><li>一个客户要读取一个具有 N 个副本的文件，必须组织一个读团体$N_R$</li><li>要修改一个文件，客户必须组织一个至少有$N_W$个服务器的写团体</li><li>限制条件<ul><li>$$<br>N_R + N_W &gt; N<br>$$</li><li>$$<br>N_W &gt; N &#x2F; 2<br>$$</li></ul></li><li>第一个条件是为了防止读写操作冲突，第二个限制条件是为了防止读读操作冲突</li></ul></li></ul><p><img src="/../assets/dissys/KG5ebuiEXofXSYxdX9ccSjmZnse.png"></p><h3 id="高速缓存相关性协议"><a href="#高速缓存相关性协议" class="headerlink" title="高速缓存相关性协议"></a>高速缓存相关性协议</h3><h1 id="容错性"><a href="#容错性" class="headerlink" title="容错性"></a>容错性</h1><h2 id="容错性概述"><a href="#容错性概述" class="headerlink" title="容错性概述"></a>容错性概述</h2><h3 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h3><ul><li>可靠的系统<ul><li>可用性：系统已经准备好，马上就可以使用</li><li>可靠性：系统可以无障碍地持续运行</li><li>安全性：系统在偶然出故障的情况下能正确操作而不会造成任何灾难</li><li>可维护性：发生故障的系统能恢复的难易程度</li></ul></li></ul><h3 id="使用冗余掩盖故障"><a href="#使用冗余掩盖故障" class="headerlink" title="使用冗余掩盖故障"></a>使用冗余掩盖故障</h3><ul><li><p>信息冗余</p><ul><li>添加额外的位可以使错乱的位恢复正常</li></ul></li><li><p>时间冗余</p><ul><li>执行一个动作，如果需要就再次执行</li></ul></li><li><p>物理冗余</p><ul><li>通过添加额外的装备或进程使系统作为一个整体来容忍部分组件的失效或故障成为可能</li></ul></li></ul><h2 id="可靠的客户-服务器通信"><a href="#可靠的客户-服务器通信" class="headerlink" title="可靠的客户-服务器通信"></a>可靠的客户-服务器通信</h2><h3 id="RPC-调用失败"><a href="#RPC-调用失败" class="headerlink" title="RPC 调用失败"></a>RPC 调用失败</h3><ul><li>RPC 调用失败类型以及解决方案<ul><li>客户端无法定位服务器<ul><li>使用特殊的返回码</li><li>抛出异常</li></ul></li><li>客户端发送到服务器的请求消息丢失<ul><li>使用定时器</li></ul></li><li>服务器返回给客户端的响应消息丢失<ul><li>使用定时器</li></ul></li><li>服务器接收到请求后崩溃<ul><li>服务器重启之前不断尝试，这种技术被称为至少一次语义</li><li>立即放弃并回滚，保证 RPC 最多一次执行语义</li><li>客户端什么也不做</li></ul></li><li>客户端发送消息后崩溃<ul><li>孤儿消灭：在客户存根发送 RPC 消息前进行日志记录说明要做什么，重新启动前对日志进行检查然后明确杀死孤儿</li><li>再生：客户端恢复后广播重启新一个轮次的请求，所有与那个客户有关的远程计算都被杀死</li><li>优雅重生：在新时期广播到达时，每台机器都进行检查来查看是否存在远程计算，如果有，就尝试定位它的拥有者，只有当不能找到拥有者时才杀死该计算</li><li>到期：每个 RPC 都有一个标准的时间 T，如果到时间还不能结束，就必须显式地请求另外的时间量</li></ul></li></ul></li></ul><h2 id="分布式提交"><a href="#分布式提交" class="headerlink" title="分布式提交"></a>分布式提交</h2><h3 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h3><p>由两个阶段组成，每个阶段又由两部组成。表决阶段的第一阶段由 12 组成，第二阶段是决定阶段由 34 组成。</p><ol><li>协作者向所有的参与者发送一个 <code>VOTE_REQUEST</code> 消息</li><li>当参与者接收到 <code>VOTE_REQUEST</code> 消息时，就向协作者返回一个 <code>VOTE_COMMIT</code> 消息通知协作者它已经准备好本地提交事务中属于它的部分，否则就返回一个 <code>VOTE_ABORT</code> 消息</li><li>协作者收集来自参与者的所有选票。如果所有的参与者都表决要提交事务，那么协作者就进行提交。在这种情况下它向所有的参与者发送一个 <code>GLOBAL_COMMIT</code> 消息。但是，如果有一个参与者表决要取消事务，那么协作者就决定取消事务并多播一个 <code>GLOBAL_ABORT</code> 消息</li><li>每个提交表决的参与者都等待协作者的最后反应。如果参与者收到一个 <code>GLOBAL_COMMIT</code> 消息，那么它就在本地提交事务，否则当接收到一个 <code>GLOBAL_ABORT</code> 消息时，就在本地取消事务</li></ol><h3 id="三阶段提交"><a href="#三阶段提交" class="headerlink" title="三阶段提交"></a>三阶段提交</h3><p>两阶段的一个问题是当协作者崩溃时，参与者不能做出最后的决定。参与者需要在协作者恢复之前保持阻塞</p><h2 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h2><h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><ul><li><p>回退恢复</p><ul><li>将系统从当前的错误状态回到先前的正确状态</li><li>每次记录系统的当前状态时，就成为设置一个检查点</li></ul></li><li><p>前向恢复</p><ul><li>尝试从可以继续执行的某点开始把系统带入一个正确的新状态</li></ul></li></ul><h3 id="检查点"><a href="#检查点" class="headerlink" title="检查点"></a>检查点</h3><ul><li>独立的检查点：进程独立地设置本地检查点</li><li>协调检查点：</li></ul>]]></content>
    
    
    <categories>
      
      <category>南大</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Durable Function</title>
    <link href="/2023/12/05/durable_function/"/>
    <url>/2023/12/05/durable_function/</url>
    
    <content type="html"><![CDATA[<h1 id="Azure-Functions-Durable-Functions"><a href="#Azure-Functions-Durable-Functions" class="headerlink" title="Azure Functions &amp; Durable Functions"></a>Azure Functions &amp; Durable Functions</h1><h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><h2 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h2><ul><li>前置条件<ul><li>VSCode 安装</li><li>Azure Function 的 VSCode 插件安装</li><li>Azure Function Core Tools 下载</li><li>NodeJS 18 以上</li></ul></li></ul><h3 id="Azure-Function-Code-Tools-下载"><a href="#Azure-Function-Code-Tools-下载" class="headerlink" title="Azure Function Code Tools 下载"></a>Azure Function Code Tools 下载</h3><ol><li>安装微软的包密钥</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor &gt; microsoft.gpg<br>sudo <span class="hljs-built_in">mv</span> microsoft.gpg /etc/apt/trusted.gpg.d/microsoft.gpg<br></code></pre></td></tr></table></figure><ol start="2"><li>设置源</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo sh -c <span class="hljs-string">&#x27;echo &quot;deb [arch=amd64] https://packages.microsoft.com/debian/$(lsb_release -rs | cut -d&#x27;</span>.<span class="hljs-string">&#x27; -f 1)/prod $(lsb_release -cs) main&quot; &gt; /etc/apt/sources.list.d/dotnetdev.list&#x27;</span><br></code></pre></td></tr></table></figure><blockquote><p>需要做一些小小的修改</p><ul><li>将 20 改为 10，因为我是 debian10 系列的主机</li><li>apricot 改为 buster</li></ul></blockquote><ol start="3"><li>更新源</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get update<br></code></pre></td></tr></table></figure><ol start="4"><li>安装</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get install azure-functions-core-tools-4<br></code></pre></td></tr></table></figure><p><img src="/../assets/durable_function/MicRbJhjio7nALxC2Gtcyvofn5d.png"></p><h3 id="创建本地项目"><a href="#创建本地项目" class="headerlink" title="创建本地项目"></a>创建本地项目</h3><ol><li>使用 VSCode 插件创建 New Project</li><li>选择一个空文件夹</li><li>完成以下设置</li></ol><p><img src="/../assets/durable_function/Qe7jbakHxoDzRHxTyKvc0O6wnFh.png"></p><ol start="4"><li>创建结果</li></ol><p><img src="/../assets/durable_function/WtMyb5p9aokhv7xlPcgcpQt6nj2.png"></p><h3 id="安装-Durable-Functions-包"><a href="#安装-Durable-Functions-包" class="headerlink" title="安装 Durable Functions 包"></a>安装 Durable Functions 包</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install durable-functions@preview<br></code></pre></td></tr></table></figure><h3 id="创建函数"><a href="#创建函数" class="headerlink" title="创建函数"></a>创建函数</h3><p>最基本的 Durable Functions 应用有三类基本的函数</p><ul><li><code>Orchestrator function</code>：描述一个编排其他 functions 的 workflow</li><li><code>Activity function</code>：由 <code>orchestrator function</code> 调用，执行工作，可能返回结果</li><li><code>Client function</code>：一个常规的 <code>Azure Function</code> 用来启动一个 <code>orchestrator function</code></li></ul><ol><li>用 VSCode 创建一个 <code>function</code></li><li>完成以下设置</li></ol><p><img src="/../assets/durable_function/PJ5QbDPmJotWDtxtTrJcn4vVnyb.png"></p><ol start="3"><li>可以在 <code>src/functions/hello.js</code> 中看到函数</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs bash">const &#123; app &#125; = require(<span class="hljs-string">&#x27;@azure/functions&#x27;</span>);<br>const <span class="hljs-built_in">df</span> = require(<span class="hljs-string">&#x27;durable-functions&#x27;</span>);<br><br>const activityName = <span class="hljs-string">&#x27;hello&#x27;</span>;<br><br>df.app.orchestration(<span class="hljs-string">&#x27;helloOrchestrator&#x27;</span>, <span class="hljs-keyword">function</span>* (context) &#123;<br>    const outputs = [];<br>    outputs.push(yield context.df.callActivity(activityName, <span class="hljs-string">&#x27;Tokyo&#x27;</span>));<br>    outputs.push(yield context.df.callActivity(activityName, <span class="hljs-string">&#x27;Seattle&#x27;</span>));<br>    outputs.push(yield context.df.callActivity(activityName, <span class="hljs-string">&#x27;Cairo&#x27;</span>));<br><br>    <span class="hljs-built_in">return</span> outputs;<br>&#125;);<br><br>df.app.activity(activityName, &#123;<br>    handler: (input) =&gt; &#123;<br>        <span class="hljs-built_in">return</span> `Hello, <span class="hljs-variable">$&#123;input&#125;</span>`;<br>    &#125;,<br>&#125;);<br><br>app.http(<span class="hljs-string">&#x27;helloHttpStart&#x27;</span>, &#123;<br>    route: <span class="hljs-string">&#x27;orchestrators/&#123;orchestratorName&#125;&#x27;</span>,<br>    extraInputs: [df.input.durableClient()],<br>    handler: async (request, context) =&gt; &#123;<br>        const client = df.getClient(context);<br>        const body = await request.text();<br>        const instanceId = await client.startNew(request.params.orchestratorName, &#123; input: body &#125;);<br><br>        context.log(`Started orchestration with ID = <span class="hljs-string">&#x27;$&#123;instanceId&#125;&#x27;</span>.`);<br><br>        <span class="hljs-built_in">return</span> client.createCheckStatusResponse(request, instanceId);<br>    &#125;,<br>&#125;);<br></code></pre></td></tr></table></figure><p>在这个例子中</p><ul><li>创建了一个名字为 <code>helloOrchestrator</code> 的编排函数</li><li>创建了一个叫做 <code>hello</code> 的活动函数</li><li>编排函数编排了多个活动函数</li><li>添加了一个 <code>HTTP trigger</code> 函数来启动编排函数</li></ul><h3 id="测试函数"><a href="#测试函数" class="headerlink" title="测试函数"></a>测试函数</h3><h4 id="本地模拟器"><a href="#本地模拟器" class="headerlink" title="本地模拟器"></a>本地模拟器</h4><ol><li>安装 Azurite 插件</li><li>启动所有 Azurite 服务</li></ol><p><img src="/../assets/durable_function/UOMFbfGUioRuCWxc7Etc87CLnib.png"></p><ol start="3"><li>F5 运行</li></ol><p><img src="/../assets/durable_function/WfwIbz34folArpx86bOcvzjKnie.png"></p><p><img src="/../assets/durable_function/TnKRbw9JxoyA3Jx0lhicaIAWnLf.png"></p><p><img src="/../assets/durable_function/KpzobaVm6oEsCLxbBAuclR2sndc.png"></p><ol start="4"><li>存储状态文件</li></ol><p><img src="/../assets/durable_function/Rk4ybJNjToS0xQxI251cN18wnLh.png"></p><h1 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h1><h2 id="实体函数"><a href="#实体函数" class="headerlink" title="实体函数"></a>实体函数</h2><p>实体的行为有点类似于通过消息进行通信的微型服务。 每个实体具有唯一的标识和内部状态（如果存在）。 与服务或对象一样，实体会根据提示执行操作。 执行的操作可能会更新实体的内部状态。 它还可能会调用外部服务并等待响应。 实体使用通过可靠队列隐式发送的消息来与其他实体、业务流程和客户端通信。</p><p>其内部存储的有关某个实体示例的信息如下图所示，其中的 <code>input</code> 字段</p><p><img src="/../assets/durable_function/TFeBbFAveoQZsvxT7pJcRYkXnzc.png"></p><h1 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h1><h2 id="可靠执行"><a href="#可靠执行" class="headerlink" title="可靠执行"></a>可靠执行</h2><p>DF 能够确保编排的可靠执行，这是通过使用存储队列来驱动函数的触发以及通过存放执行历史记录来实现的。</p><h3 id="任务关键类"><a href="#任务关键类" class="headerlink" title="任务关键类"></a>任务关键类</h3><p><img src="/./../assets/durable_function/taskkeyclass.png"></p><h4 id="TaskBase"><a href="#TaskBase" class="headerlink" title="TaskBase"></a><code>TaskBase</code></h4><p>所有任务的基类，定义了所有任务的基本状态转移</p><ul><li>在 <code>orchestrator</code> 调用 <code>callActicity</code> 函数的时候，其内部会创建 <code>AtomicTask</code> 类，该类是 <code>TaskBase</code> 的一个子类</li><li>该类的内部存储了 <code>task</code> 的状态 <code>state</code>，表明该任务是 <code>Running</code>、<code>Failed</code> 或者 <code>Completed</code></li><li>当任务（通常是 <code>CompoundTask</code>）调用这个函数时，会判断这个函数是否已经被执行过</li></ul><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@hidden</span></span><br><span class="hljs-comment"> * Notifies this task&#x27;s parents about its state change.</span><br><span class="hljs-comment"> */</span><br>private <span class="hljs-title function_">propagate</span>(executor?: <span class="hljs-title class_">TaskOrchestrationExecutor</span>): <span class="hljs-keyword">void</span> &#123;<br>    <span class="hljs-keyword">const</span> hasCompleted = <span class="hljs-variable language_">this</span>.<span class="hljs-property">state</span> !== <span class="hljs-title class_">TaskState</span>.<span class="hljs-property">Running</span>;<br>    <span class="hljs-keyword">if</span> (hasCompleted &amp;&amp; <span class="hljs-variable language_">this</span>.<span class="hljs-property">parent</span> !== <span class="hljs-literal">undefined</span>) &#123;<br>        <span class="hljs-variable language_">this</span>.<span class="hljs-property">parent</span>.<span class="hljs-title function_">handleCompletion</span>(<span class="hljs-variable language_">this</span>, executor);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="DFTask"><a href="#DFTask" class="headerlink" title="DFTask"></a><code>DFTask</code></h4><p>该类简单继承了一下 <code>TaskBase</code>，增加了函数的回调操作</p><h4 id="CompoundTask"><a href="#CompoundTask" class="headerlink" title="CompoundTask"></a><code>CompoundTask</code></h4><p>该类继承 <code>DFTask</code>，包含了多个 <code>TaskBase</code>，也就是维护了多个子任务</p><h3 id="编排关键类"><a href="#编排关键类" class="headerlink" title="编排关键类"></a>编排关键类</h3><p><img src="/../assets/durable_function/orchkeyclass.png"></p><h4 id="Orchestrator"><a href="#Orchestrator" class="headerlink" title="Orchestrator"></a><code>Orchestrator</code></h4><ul><li>负责监听一个编排触发器 <code>DurableOrchestrationBindingInfo</code> 以及处理维护一个上下文 <code>OrchestrationContext</code>，将结果返回给 <code>OrchestratorState</code></li><li>处理的最后将上下文等信息交托给 <code>TaskOrchestrationExecutor</code> 继续执行</li></ul><h4 id="TaskOrchestrationExecutor"><a href="#TaskOrchestrationExecutor" class="headerlink" title="TaskOrchestrationExecutor"></a><code>TaskOrchestrationExecutor</code></h4><p><code>execute</code> 函数负责管理一个编排函数的执行，并且通过历史记录进行重播</p><ol><li>通过历史记录执行编排函数</li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-comment">// Execute the orchestration, using the history for replay</span><br><span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> historyEvent <span class="hljs-keyword">of</span> history) &#123;<br>    <span class="hljs-variable language_">this</span>.<span class="hljs-title function_">processEvent</span>(historyEvent);<br>    <span class="hljs-keyword">if</span> (<span class="hljs-variable language_">this</span>.<span class="hljs-title function_">isDoneExecuting</span>()) &#123;<br>        <span class="hljs-keyword">break</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ol start="2"><li><code>processEvent</code> 函数的主要功能</li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs javascript">private <span class="hljs-title function_">processEvent</span>(<span class="hljs-attr">event</span>: <span class="hljs-title class_">HistoryEvent</span>): <span class="hljs-keyword">void</span> &#123;<br>    <span class="hljs-keyword">const</span> eventType = event.<span class="hljs-property">EventType</span>;<br>    <span class="hljs-keyword">switch</span> (eventType) &#123;<br>        <span class="hljs-keyword">case</span> <span class="hljs-title class_">HistoryEventType</span>.<span class="hljs-property">OrchestratorStarted</span>: &#123;<br>            ...<br>        &#125;<br>        <span class="hljs-keyword">case</span> <span class="hljs-title class_">HistoryEventType</span>.<span class="hljs-property">ContinueAsNew</span>: &#123;<br>           <span class="hljs-comment">// 清除所有编排的状态</span><br>        &#125;<br>        <span class="hljs-keyword">case</span> <span class="hljs-title class_">HistoryEventType</span>.<span class="hljs-property">ExecutionStarted</span>: &#123;<br>           <span class="hljs-comment">// 继续执行编排函数</span><br>        &#125;<br>        <span class="hljs-keyword">case</span> <span class="hljs-title class_">HistoryEventType</span>.<span class="hljs-property">EventSent</span>: &#123;<br>           <span class="hljs-comment">// 更新事件ID</span><br>        &#125;<br>        <span class="hljs-attr">default</span>:<br>            <span class="hljs-comment">// 如果当前事件包含了已完成任务的数据，则将该任务封装成一个值</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ol start="3"><li><p><code>tryResumingUserCode</code> 函数</p><ol><li>如果当前执行的任务还在 <code>running</code> 则不能直接执行</li><li>如果整个编排函数执行完成了，则获取其返回值</li><li>如果结果生成器返回了一个 <code>DFTask</code>，那么就表示接下来要执行新的函数</li><li>然后编排函数再以递归的方式执行该函数</li></ol></li><li><p>构建当前的编排状态</p></li></ol><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs javascript"><span class="hljs-comment">// Construct current orchestration state</span><br><span class="hljs-keyword">const</span> <span class="hljs-attr">actions</span>: <span class="hljs-title class_">IAction</span>[][] = <span class="hljs-variable language_">this</span>.<span class="hljs-property">actions</span>.<span class="hljs-property">length</span> == <span class="hljs-number">0</span> ? [[]] : [<span class="hljs-variable language_">this</span>.<span class="hljs-property">actions</span>];<br><span class="hljs-keyword">const</span> orchestratorState = <span class="hljs-keyword">new</span> <span class="hljs-title class_">OrchestratorState</span>(&#123;<br>    <span class="hljs-attr">isDone</span>: <span class="hljs-variable language_">this</span>.<span class="hljs-title function_">hasCompletedSuccessfully</span>(),<br>    <span class="hljs-attr">actions</span>: actions,<br>    <span class="hljs-attr">output</span>: <span class="hljs-variable language_">this</span>.<span class="hljs-property">output</span>,<br>    <span class="hljs-attr">error</span>: <span class="hljs-variable language_">this</span>.<span class="hljs-property">exception</span>?.<span class="hljs-property">message</span>,<br>    <span class="hljs-attr">customStatus</span>: <span class="hljs-variable language_">this</span>.<span class="hljs-property">context</span>.<span class="hljs-property">customStatus</span>,<br>    <span class="hljs-attr">schemaVersion</span>: <span class="hljs-variable language_">this</span>.<span class="hljs-property">schemaVersion</span>,<br>&#125;);<br></code></pre></td></tr></table></figure><h4 id="DurableOrchestrationContext"><a href="#DurableOrchestrationContext" class="headerlink" title="DurableOrchestrationContext"></a><code>DurableOrchestrationContext</code></h4><p>维护函数流的上下文</p>]]></content>
    
    
    <categories>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Serverless</tag>
      
      <tag>Function orchestration</tag>
      
      <tag>Azure</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PXE 批量部署</title>
    <link href="/2023/11/27/PXE/"/>
    <url>/2023/11/27/PXE/</url>
    
    <content type="html"><![CDATA[<h1 id="PXE-批量部署"><a href="#PXE-批量部署" class="headerlink" title="PXE 批量部署"></a>PXE 批量部署</h1><ul><li>代码仓库：<a href="https://github.com/Xdydy/pxe">https://github.com/Xdydy/pxe</a></li></ul><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>PXE（Preboot Execution Environment，预启动执行环境）批量部署是一种通过网络对计算机系统进行安装和配置的技术。这种技术主要用于大规模部署操作系统，特别是在企业或教育机构等环境中，可以同时为多台计算机安装操作系统和软件。下面是 PXE 批量部署的主要步骤和特点：</p><ol><li><strong>启动环境设置</strong>：PXE 利用网络接口卡（NIC）的预引导功能，允许计算机在操作系统加载之前从网络启动。</li><li><strong>TFTP服务器</strong>：PXE 客户端通过网络从 TFTP（Trivial File Transfer Protocol，简单文件传输协议）服务器下载所需的引导文件和操作系统映像。</li><li><strong>DHCP服务</strong>：动态主机配置协议（DHCP）服务器为 PXE 客户端提供网络配置信息，如 IP 地址、子网掩码、默认网关和 TFTP 服务器地址。</li><li><strong>无需物理介质</strong>：与传统的基于 CD&#x2F;DVD 或 USB 驱动器的安装不同，PXE 批量部署不需要物理介质，大大简化了安装过程。</li><li><strong>自动化安装</strong>：PXE 批量部署可以结合脚本和配置文件实现操作系统的自动化安装和配置，减少了手动干预的需求。</li><li><strong>适用于多种操作系统</strong>：PXE 批量部署不限于特定的操作系统，可以用于安装多种不同的操作系统，包括 Windows、Linux 等。</li></ol><p>PXE 批量部署特别适合需要在短时间内为大量计算机安装或重新安装操作系统的情况，大大提高了效率和一致性。</p><h2 id="KVM-与-TCG"><a href="#KVM-与-TCG" class="headerlink" title="KVM 与 TCG"></a>KVM 与 TCG</h2><h3 id="KVM-模式"><a href="#KVM-模式" class="headerlink" title="KVM 模式"></a>KVM 模式</h3><p>KVM（Kernel-based Virtual Machine）是一种基于 Linux 内核的虚拟化技术。它允许你在 Linux 系统上运行多个带有自己操作系统的虚拟机，这些虚拟机可以是 Linux、Windows 或其他任何支持 x86 架构的操作系统。KVM 模式的特点包括：</p><ol><li><strong>硬件辅助虚拟化</strong>：KVM 利用现代处理器的硬件虚拟化支持（如 Intel VT 或 AMD-V）来提高性能。</li><li><strong>内核级运行</strong>：作为 Linux 内核的一部分运行，提供高效的性能和优良的集成。</li><li><strong>支持多种客户机操作系统</strong>：可以在 KVM 上运行各种操作系统。</li></ol><h3 id="TCG-模式"><a href="#TCG-模式" class="headerlink" title="TCG 模式"></a>TCG 模式</h3><p>TCG（Tiny Code Generator）是 QEMU（一种常用的虚拟化软件）使用的软件模拟模式。当硬件不支持虚拟化或者没有启用硬件虚拟化功能时，QEMU 会使用 TCG 来模拟 CPU，这意味着 CPU 指令是在软件层面上被模拟的。TCG 模式相比 KVM 模式性能较低，但它可以在不支持硬件虚拟化的环境下工作。</p><h3 id="如何检查系统是否支持-KVM"><a href="#如何检查系统是否支持-KVM" class="headerlink" title="如何检查系统是否支持 KVM"></a>如何检查系统是否支持 KVM</h3><p>要检查您的 Linux 系统是否支持 KVM，您可以使用以下命令：</p><ol><li><strong>检查<strong><strong>CPU</strong></strong>是否支持硬件虚拟化</strong>：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">egrep -c <span class="hljs-string">&#x27;(vmx|svm)&#x27;</span> /proc/cpuinfo<br></code></pre></td></tr></table></figure><p>如果这个命令返回的数字大于0，那么您的CPU支持硬件虚拟化（vmx针对Intel处理器，svm针对AMD处理器）。</p><ol start="2"><li><strong>检查<strong><strong>KVM</strong></strong>内核模块是否已加载</strong>：</li></ol><ul><li>对于Intel处理器：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">lsmod | grep kvm_intel<br></code></pre></td></tr></table></figure><ul><li>对于 AMD 处理器：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">lsmod | grep kvm_amd<br></code></pre></td></tr></table></figure> 如果这些命令返回了结果，表明相应的KVM模块已经被加载到内核中。</li></ul><ol><li><p><strong>检查是否安装了<strong><strong>KVM</strong></strong>工具：</strong></p><p>可以通过检查<code>qemu-kvm</code>包是否安装来确定系统是否配置了KVM。</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kvm-ok<br></code></pre></td></tr></table></figure><p>如果您的系统安装了 <code>cpu-checker</code> 包，<code>kvm-ok</code> 命令会告诉您系统是否准备好运行 KVM 虚拟机。</p><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><h3 id="以命令行的方式启动虚拟机镜像"><a href="#以命令行的方式启动虚拟机镜像" class="headerlink" title="以命令行的方式启动虚拟机镜像"></a>以命令行的方式启动虚拟机镜像</h3><p>通过命令行启动虚拟机的镜像通常涉及到使用虚拟化工具，例如 QEMU 或 KVM。以下是使用 QEMU&#x2F;KVM 通过命令行启动一个虚拟机镜像的基本步骤：</p><h4 id="使用-QEMU-启动虚拟机"><a href="#使用-QEMU-启动虚拟机" class="headerlink" title="使用 QEMU 启动虚拟机"></a>使用 QEMU 启动虚拟机</h4><ol><li><strong>安装 QEMU</strong>（如果尚未安装）：</li></ol><p>在 Ubuntu 或 Debian 系统上，您可以使用以下命令安装 QEMU：</p><ol><li><p><strong>启动虚拟机</strong>：</p><p>使用以下命令启动虚拟机镜像：</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">qemu-system-x86_64 -hda /path/to/your/vm/image.img<br></code></pre></td></tr></table></figure><ul><li><code>qemu-system-x86_64</code> 是 QEMU 用于 x86_64 架构的模拟器。</li><li><code>-hda</code> 指定硬盘镜像的位置，这里是您的虚拟机镜像的路径。</li></ul><ol start="2"><li><strong>其他选项</strong>：</li></ol><ul><li>您可以添加 <code>-m</code> 参数来指定分配给虚拟机的内存量。例如，<code>-m 2048</code> 分配 2GB 内存。</li><li><code>-cdrom</code> 参数可以用来指定一个 ISO 镜像以模拟光驱。例如，<code>-cdrom /path/to/cdrom/image.iso</code>。</li></ul><h1 id="预备工具"><a href="#预备工具" class="headerlink" title="预备工具"></a>预备工具</h1><h2 id="准备-Ubuntu-镜像"><a href="#准备-Ubuntu-镜像" class="headerlink" title="准备 Ubuntu 镜像"></a>准备 Ubuntu 镜像</h2><p>从 <a href="https://mirrors.nju.edu.cn/ubuntu-releases/22.04/ubuntu-22.04.3-live-server-amd64.iso">https://mirrors.nju.edu.cn/ubuntu-releases/22.04/ubuntu-22.04.3-live-server-amd64.iso</a> 下下载.iso 镜像，举个例子，放到 <code>~/Downloads</code> 目录下</p><h2 id="DHCP-服务器"><a href="#DHCP-服务器" class="headerlink" title="DHCP 服务器"></a>DHCP 服务器</h2><ol><li>配置网络适配器</li></ol><p>由于未来的虚拟机要在 <code>192.168.1.n</code> 的网络环境下进行通信，我们需要建造一个网桥</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo brctl addbr br0<br>sudo ifup br0<br>sudo ip <span class="hljs-built_in">link</span> <span class="hljs-built_in">set</span> br0 up<br></code></pre></td></tr></table></figure><ol><li>编辑 <code>/etc/network/interfaces</code> 文件</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">auto br0<br>iface br0 inet static<br>    address 192.168.1.1<br>    netmask 255.255.255.0<br>    network 192.168.1.0<br>    broadcast 192.168.1.255<br></code></pre></td></tr></table></figure><ol start="2"><li>安装 <code>dhcp</code> 服务器</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt install isc-dhcp-server<br></code></pre></td></tr></table></figure><ol start="3"><li>配置 <code>dhcp</code> 服务器<br>编辑 DHCP 服务器的配置文件 <code>/etc/dhcp/dhcpd.conf</code>，将配置文件加入到里头</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">subnet 192.168.1.0 netmask 255.255.255.0 &#123;<br>    range 192.168.1.10 192.168.1.100;<br>    option domain-name-servers 8.8.8.8;<br>    option routers 192.168.1.1;<br>    option broadcast-address 192.168.1.255;<br>    default-lease-time 600;<br>    max-lease-time 7200;<br>&#125;<br><br>allow booting;<br>allow bootp;<br><br>next-server 192.168.1.1;<br>filename <span class="hljs-string">&quot;pxelinux.0&quot;</span>;<br></code></pre></td></tr></table></figure><p>这个配置指定了 DHCP 服务管理的子网、IP 地址范围、DNS 服务器地址、默认路由器（网关）地址和广播地址。另外 <code>filename</code> 定义了 <code>tftp</code> 服务器的相关配置，在下列文档中会提到</p><ol start="4"><li>指定网络接口</li></ol><p>在 <code>/etc/default/isc-dhcp-server</code> 文件中指定 <code>DHCP</code> 服务应该监听的网络接口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">INTERFACESv4=<span class="hljs-string">&quot;br0&quot;</span><br></code></pre></td></tr></table></figure><ol start="5"><li>使用 <code>systemctl</code> 启动 <code>dhcp</code> 服务</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo systemctl start isc-dhcp-server.service<br><span class="hljs-comment"># 检查启动状态</span><br>sudo systemctl status isc-dhcp-server.service<br></code></pre></td></tr></table></figure><h2 id="TFTP-服务器"><a href="#TFTP-服务器" class="headerlink" title="TFTP 服务器"></a>TFTP 服务器</h2><ol><li>下载 <code>tftp</code> 服务器</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt install tftpd-hpa<br></code></pre></td></tr></table></figure><ol start="2"><li>配置 <code>tftp</code> 服务器</li></ol><p>编辑 <code>/etc/default/tftp-hpa</code> 文件为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">TFTP_USERNAME=<span class="hljs-string">&quot;tftp&quot;</span><br>TFTP_DIRECTORY=<span class="hljs-string">&quot;/var/lib/tftpboot&quot;</span><br>TFTP_ADDRESS=<span class="hljs-string">&quot;0.0.0.0:69&quot;</span><br>TFTP_OPTIONS=<span class="hljs-string">&quot;--secure&quot;</span><br></code></pre></td></tr></table></figure><ol start="3"><li>设置 <code>tftp</code> 根目录</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mkdir</span> /var/lib/tftpboot<br>sudo <span class="hljs-built_in">chown</span> tftp:tftp /var/lib/tftpboot<br>sudo <span class="hljs-built_in">chmod</span> -R 755 /var/lib/tftpboot<br></code></pre></td></tr></table></figure><ol start="4"><li>设置 <code>qemu</code> 安装时的引导文件</li></ol><p>编辑 <code>/var/lib/tftpboot/pxelinux.cfg/default</code> 文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">DEFAULT linux<br>LABEL linux<br>  SAY <span class="hljs-string">&quot;Booting the Ubuntu 22.04 Installer...&quot;</span><br>  KERNEL vmlinuz<br>  INITRD initrd<br>  APPEND root=/dev/ram0 ramdisk_size=1500000  ip=dhcp url=http://192.168.1.1/ubuntu-22.04.3-live-server-amd64.iso autoinstall ds=nocloud-net s=http://192.168.1.1/autoinstall/ cloud-config-url=http://192.168.1.1/autoinstall/user-data console=tty1 console=ttyS0 ---<br></code></pre></td></tr></table></figure><ul><li><p><code>DEFAULT linux</code>: 这指定了默认的标签或菜单项，当 PXE 引导时，如果没有用户交互，将自动选择这个菜单项。</p></li><li><p><code>LABEL linux</code>: 这定义了一个新的标签或菜单项，可以通过用户输入或默认设置被选择。</p></li><li><p><code>SAY &quot;Booting the Ubuntu 22.04 Installer...&quot;</code>: 这将在引导时在屏幕上打印一条消息，指示正在启动安装程序。</p></li><li><p><code>KERNEL vmlinuz</code>: 这指定了内核文件的位置，该文件是必须由 TFTP 服务器提供的，以便客户端下载并启动。</p></li><li><p><code>INITRD initrd</code>: 这指定了初始化 RAM 磁盘的位置，这也是由 TFTP 服务器提供，包含了内核在启动过程中所需的所有驱动程序和工具。</p></li><li><p><code>APPEND</code>: 这一行提供了内核启动时所需的额外参数：</p><ul><li><code>root=/dev/ram0</code>: 使用 RAM 磁盘作为根文件系统。</li><li><code>ramdisk_size=1500000</code>: 设置 RAM 磁盘的大小（以千字节为单位）。</li><li><code>ip=dhcp</code>: 通过 DHCP 获得 IP 地址。</li><li><code>url=http://192.168.1.1/ubuntu-22.04.3-live-server-amd64.iso</code>: 指定 Ubuntu 安装 ISO 文件的位置，PXE 客户端将从这个 URL 下载 ISO 并进行安装。</li><li><code>autoinstall</code>: 指定使用 autoinstall 方法进行无人值守安装。</li><li><code>ds=nocloud-net s=http://192.168.1.1/autoinstall/</code>: 指定 autoinstall 配置文件的位置，它告诉安装程序如何进行无人值守安装。</li><li><code>cloud-config-url=http://192.168.1.1/autoinstall/user-data</code>: 指定用户数据文件的 URL，它包含了安装过程中所需的用户和系统配置。</li><li><code>console=tty1 console=ttyS0</code>: 指定控制台输出应该重定向到哪里，<code>tty1</code> 是第一个虚拟终端，<code>ttyS0</code> 是第一个串行端口。</li></ul></li></ul><blockquote><p>以上 http 的内容将在 Apache 服务器的配置中实现</p></blockquote><ol start="5"><li>放置资源文件</li></ol><p>从刚才的 <code>.iso</code> 镜像中拿取响应的资源文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mkdir</span> -p /mnt/ubuntu<br>sudo mount -o loop ~/Downloads/ubuntu-22.04.3-live-server-amd64.iso /mnt/ubuntu<br>sudo <span class="hljs-built_in">cp</span> /mnt/casper/vmlinuz /var/lib/tftpboot/<br>sudo <span class="hljs-built_in">cp</span> /mnt/casper/initrd /var/lib/tftpboot/<br>sudo umount /mnt/ubuntu<br></code></pre></td></tr></table></figure><ol start="6"><li>启动 <code>tftp</code> 服务</li></ol><p>配置完成后，启动 <code>tftp</code> 服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo systemctl start tftp-hpa.service<br>sudo systemctl status tftp-hpa.service<br></code></pre></td></tr></table></figure><h2 id="Apache-服务器"><a href="#Apache-服务器" class="headerlink" title="Apache 服务器"></a>Apache 服务器</h2><ol><li>安装 <code>Apache</code> 服务器</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt install apache2<br></code></pre></td></tr></table></figure><ol start="2"><li>配置 <code>Apache</code> 服务器</li></ol><p>编辑 <code>/etc/apache2/apache2.conf</code> 文件，在最后一行指定 <code>Apache</code> 服务器监听的位置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">serverName 192.168.1.1<br></code></pre></td></tr></table></figure><ol start="3"><li>启动 <code>Apache</code> 服务</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo systemctl start apache2<br></code></pre></td></tr></table></figure><ol start="4"><li>开机自启动</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo systemctl <span class="hljs-built_in">enable</span> apache2<br></code></pre></td></tr></table></figure><ol start="5"><li>检查 <code>Apache</code> 服务状态</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo systemctl status apache2<br></code></pre></td></tr></table></figure><ol start="6"><li>放置资源文件<ul><li>首先将.iso 镜像放到 <code>/var/www/html</code> 中</li><li>放 <code>autoinstall</code> 目录</li></ul></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mkdir</span> -p /var/www/html/autoinstall<br>sudo <span class="hljs-built_in">touch</span> /var/www/html/autoinstall/meta-data<br>sudo <span class="hljs-built_in">chmod</span> -R 777 /var/www/html/autoinstall<br></code></pre></td></tr></table></figure><ul><li><p>放置初始化脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mkdir</span> -p /var/www/html/init<br>sudo <span class="hljs-built_in">cp</span> init/install.sh /var/www/html/init<br>sudo <span class="hljs-built_in">cp</span> init/http_server.py /var/www/html/init<br>sudo <span class="hljs-built_in">cp</span> init/http_server.service /var/www/html/init<br></code></pre></td></tr></table></figure></li><li><p>放置ssh文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mkdir</span> -p /var/www/html/ssh<br>sudo <span class="hljs-built_in">cp</span> ~/.ssh/id_ed25519 /var/www/html/ssh<br>sudo <span class="hljs-built_in">cp</span> ~/.ssh/id_ed25519.pub /var/www/html/ssh<br></code></pre></td></tr></table></figure></li></ul><h1 id="构建流程"><a href="#构建流程" class="headerlink" title="构建流程"></a>构建流程</h1><h2 id="构建虚拟机镜像"><a href="#构建虚拟机镜像" class="headerlink" title="构建虚拟机镜像"></a>构建虚拟机镜像</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">bash build.sh 10<br></code></pre></td></tr></table></figure><p>该过程会调用 <code>user_data.py</code> 自动生成 <code>user-data</code> 放到 <code>Apache</code> 服务器的目录下，然后生成 <code>vm-10</code> 目录</p><h2 id="启动虚拟机"><a href="#启动虚拟机" class="headerlink" title="启动虚拟机"></a>启动虚拟机</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">bash vm-10 run.sh<br></code></pre></td></tr></table></figure><p>启动后安装相应工具，安装脚本已经预先安装在了 <code>/install.sh</code> 下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">bash /install.sh<br></code></pre></td></tr></table></figure><h2 id="测试连通性"><a href="#测试连通性" class="headerlink" title="测试连通性"></a>测试连通性</h2><ol><li>通过主机请求虚拟机的端口获取虚拟机的机器编号</li><li>测试虚拟机是否能够 ping 通主机</li><li>测试主机是否能够 ping 通虚拟机</li><li>测试虚拟机之间能否互相 ping 通</li></ol><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="网桥问题"><a href="#网桥问题" class="headerlink" title="网桥问题"></a>网桥问题</h2><ul><li><p>问题描述</p><ul><li>要启动虚拟机的时候需要用到 <code>br0</code> 作为网桥，使用 <code>helper</code> 参数前需要先 allow 一下 br0</li><li>启动脚本访问该文件的时候需要 <code>root</code> 权限</li></ul></li><li><p>解决方案</p><ul><li>编辑 <code>/etc/qemu/bridge.conf</code> 为</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">allow br0<br></code></pre></td></tr></table></figure><ul><li>为<code>/usr/lib/qemu/qemu-bridge-helper</code>添加权限<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">chmod</span> u+s /usr/lib/qemu/qemu-bridge-helper<br></code></pre></td></tr></table></figure></li></ul><h2 id="MAC-地址重复"><a href="#MAC-地址重复" class="headerlink" title="MAC 地址重复"></a>MAC 地址重复</h2><ul><li>问题描述<ul><li>在启动多台虚拟机后，默认的多台虚拟机的 mac 地址会有重复</li></ul></li><li>解决方案<ul><li>在启动时添加一个 mac 地址的参数，其中 14 表示虚拟机 20</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">mac=08:00:27:02:14:E7<br></code></pre></td></tr></table></figure><h2 id="虚拟机之间不能ping通"><a href="#虚拟机之间不能ping通" class="headerlink" title="虚拟机之间不能ping通"></a>虚拟机之间不能ping通</h2><ul><li><p>问题描述：</p><ul><li>虚拟机可以ping通主机</li><li>主机可以ping通虚拟机</li><li>虚拟机之间不能互相ping通</li><li>虚拟机查看<code>arp -n</code>可以看到另一台虚拟机的IP地址</li><li>虚拟机之间可以通过<code>arping</code>连接</li></ul></li><li><p>解决方案</p><ul><li>这种情况下大概率是主机的防火墙问题，查看了一下<code>iptables</code>，发现里头的INPUT以及OUTPUT都是ACCEPT的，但是FORWARD选项是DROP的，这样表示，输入输出都没问题，但是禁止转发，通过下列命令进行修正</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo iptables -P FORWARD ACCEPT<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>南大</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Shell</tag>
      
      <tag>Linux</tag>
      
      <tag>Qemu</tag>
      
      <tag>DHCP</tag>
      
      <tag>TFTP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes 学习笔记</title>
    <link href="/2023/10/29/kubernetes/"/>
    <url>/2023/10/29/kubernetes/</url>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes-概述"><a href="#Kubernetes-概述" class="headerlink" title="Kubernetes 概述"></a>Kubernetes 概述</h1><ul><li>k8s 官网：<a href="https://kubernetes.io/">https://kubernetes.io/</a></li></ul><p>Kubernetes 又被叫做 k8s，是一个用于自动化部署、自动扩容以及容器化应用管理的开源系统</p><h1 id="kubernetes-搭建"><a href="#kubernetes-搭建" class="headerlink" title="kubernetes 搭建"></a><code>kubernetes</code> 搭建</h1><h2 id="准备工具"><a href="#准备工具" class="headerlink" title="准备工具"></a>准备工具</h2><p>使用阿里云的镜像构建 k8s</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https<br>curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add -<br></code></pre></td></tr></table></figure><p><img src="/../assets/kubernetes/OQ4Ib3kX8oPLdMxC3MZcdZmmnNf.png"></p><p>之后将阿里云的镜像地址写到 <code>sources.list</code> 当中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo vim /etc/apt/sources.list.d/kubernetes.list<br><br><span class="hljs-comment"># 写入下列内容</span><br>deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main<br></code></pre></td></tr></table></figure><p>退出后更新软件包，下载 k8s</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get update<br>sudo apt-get install -y kubelet kubeadm kubectl<br></code></pre></td></tr></table></figure><p>如果需要安装特定版本的k8s，则</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get install -y kubelet=1.27.0-00 kubeadm=1.27.0-00 kubectl=1.27.0-00<br></code></pre></td></tr></table></figure><h2 id="集群启动"><a href="#集群启动" class="headerlink" title="集群启动"></a>集群启动</h2><p>搭建后可以通过</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo kubeadm init<br></code></pre></td></tr></table></figure><p>启动容器可能会遇到诸多问题，见<a href="#kubeadm-init">问题<code>kubeadm init</code></a></p><p>容器启动成功后，运行命令提示的三条命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">mkdir</span> -p .kube/config<br>sudo <span class="hljs-built_in">cp</span> -i /etc/kubernetes/admin.conf .kube/config<br>sudo <span class="hljs-built_in">chown</span> $(<span class="hljs-built_in">id</span> -u):$(<span class="hljs-built_in">id</span> -g) .kube/config<br></code></pre></td></tr></table></figure><h2 id="网络插件"><a href="#网络插件" class="headerlink" title="网络插件"></a>网络插件</h2><p>启动容器后可以通过<code>kubectl get pods -n kube-system</code>观察到几个<code>pods</code>能够顺利运行，除了两个<code>core-dns</code>一直在<code>pending</code>，所以这个时候需要安装网络插件，以下选择<code>calico</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://calico-v3-25.netlify.app/archive/v3.25/manifests/calico.yaml<br></code></pre></td></tr></table></figure><p>下载后</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f calico.yaml<br></code></pre></td></tr></table></figure><h2 id="运行时配置"><a href="#运行时配置" class="headerlink" title="运行时配置"></a>运行时配置</h2><p>然后等一会儿，可以通过<code>kubectl get pods -n kube-system</code>看到<code>pods</code>的相关信息。等到插件成功变为<code>running</code>之后，通过</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl get nodes<br></code></pre></td></tr></table></figure><p>可以看到控制节点应为<code>ready</code>状态，如果没有，多半是<code>containerd</code>的配置问题</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo vim /etc/cni/net.d/10-containerd-net.conflist<br><br><span class="hljs-comment"># 写入以下内容</span><br>&#123;<br> <span class="hljs-string">&quot;cniVersion&quot;</span>: <span class="hljs-string">&quot;1.0.0&quot;</span>,<br> <span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;containerd-net&quot;</span>,<br> <span class="hljs-string">&quot;plugins&quot;</span>: [<br>   &#123;<br>     <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;bridge&quot;</span>,<br>     <span class="hljs-string">&quot;bridge&quot;</span>: <span class="hljs-string">&quot;cni0&quot;</span>,<br>     <span class="hljs-string">&quot;isGateway&quot;</span>: <span class="hljs-literal">true</span>,<br>     <span class="hljs-string">&quot;ipMasq&quot;</span>: <span class="hljs-literal">true</span>,<br>     <span class="hljs-string">&quot;promiscMode&quot;</span>: <span class="hljs-literal">true</span>,<br>     <span class="hljs-string">&quot;ipam&quot;</span>: &#123;<br>       <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;host-local&quot;</span>,<br>       <span class="hljs-string">&quot;ranges&quot;</span>: [<br>         [&#123;<br>           <span class="hljs-string">&quot;subnet&quot;</span>: <span class="hljs-string">&quot;10.88.0.0/16&quot;</span><br>         &#125;],<br>         [&#123;<br>           <span class="hljs-string">&quot;subnet&quot;</span>: <span class="hljs-string">&quot;2001:db8:4860::/64&quot;</span><br>         &#125;]<br>       ],<br>       <span class="hljs-string">&quot;routes&quot;</span>: [<br>         &#123; <span class="hljs-string">&quot;dst&quot;</span>: <span class="hljs-string">&quot;0.0.0.0/0&quot;</span> &#125;,<br>         &#123; <span class="hljs-string">&quot;dst&quot;</span>: <span class="hljs-string">&quot;::/0&quot;</span> &#125;<br>       ]<br>     &#125;<br>   &#125;,<br>   &#123;<br>     <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;portmap&quot;</span>,<br>     <span class="hljs-string">&quot;capabilities&quot;</span>: &#123;<span class="hljs-string">&quot;portMappings&quot;</span>: <span class="hljs-literal">true</span>&#125;,<br>     <span class="hljs-string">&quot;externalSetMarkChain&quot;</span>: <span class="hljs-string">&quot;KUBE-MARK-MASQ&quot;</span><br>   &#125;<br> ]<br>&#125;<br></code></pre></td></tr></table></figure><p>然后重启一下<code>containerd</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo systemctl restart containerd<br></code></pre></td></tr></table></figure><h2 id="排除污点"><a href="#排除污点" class="headerlink" title="排除污点"></a>排除污点</h2><p>获取配置中的污点信息并把污点排除掉</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl get nodes -o yaml | code -<br>kubectl taint nodes &lt;node_name&gt; &lt;taint_name&gt;-<br></code></pre></td></tr></table></figure><h1 id="Kind"><a href="#Kind" class="headerlink" title="Kind"></a>Kind</h1><h2 id="在集群中加载镜像"><a href="#在集群中加载镜像" class="headerlink" title="在集群中加载镜像"></a>在集群中加载镜像</h2><p>在一个已经运行的集群中加载一个 <code>docker-image</code>，<code>dockerfile</code> 如下</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> ubuntu:latest<br><br><span class="hljs-keyword">COPY</span><span class="language-bash"> <span class="hljs-variable">$&#123;pwd&#125;</span>/code /code</span><br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apt update &amp;&amp; apt install -y python3-pip &amp;&amp; apt-get clean</span><br><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install flask</span><br><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [ <span class="hljs-string">&quot;sh&quot;</span>, <span class="hljs-string">&quot;-c&quot;</span>, <span class="hljs-string">&quot;python3 /code/app.py&quot;</span>]</span><br></code></pre></td></tr></table></figure><p><code>code</code> 里头运行了一个简单的 <code>flask</code> 应用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><br>app = Flask(__name__)<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/&quot;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hello_world</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&lt;p&gt;Hello World!&lt;/p&gt;&quot;</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    app.run(host=<span class="hljs-string">&quot;0.0.0.0&quot;</span>,port=<span class="hljs-number">8080</span>,debug=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>加载到集群中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kind load docker-image flask-image:latest<br></code></pre></td></tr></table></figure><p><img src="/../assets/kubernetes/O2hIbVjzkoI2bfxS3QVcdavHnAf.png"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">docker exec -it kind-control-plane crictl images<br></code></pre></td></tr></table></figure><p><img src="/../assets/kubernetes/TxjHbHJVsoPjNXxnIoLc8IuFnwc.png"></p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><h2 id="kubeadm-init"><a href="#kubeadm-init" class="headerlink" title="kubeadm init"></a><code>kubeadm init</code></h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">[WARNING Hostname]: hostname <span class="hljs-string">&quot;dydy-pc&quot;</span> could not be reached<br>[WARNING Hostname]: hostname <span class="hljs-string">&quot;dydy-pc&quot;</span>: lookup dydy-pc on 210.28.129.251:53: no such host<br></code></pre></td></tr></table></figure><p>修改 <code>/etc/hosts</code>，将 <code>localhost</code> 后面添加自己的电脑主机地址即可</p><hr><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">[ERROR CRI]: container runtime is not running: output: time=<span class="hljs-string">&quot;2023-09-19T09:03:23+08:00&quot;</span> level=fatal msg=<span class="hljs-string">&quot;validace connection: CRI v1 runtime API is not implemented for endpoint \&quot;unix:///var/run/containerd/containerd.sock\&quot;: rpc error: code = Unimplemented desc = unknown service runtime.v1.RuntimeService&quot;</span><br></code></pre></td></tr></table></figure><p><a href="https://yxrt3ryg3jg.feishu.cn/docx/Xru9d9V7MoSk5kxsFJXcqtUjn2c#part-RfVPd1aHPoNdExx7ppqcVT9Gn6f">Kubernetes 环境搭建</a></p><hr><ul><li><p>问：启动后<code>kubectl</code>任何命令提示连不上<code>kube-apiserver</code></p></li><li><p>答：代理问题。启动后可以<code>unset http_proxy https_proxy</code>或者将<code>kube-apiserver</code>的IP地址添加到<code>no_proxy</code>里头</p></li></ul><hr><h2 id="kubeadm-config-images-pull"><a href="#kubeadm-config-images-pull" class="headerlink" title="kubeadm config images pull"></a><code>kubeadm config images pull</code></h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">failed to pull image <span class="hljs-string">&quot;registry.k8s.io/kube-apiserver:v1.28.2&quot;</span>: output: E0919 09:32:01.239971   35982 remote_image.go:171] <span class="hljs-string">&quot;PullImage from image service failed&quot;</span> err=<span class="hljs-string">&quot;rpc error: code = Unavailable desc = connection error: desc = \&quot;transport: Error while dialing dial unix /var/run/containerd/containerd.sock: connect: permission denied\&quot;&quot;</span> image=<span class="hljs-string">&quot;registry.k8s.io/kube-apiserver:v1.28.2&quot;</span><br>time=<span class="hljs-string">&quot;2023-09-19T09:32:01+08:00&quot;</span> level=fatal msg=<span class="hljs-string">&quot;pulling image: rpc error: code = Unavailable desc = connection error: desc = \&quot;transport: Error while dialing dial unix /var/run/containerd/containerd.sock: connect: permission denied\&quot;&quot;</span><br>, error: <span class="hljs-built_in">exit</span> status 1<br></code></pre></td></tr></table></figure><p>生成默认配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubeadm config <span class="hljs-built_in">print</span> init-defaults &gt; init.default.yaml<br></code></pre></td></tr></table></figure><p>修改默认配置文件</p>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>OpenWhisk 学习笔记</title>
    <link href="/2023/10/29/openwhisk/"/>
    <url>/2023/10/29/openwhisk/</url>
    
    <content type="html"><![CDATA[<h1 id="OpenWhisk概述"><a href="#OpenWhisk概述" class="headerlink" title="OpenWhisk概述"></a>OpenWhisk概述</h1><p>Openwhisk是属于Apache基金会的开源Faas计算平台，由IBM在2016年公布并贡献给开源社区。IBM Cloud本身也提供完全托管的OpenWhisk Faas服务IBM Cloud Function。从业务逻辑来看，OpenWhisk同AWS Lambda一样，为用户提供基于事件驱动的无状态的计算模型，并直接支持多种编程语言。</p><p>OpenWhisk特点：</p><ul><li>高性能，高扩展性的分布式FaaS计算平台</li><li>函数的代码及运行时全部在Docker容器中运行，利用Docker engine实现FaaS函数运行的管理、负载均衡、扩展.</li><li>OpenWhisk所有其他组件(如：API网关，控制器，触发器等)也全部运行在 Docker容器中。这使得OpenWhisk全栈可以很容易的部署在任意IaaS&#x2F;PaaS平台上。</li><li>相比其他FaaS实现(比如OpenFaaS)，OpenWhisk更像是一套完整的Serverless 解决方案，除了容器的调用和函数的管理，OpenWhisk 还包括了用户身份验证&#x2F;鉴权、函数异步触发等功能。</li></ul><p>目前支持的语言: <code>Nodejs</code>, <code>Python</code>, <code>Java</code>, <code>php</code>, <code>Ruby</code>, <code>Go</code>, <code>Rust</code>, <code>dotnet</code>, <code>Ballerina</code>, <code>blackBoxes</code>。</p><h1 id="OpenWhisk环境搭建"><a href="#OpenWhisk环境搭建" class="headerlink" title="OpenWhisk环境搭建"></a>OpenWhisk环境搭建</h1><h2 id="安装Java"><a href="#安装Java" class="headerlink" title="安装Java"></a>安装Java</h2><p>deepin上安装Java的方式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get install default-jre<br>sudo apt-get install default-jdk<br>安装nodejs<br><span class="hljs-comment">#下载Node.js安装包</span><br>wget https://nodejs.org/dist/v10.15.3/node-v10.15.3-linux-x64.tar.xz<br><span class="hljs-comment">#解压文件</span><br>tar xvf node-v10.15.3-linux-x64.tar.xz<br><span class="hljs-comment">#移动到相应目录下</span><br><span class="hljs-built_in">mv</span> ./node-v10.15.3-linux-x64 ./node<br><span class="hljs-built_in">mv</span> ./node /opt/node<br><span class="hljs-comment">#添加环境变量</span><br><span class="hljs-built_in">cd</span> <br>vim .bash_profile<br><span class="hljs-comment">#node</span><br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:/opt/node/bin<br></code></pre></td></tr></table></figure><h2 id="编译openwhisk"><a href="#编译openwhisk" class="headerlink" title="编译openwhisk"></a>编译openwhisk</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># git clone下来</span><br>git <span class="hljs-built_in">clone</span> https://github.com/apache/incubator-openwhisk.git openwhisk<br><span class="hljs-comment"># 切换到openwhisk目录，运行下面命令</span><br>$ ./gradlew :core:standalone:build<br></code></pre></td></tr></table></figure><p><img src="/../assets/openwhisk/o1.PNG"><br><img src="/../assets/openwhisk/o2.PNG"></p><h2 id="配置OpenWhisk-Cli工具"><a href="#配置OpenWhisk-Cli工具" class="headerlink" title="配置OpenWhisk Cli工具"></a>配置OpenWhisk Cli工具</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">- github下载网址：https://link.zhihu.com/?target=https%3A//github.com/apache/openwhisk-cli 下载二进制文件<br><span class="hljs-comment"># 上传到服务器解压, 解压</span><br><span class="hljs-comment"># 设置API HOST</span><br>wsk property <span class="hljs-built_in">set</span> --apihost http://172.17.0.1:3233<br><span class="hljs-comment"># 设置auth</span><br>wsk property <span class="hljs-built_in">set</span> --auth 789c46b1-71f6-4ed5-8c54-816aa4f8c502<br><span class="hljs-comment"># 可以通过以下命令获取当前的auth</span><br>wsk property get --auth<br></code></pre></td></tr></table></figure><p><img src="/../assets/openwhisk/o3.png"></p><h2 id="配置Docker"><a href="#配置Docker" class="headerlink" title="配置Docker"></a>配置Docker</h2><p><a href="https://cloud.tencent.com/developer/article/1753250">https://cloud.tencent.com/developer/article/1753250</a></p><ol><li>卸载旧版本残留</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get remove docker.io docker-engine<br></code></pre></td></tr></table></figure><ol start="2"><li>下载并安装密钥</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/debian/gpg | sudo apt-key add -<br></code></pre></td></tr></table></figure><ol start="3"><li>检查是否安装成功</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-key fingerprint 0EBFCD88<br></code></pre></td></tr></table></figure><p><img src="/../assets/openwhisk/o4.png"></p><ol start="4"><li>在source.list中添加docker-ce的软件源</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo deepin-editor /etc/apt/sources.list.d/docker.list <span class="hljs-comment"># 使用 deepin 默认的编辑器新建并打开 docker.list 文件</span><br><span class="hljs-comment"># 写入一条内容如下：</span><br>deb [<span class="hljs-built_in">arch</span>=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/debian buster stable <span class="hljs-comment"># 这里 buster 是 debain 版本的代号，deepin20 是debain10 代号为 buster，编辑完成后保存</span><br>注意： 使用 <span class="hljs-built_in">cat</span> /etc/debian_version 查看自己的 debain 版本。<br></code></pre></td></tr></table></figure><ol start="5"><li>更新仓库</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt update<br></code></pre></td></tr></table></figure><ol start="6"><li>安装docker</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt install docker-ce docker-ce-cli containerd.io<br></code></pre></td></tr></table></figure><ol start="7"><li>验证</li></ol><p><img src="/../assets/openwhisk/o5.png"><br><img src="/../assets/openwhisk/o6.png"></p><ol><li>管理启动项</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt install chkconfig <br><span class="hljs-comment"># 列出所有启动项</span><br>sudo chkconfig<br><span class="hljs-comment"># chkconfig --help 查看帮助命令</span><br><br>sudo chkconfig --del docker<br></code></pre></td></tr></table></figure><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>在openwhisk的bin目录下会有相应的可执行文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">java -jar openwhisk-standalone.jar<br></code></pre></td></tr></table></figure><p>如果docker需要管理员权限就加个sudo</p><p><img src="/../assets/openwhisk/o7.png"></p><p>服务起来后设置提示的命令:设置apihost和auth</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wsk property <span class="hljs-built_in">set</span> --apihost <span class="hljs-string">&#x27;http://172.17.0.1:3233&#x27;</span> --auth <span class="hljs-string">&#x27;23bc46b1-71f6-4ed5-8c54-816aa4f8c502:123zO3xZCLrMN6v2BKK1dXYFpXlPkccOFqm12CdAsMgRU4VrNZ9lyGVCGuMDGIwP&#x27;</span><br></code></pre></td></tr></table></figure><p><img src="/../assets/openwhisk/o8.png"><br><img src="/../assets/openwhisk/o9.png"></p><h1 id="OpenWhisk包下载"><a href="#OpenWhisk包下载" class="headerlink" title="OpenWhisk包下载"></a>OpenWhisk包下载</h1><h2 id="Catalog包"><a href="#Catalog包" class="headerlink" title="Catalog包"></a>Catalog包</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/apache/openwhisk-catalog<br><span class="hljs-built_in">cd</span> openwhisk-catalog<br><span class="hljs-comment">#将一些变量添加进来</span><br>vim ~/.bashrc<br><br><span class="hljs-comment">#openwhisk</span><br>OPENWHISK_HOME=~/Serverless/openwhisk<br>WSK=<span class="hljs-variable">$OPENWHISK_HOME</span>/bin<br>CLI_PATH=<span class="hljs-variable">$OPENWHISK_HOME</span>/bin/wsk<br>API_HOST=http://172.17.0.1:3233<br>AUTH=789c46b1-71f6-4ed5-8c54-816aa4f8c502:abczO3xZCLrMN6v2BKK1dXYFpXlPkccOFqm12CdAsMgRU4VrNZ9lyGVCGuMDGIwP<br><span class="hljs-built_in">export</span> OPENWHISK_HOME CLI_PATH API_HOST API_KEY<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$WSK</span><br><br><br><span class="hljs-comment">#在本地standalone运行时下载包</span><br>./packages/installCatalogUsingWskdeploy.sh <span class="hljs-variable">$AUTH</span> <span class="hljs-variable">$API_HOST</span> <span class="hljs-variable">$CLI_PATH</span><br><span class="hljs-comment">#然后验证</span><br>wsk package list /whisk.system<br></code></pre></td></tr></table></figure><p><img src="/../assets/openwhisk/o10.png"></p><h1 id="OpenWhisk-couchDB数据库配置"><a href="#OpenWhisk-couchDB数据库配置" class="headerlink" title="OpenWhisk couchDB数据库配置"></a>OpenWhisk couchDB数据库配置</h1><ol><li>依次执行以下3条命令</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt update &amp;&amp; sudo apt install -y curl apt-transport-https gnupg<br>curl https://couchdb.apache.org/repo/keys.asc | gpg --dearmor | sudo <span class="hljs-built_in">tee</span> /usr/share/keyrings/couchdb-archive-keyring.gpg &gt;/dev/null 2&gt;&amp;1source /etc/os-release<br><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;deb [signed-by=/usr/share/keyrings/couchdb-archive-keyring.gpg] https://apache.jfrog.io/artifactory/couchdb-deb/ <span class="hljs-variable">$&#123;VERSION_CODENAME&#125;</span> main&quot;</span> \| sudo <span class="hljs-built_in">tee</span> /etc/apt/sources.list.d/couchdb.list &gt;/dev/null<br></code></pre></td></tr></table></figure><ol start="2"><li>执行后你可以在<code>/etc/apt/source.list.d</code>里头看到<code>couchdb.list</code>文件，用<code>vim</code>打开，将里头的<code>apricot</code>改为<code>buster</code>，因为原来那个在网站上的资源没有了T_T</li><li>之后更新源后下载couchdb</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt update<br>sudo apt install couchdb<br></code></pre></td></tr></table></figure><ol start="4"><li>新建一个文件夹后在里头导出一些环境变量</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> logconf &amp;&amp; <span class="hljs-built_in">cd</span> logconf<br>vim wsk_env.sh<br><span class="hljs-built_in">export</span> OW_DB=CouchDB<br><span class="hljs-built_in">export</span> OW_DB_USERNAME=openwhisk<br><span class="hljs-built_in">export</span> OW_DB_PASSWORD=openwhisk<br><span class="hljs-built_in">export</span> OW_DB_PROTOCOL=http<br><span class="hljs-built_in">export</span> OW_DB_HOST=127.0.0.1<br><span class="hljs-built_in">export</span> OW_DB_PORT=4444<br><span class="hljs-built_in">export</span> OPENWHISK_TMP_DIR=~/Serverles/logconf<br></code></pre></td></tr></table></figure><ol start="5"><li>之后进行ansible安装</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">source</span> openwsk_env.sh<br><span class="hljs-built_in">cd</span> ansible<br>ansible-playbook -i environments/local setup.yml<br></code></pre></td></tr></table></figure><p><img src="/../assets/openwhisk/o11.png"></p><p><img src="/../assets/openwhisk/o12.png"></p><h1 id="OpenWhisk内部流程"><a href="#OpenWhisk内部流程" class="headerlink" title="OpenWhisk内部流程"></a>OpenWhisk内部流程</h1><p><img src="/../assets/openwhisk/o13.png"></p><ol><li>面向用户的REST API(Nginx)：OpenWhisk通过Nginx 接收函数触发和函数的CRUD请求。</li><li>控制器(Controller): 真正处理请求的地方。</li><li>CouchDB(身份验证和鉴权):控制器首先需要验证用户的身份和权限。用户的身份信息保存在CouchDB的用户身份数据库中。验证无误后，控制器进行下一步处理。</li><li>CouchDB: 确认用户的身份后，控制器需要从 CouchDB中读取将要被触发的action。action对应的数据存储在CouchDB的whisk 数据库，主要包含要被执行的代码、默认参数、被执行代码的权限等。</li><li>Consul和负载均衡:控制器已经有了触发函数所需要的全部信息，在将数据发送给触发器(Invoker)之前，控制器需要和Consul确认，从Consul 获取处于空闲状态的触发器的地址。Consul 是一个开源的服务注册&#x2F;发现系统，在 OpenWhisk中Consul负责记录跟踪所有触发器的状态信息。当控制器向Consul发出请求，Consul从后台随机选取一个空闲的触发器信息，并返回。</li><li>触发请求送进Kafka: Kafka 充当了Controller和Invoker之间的缓存，当后端 Invoker 负载过大，没有及时处理Kafka数据流中的请求时，Controller 依然可以将请求送入Kafka，无需阻塞当前线程。同时所有送进Kafka 的请求消息都会被以log的形式的形式保存在文件系统中，即使系统瘫痪，已经由 Controller发出的请求也不会丢失。</li><li>触发器运行用户代码: 触发器从对应的 Kafka topic 中接收控制器传来的请求，并执行响应代码。OpenWhisk 的触发器是构建在 Docker 之上的，每一个函数触发都运行在一个独立的 Docker 容器之内.</li><li>CouchDB 保存运行结果: 触发器执行结果最终会被保存在 CouchDB 中的 whisk 数据库里</li></ol><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p><a href="https://blog.csdn.net/weixin_51971301/article/details/121436849">openwhisk配置流程</a><br><a href="https://mlog.club/article/5772204">bbs-go-site</a><br><a href="https://docs.couchdb.org/en/latest/install/unix.html#installation-using-the-apache-couchdb-convenience-binary-packages">1.1. Installation on Unix-like systems ‒ Apache CouchDB® 3.2 Documentation</a></p>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OpenWhisk</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker 笔记</title>
    <link href="/2023/10/28/docker/"/>
    <url>/2023/10/28/docker/</url>
    
    <content type="html"><![CDATA[<h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><h2 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a>环境安装</h2><p>卸载旧版本残留</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-get remove docker.io docker-engine<br></code></pre></td></tr></table></figure><ol><li>下载并安装密钥</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -fsSL https://mirrors.ustc.edu.cn/docker-ce/linux/debian/gpg | sudo apt-key add -<br></code></pre></td></tr></table></figure><ol start="2"><li>检查是否安装成功</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt-key fingerprint 0EBFCD88<br></code></pre></td></tr></table></figure><p><img src="/../assets/docker/docker1.PNG"></p><ol start="3"><li>在source.list中添加docker-ce的软件源</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo deepin-editor /etc/apt/sources.list.d/docker.list <span class="hljs-comment"># 使用 deepin 默认的编辑器新建并打开 docker.list 文件</span><br><span class="hljs-comment"># 写入一条内容如下：</span><br>deb [<span class="hljs-built_in">arch</span>=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/debian buster stable <span class="hljs-comment"># 这里 buster 是 debain 版本的代号，deepin20 是debain10 代号为 buster，编辑完成后保存</span><br></code></pre></td></tr></table></figure><p>注意： 使用 cat &#x2F;etc&#x2F;debian_version 查看自己的 debain 版本。</p><ol start="4"><li>更新仓库</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt update<br></code></pre></td></tr></table></figure><ol start="5"><li>安装docker</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt install docker-ce docker-ce-cli containerd.io<br></code></pre></td></tr></table></figure><ol start="6"><li><p>验证<br><img src="/../assets/docker/docker2.PNG"></p></li><li><p>管理启动项</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo apt install chkconfig <br><span class="hljs-comment"># 列出所有启动项</span><br>sudo chkconfig<br><span class="hljs-comment"># chkconfig --help 查看帮助命令</span><br><br>sudo chkconfig --del docker<br></code></pre></td></tr></table></figure><ol start="8"><li>Rootless 配置</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo usermod -aG docker <span class="hljs-variable">$USER</span><br>reboot<br></code></pre></td></tr></table></figure><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="拷贝文件夹"><a href="#拷贝文件夹" class="headerlink" title="拷贝文件夹"></a>拷贝文件夹</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker <span class="hljs-built_in">cp</span> &lt;container&gt;:&lt;container-dir&gt; &lt;local-dir&gt;<br></code></pre></td></tr></table></figure><h1 id="Docker-Compose"><a href="#Docker-Compose" class="headerlink" title="Docker Compose"></a>Docker Compose</h1><h2 id="环境安装-1"><a href="#环境安装-1" class="headerlink" title="环境安装"></a>环境安装</h2><ol><li>下载二进制包</li></ol><p><a href="https://github.com/docker/compose/releases">https://github.com/docker/compose/releases</a></p><ol start="2"><li>添加权限并移动到&#x2F;usr&#x2F;local&#x2F;bin下</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">chmod</span> 755 docker-compose-linux-x86_64<br>sudo <span class="hljs-built_in">mv</span> docker-compose-linux-x86_64 /usr/local/bin/docker-compose<br></code></pre></td></tr></table></figure><ol start="3"><li>验证</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker-compose<br></code></pre></td></tr></table></figure><p><img src="/../assets/docker/docker3.png"></p><h2 id="简单示例"><a href="#简单示例" class="headerlink" title="简单示例"></a>简单示例</h2><h3 id="1-定义应用依赖"><a href="#1-定义应用依赖" class="headerlink" title="1. 定义应用依赖"></a>1. 定义应用依赖</h3><p>使用一个简单的程序</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">import</span> redis<br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><br>app = Flask(__name__)<br>cache = redis.Redis(host=<span class="hljs-string">&#x27;redis&#x27;</span>, port=<span class="hljs-number">6379</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_hit_count</span>():<br>    retries = <span class="hljs-number">5</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-keyword">return</span> cache.incr(<span class="hljs-string">&#x27;hits&#x27;</span>)<br>        <span class="hljs-keyword">except</span> redis.exceptions.ConnectionError <span class="hljs-keyword">as</span> exc:<br>            <span class="hljs-keyword">if</span> retries == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">raise</span> exc<br>            retries -= <span class="hljs-number">1</span><br>            time.sleep(<span class="hljs-number">0.5</span>)<br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&#x27;/&#x27;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>():<br>    count = get_hit_count()<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;Hello World! I have been seen &#123;&#125; times.\n&#x27;</span>.<span class="hljs-built_in">format</span>(count)<br></code></pre></td></tr></table></figure><p>并提供其软件包<code>requirements.txt</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">flask<br>redis<br></code></pre></td></tr></table></figure><h3 id="2-定义一个Dockerfile"><a href="#2-定义一个Dockerfile" class="headerlink" title="2. 定义一个Dockerfile"></a>2. 定义一个Dockerfile</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-comment"># syntax=docker/dockerfile:1</span><br><span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.7</span>-alpine<br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /code</span><br><span class="hljs-keyword">ENV</span> FLASK_APP=app.py<br><span class="hljs-keyword">ENV</span> FLASK_RUN_HOST=<span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apk add --no-cache gcc musl-dev linux-headers</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> requirements.txt requirements.txt</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> pip install -r requirements.txt</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">5000</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> . .</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;flask&quot;</span>, <span class="hljs-string">&quot;run&quot;</span>]</span><br></code></pre></td></tr></table></figure><h3 id="3-定义一个compose文件"><a href="#3-定义一个compose文件" class="headerlink" title="3. 定义一个compose文件"></a>3. 定义一个compose文件</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">services:<br>  web:<br>    build: .<br>    ports:<br>      - <span class="hljs-string">&quot;8000:5000&quot;</span><br>  redis:<br>    image: <span class="hljs-string">&quot;redis:alpine&quot;</span><br></code></pre></td></tr></table></figure><h3 id="4-构建运行"><a href="#4-构建运行" class="headerlink" title="4. 构建运行"></a>4. 构建运行</h3><p>运行<code>docker compose up</code></p><p><img src="/../assets/docker/docker4.png"><br><img src="/../assets/docker/docker5.png"><br>停止运行<code>docker compose down</code></p><h3 id="5-compose文件添加挂载"><a href="#5-compose文件添加挂载" class="headerlink" title="5. compose文件添加挂载"></a>5. compose文件添加挂载</h3><p>重新编辑一下compose文件</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">services:<br>  web:<br>    build: .<br>    ports:<br>      - <span class="hljs-string">&quot;8000:5000&quot;</span><br>    volumes:<br>      - .:/code<br>    environment:<br>      FLASK_DEBUG: <span class="hljs-string">&quot;true&quot;</span><br>  redis:<br>    image: <span class="hljs-string">&quot;redis:alpine&quot;</span><br></code></pre></td></tr></table></figure><h3 id="6-重新构建"><a href="#6-重新构建" class="headerlink" title="6. 重新构建"></a>6. 重新构建</h3><p><img src="/../assets/docker/docker6.png"></p><h3 id="7-应用更新"><a href="#7-应用更新" class="headerlink" title="7. 应用更新"></a>7. 应用更新</h3><p>由于在上面的步骤中，我们将应用程序的代码与容器进行挂载，因此，当我们现在对源代码进行修改时，容器里头的代码也会跟着修改</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;Hello from Docker! I have been seen &#123;&#125; times.\n&#x27;</span>.<span class="hljs-built_in">format</span>(count)<br></code></pre></td></tr></table></figure><p><img src="/../assets/docker/docker7.png"></p>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
