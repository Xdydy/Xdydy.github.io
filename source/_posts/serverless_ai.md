---
title: Serverless 智能化应用
# date: 2023-11-01 09:00:00
excerpt: 记录Serverless函数智能化的相关论文阅读研究
author: dydy
tags:
- Serverless
- AI

categories:
- 科研
---

# Serverless 智能化应用

# 研究问题

- 底层系统资源的配置（GPU，内存大小配置等）智能适应 or 人工设定
- 有状态函数的快速存储机制
- 容错

  - 执行顺序：多个无状态函数可能会乱序执行，导致结果也是乱序
  - 执行状态：有状态函数的执行可能会断掉，需要能够恢复

# 参考文献

## [Cirrus: a Serverless Framework for End-to-end ML Workflow](https://dl.acm.org/doi/abs/10.1145/3357223.3362711)

代码仓库：[https://github.com/ucbrise/cirrus](https://github.com/ucbrise/cirrus)

### 解决问题

- 解决 ML 过程资源配置和管理的问题

  - 传统的 `workflow` 拥有多个阶段，每一个阶段的计算都是异构的
  - 计算的异构使得机器学习用户很难正确配置和管理资源，并且在实践中，这会构成重大负担，经常导致过度配置并损害用户生产力。
- Serverless 可以很好的管理资源

  - 但是很难适应 Serverless
- `Cirrus` 通过 Serverless 的框架对 ML 做资源的适配管理

  - 轻量级的工作运行时，为 ML 人员找到最适合的资源配置
  - 节省了配置大量内存或存储的成本
    - (a) 来自远程存储的流式训练小批量数据；
    - (b) 重新设计分布式训练算法以在无服务器环境中稳健运行
  - 采用无状态的 worker 架构，使系统能够有效地处理频繁的 worker 离开和到达作为预期行为。

### 问题描述

- ML Workflow 带来两个问题

  - 过度配置：如果使用虚拟机做资源的配置，配置的复杂性就会导致过度配置
  - 资源管理：管理的复杂性降低了交互式和迭代用例
- Serverless 本身的挑战

  - 内存以及存储过小：利用无服务器计算的主要挑战是与 lambda 函数相关的本地资源限制（内存、CPU、存储、网络）非常小
  - 低带宽以及缺少 P2P 通信：最新的 Lambda 也只有 60MB 的带宽；缺少通信策略，用于数据中心机器学习的常见通信策略，例如树形结构或环形结构的 AllReduce 通信，在此类环境中受到限制
  - 启动时间短暂并且不可预测：Lambda 函数的生命周期很短，并且其启动时间变化很大。这意味着在训练期间，lambda 会在不可预测的时间开始，并可能在训练中间结束。这需要 lambda 的 ML 运行时能够容忍工作人员的频繁离开和到达。
  - 缺少快速共享存储的功能：由于 lambda 函数彼此不能直接通信，因此需要快速的共享存储。但是 ML 训练对数据的性能要求非常高，不能有太大的延时

### 系统设计

#### 系统架构图

![](../assets/serverless_ai/T6RKbWlZ9o53x3xfiy6chhkXn7g.png)

#### 模块

- Python 前端：提供了一个底层抽象系统资源的高级接口

  - 预处理模块：该子模块允许不同类型的数据集转换：最小-最大缩放、标准化和特征哈希。
  - 训练模块：可以使用随机梯度下降来训练的 ML 模型。
  - 超参数优化：允许用户对给定的参数集运行网格搜索。
- 客户端后端：解析训练数据并将其加载到 S3，在 lambda 上启动 Cirrus 工作程序，管理分布式数据存储，跟踪计算进度，并在计算完成后将结果返回到 Python 前端。
- 工作运行时：Cirrus 提供了一个运行时，它封装了系统支持的不同计算之间共享的所有函数
- 分布式数据存储：

  - 低延迟：将数据存储部署在云虚拟机中
  - 可扩展：Cirrus 包括以下机制：(1) 分片存储、(2) 高度多线程、(3) 数据压缩、(4) 梯度过滤器和 (5) 异步通信。
  - 强接口

#### 端到端的 ML 阶段

- 数据加载与预处理

  - 假设数据已经被全局存储（例如 S3）Cirrus 将其转为二进制数据
  - 使用 Map-Reduce 模式。
- 模型训练

  - 分布式 SGD 算法
  - 每个 `worker` 运行 Lambda 函数并负责迭代计算梯度步骤。每个梯度计算都需要两个输入：一个小批量和最新的模型
  - 对于每次迭代，每个工作人员都会计算一个新的梯度。然后将该梯度异步发送到数据存储 (send_gradient_X ) 以更新模型。
- 超参数优化

  - 典型的做法是在多维参数空间上执行网格搜索。通常让网格搜索完全运行完成并对结果进行后处理以找到最佳配置（过度配置）
  - 随着时间的推移，Cirrus 通过提供超参数搜索仪表板来消除这种过度配置的情况
  - 因此，Cirrus 提供 (a) 用于启动超参数搜索的 API 和执行后端，(b) 用于监控模型精度收敛的仪表板，(c) 终止单独调整实验并节省超额配置成本的能力。

### 实现方式

#### Python 前端

- 抽象了有关开发者的细节
- 通过 API 参数覆盖内部配置参数

#### Client 后端

- 将前端的算法部署到 Lambda 上并抽象了管理

  - 内部保存了与 Lambda 函数的连接列表
- 使用线程池响应请求

  - Lambda API 的特殊性

#### 分布式数据存储

- 多线程服务器，将任务分配给多个核心

  - 目的：高效地更新模型
- 对传入/传出存储的梯度和模型实施数据压缩

  - 目的：减少网络带来的瓶颈
- 通过发送和接收稀疏梯度和模型数据结构来优化通信

#### Worker 运行时

![](../assets/serverless_ai/EIpDbh2kooFxcOxq9BMcZ2QUnXV.png)

- ML 计算的通用抽象
- 用于访问训练数据、参数模型和中间结果的数据原语。

## [Ray: A Distributed Framework for Emerging AI Applications](https://www.usenix.org/conference/osdi18/presentation/moritz)

### 解决问题

- 需求：下一代的 AI 需要持续与环境交互，对性能和复杂性有要求

  - 必须支持细粒度计算
  - 支持时间和资源的合理使用的异构性
  - 必须支持动态执行，因为模拟或与环境交互的结果可能会改变未来的计算
- 贡献：Ray，一个通用集群计算框架，支持 RL 应用程序的模拟、训练和服务

  - 该框架统一了新兴 RL 应用程序的训练、模拟和服务必要组件
  - 抽象任务并行以及 Actor 计算
  - 控制状态存储在分片元数据存储中，所有其他系统组件都是无状态的。
  - 自下而上的分布式调度策略

### 问题描述

- 针对需求

  - 细粒度、异构计算
    - 计算时间可能几秒钟到几小时
    - 硬件资源可能也不一样
  - 灵活的计算模型
    - 无状态：无状态计算可以在系统中的任何节点上执行，这使得在需要时可以轻松实现负载平衡和计算到数据的移动
      - 适合细粒度模拟和数据处理
    - 有状态：状态计算非常适合实现参数服务器、对 GPU 支持的数据执行重复计算或运行不公开其状态的第三方模拟器
  - 动态执行
    - 计算完成的顺序并不总是事先知道（例如，模拟完成的顺序），并且计算的结果可以决定未来的计算
- 对要实现的目标

  - 要每秒处理数百万个任务
  - 集成现有的模拟器以及机器学习框架

### 编程与计算模型

#### 编程模型

- `Tasks`：表示在无状态工作线程上执行远程函数

  - 并行：当调用远程函数时，会立即返回表示任务结果的 future
  - 协作：可以使用 ray.get() 检索 Future，并将其作为参数传递给其他远程函数
  - 无状态：对不可变对象进行操作，具有幂等性，具备容错能力
- `Actor`：表示有状态的计算

  - `handle`：可以被传递给其他的 `Actor`，便于远程调用

![](../assets/serverless_ai/IzQgbNQ7joYN7Hxcc5tcVVCEnNg.png)

- 为了处理具有异构持续时间的并发任务，引入了 ray.wait()，它等待前 k 个可用结果，而不是像 ray.get() 那样等待所有结果。
- 为了处理资源异构任务，使开发人员能够指定资源需求，以便 Ray 调度器能够有效地管理资源。
- 为了提高灵活性，启用**嵌套远程函数**，这意味着远程函数可以调用其他远程函数。这对于实现高可扩展性也至关重要，因为它允许多个进程以分布式方式调用远程函数。

#### 计算模型

- 任务图计算：输入满足条件时自动触发

  - 两种节点类型
    - 数据节点
    - 任务节点
  - 两种边
    - 数据边：捕捉数据节点和任务节点之间的依赖关系
      - 若 D 是 T 的输出，那么从 T 到 D 就有一条连边
    - 控制边：捕捉两个有调用关系的任务节点之间的计算依赖关系
      - 若 T1 调用 T2，那么 T1 到 T2 有一条边
- Actor

  - 新增状态边
    - 若 Mj 方法在 Mi 方法之后，那么 Mi 到 Mj 有一条边
    - 所有对一个 Actor 的方法的调用顺序通过状态边连接
- 有状态边帮助我们将参与者嵌入到无状态任务图中，因为它们捕获共享参与者内部状态的连续方法调用之间的隐式数据依赖关系

### 系统架构

- 应用层：实现 API
- 系统层：提供高拓展性以及容错性

#### 应用层

- `Driver`：运行用户程序的进程
- `Worker`：一个调用远程函数或 Task 的无状态进程

  - 由系统层分配任务
  - 当远程函数被声明时，函数被分配到所有的 `Worker`
- `Actor`：有状态进程，在调用时仅执行他所公开的方法

  - `Actor` 必须被显式实例化
  - 通过之前方法的执行结果序列化地执行方法

#### 系统层

![](../assets/serverless_ai/TRtMbePDxoNIBBxigoEcxkubnxh.png)

##### 全局控制存储（GCS）：维护系统的控制状态

- 具有发布-订阅的键值存储

  - 使用分片来实现扩展
  - 使用每个分片链复制来提供容错能力
- 容错能力

  - 需要维护沿袭信息：持久沿袭信息组件与其他组件分离，每个组件独立扩展
- 保持低延迟

  - 最大限度的减少任务调度的开销
  - 任务分配与任务调度分离：对象元数据存储在 GCS 中而不是调度程序中
- 使系统中的每个其他组件都是无状态的

##### 自下而上的分部署调度器：两级分层调度器

- 全局调度器

  - 考虑每个节点的负载和任务的约束来做出调度决策
  - 选择提供最短估计等待时间的节点
  - 通过心跳获取每个节点的队列大小和节点资源可用性，以及来自 GCS 的任务输入的位置及其大小。
  - 如果全局调度程序成为瓶颈，可以通过 GCS 实例化更多共享相同信息的副本
- 每个节点本地调度器

  - 每个节点创建的任务首先通过本地调度器
  - 本地调度器在本地调度程序，直到节点过载
  - 当本地调度器不想管了，就交给全局调度器

![](../assets/serverless_ai/QU23b2xyEogFT1xauHzcpLb8nyc.png)

##### 内存中分布式对象存储

在每个节点上，通过共享内存实现对象存储。这允许在同一节点上运行的任务之间进行零拷贝数据共享。作为数据格式，使用 Apache Arrow

- 对象存储：

  - 如果任务的输入不是本地的，则输入会在执行之前复制到本地对象存储。
  - 此外，任务将其输出写入本地对象存储
- 低延迟

  - 将整个对象保持在内存中，通过 LRU 机制写入磁盘
- 容错

  - 通过沿袭重新执行来恢复任何所需的对象。
  - 在初始执行时，GCS 存储的沿袭信息追踪着有状态的 Actor 以及无状态的 Tasks
  -
